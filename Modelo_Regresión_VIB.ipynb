{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rx4M00N/IA_Tarea1/blob/main/Modelo_Regresi%C3%B3n_VIB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementación Modelo VIB\n",
        "Regresión para obtener calidad en muestras de vino blanco.\n",
        "\n",
        "Elaborado por: Joshua Corvera y Ricardo Luna.\n",
        "\n",
        "MT-8008 Inteligencia Artificial, grupo 1, II Semestre 2022."
      ],
      "metadata": {
        "id": "yHZGrDfxy9qD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importación de librerías"
      ],
      "metadata": {
        "id": "z4abSetmzcEE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDYuimN4y4rl"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Normalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Carga de datos a partir de archivo .csv"
      ],
      "metadata": {
        "id": "wrwJZ9FOzqAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se cargan los datos desde un .csv\n",
        "datos_vinoblanco = pd.read_csv('winequality-white.csv', header=0)\n",
        "#Se revisa el arreglo cargado y se elimiman datos nulos\n",
        "datos_vinoblanco = datos_vinoblanco.dropna()\n",
        "#Muestra el arreglo cargado en pantalla\n",
        "print(datos_vinoblanco)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfgQAh8zzjnC",
        "outputId": "5643f2ec-7d1b-4cea-8b76-ea335d8bd0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
            "0               7.0              0.27         0.36            20.7      0.045   \n",
            "1               6.3              0.30         0.34             1.6      0.049   \n",
            "2               8.1              0.28         0.40             6.9      0.050   \n",
            "3               7.2              0.23         0.32             8.5      0.058   \n",
            "4               7.2              0.23         0.32             8.5      0.058   \n",
            "...             ...               ...          ...             ...        ...   \n",
            "4893            6.2              0.21         0.29             1.6      0.039   \n",
            "4894            6.6              0.32         0.36             8.0      0.047   \n",
            "4895            6.5              0.24         0.19             1.2      0.041   \n",
            "4896            5.5              0.29         0.30             1.1      0.022   \n",
            "4897            6.0              0.21         0.38             0.8      0.020   \n",
            "\n",
            "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
            "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
            "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
            "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
            "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
            "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
            "...                   ...                   ...      ...   ...        ...   \n",
            "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
            "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
            "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
            "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
            "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
            "\n",
            "      alcohol  quality  \n",
            "0         8.8        6  \n",
            "1         9.5        6  \n",
            "2        10.1        6  \n",
            "3         9.9        6  \n",
            "4         9.9        6  \n",
            "...       ...      ...  \n",
            "4893     11.2        6  \n",
            "4894      9.6        5  \n",
            "4895      9.4        6  \n",
            "4896     12.8        7  \n",
            "4897     11.8        6  \n",
            "\n",
            "[4898 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Formato de los datos y separación en subconjuntos"
      ],
      "metadata": {
        "id": "s2cXARY-zzqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============== Dar formato a los datos de entrenamiento ===============\n",
        "#Se define un porcentaje de los datos que se usará para entrenar.\n",
        "#En este caso se usan 80% de los datos para entrenamiento y validación, y 20%\n",
        "#para pruebas\n",
        "p_train = 0.80\n",
        "#Se seleccionan datos al azar, mediante la asignación temporal de flags\n",
        "datos_vinoblanco['is_train'] = np.random.uniform(0, 1, len(datos_vinoblanco)) <= p_train\n",
        "#Se dividen los datos en subconjuntos, según los flags asginados\n",
        "train, test = datos_vinoblanco[datos_vinoblanco['is_train']==True], datos_vinoblanco[datos_vinoblanco['is_train']==False]\n",
        "#Se eliminan los flags del conjunto original\n",
        "datos_vinotinto = datos_vinoblanco.drop('is_train', 1)\n",
        "#Se imprimen las cantidades de datos de entrenamiento y de prueba\n",
        "print(\"Ejemplos usados para entrenar: \", len(train))\n",
        "print(\"Ejemplos usados para test: \", len(test))\n",
        "#Se eliminan los flags temporales de los subconjuntos de prueba y entrenamiento\n",
        "train.pop('is_train')\n",
        "test.pop('is_train')\n",
        "#Se separan las etiquetas de las entradas, para cada subconjunto de datos\n",
        "train_labels = train.pop('quality')\n",
        "train_data = train\n",
        "test_labels = test.pop('quality')\n",
        "test_data = test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H_qOHSozyr6",
        "outputId": "1713e393-8427-4768-a942-0806441c9cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplos usados para entrenar:  3876\n",
            "Ejemplos usados para test:  1022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Normalización de datos "
      ],
      "metadata": {
        "id": "TkJ4skFy0LdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea un objeto tipo scaler, que se encargará de normalizar los datos de cada\n",
        "#subconjunto\n",
        "scaler = StandardScaler()\n",
        "#Se normalizan los subconjuntos de entrenamiento y prueba \n",
        "normed_train_data = scaler.fit_transform(train_data)\n",
        "normed_test_data = scaler.fit_transform(test_data)"
      ],
      "metadata": {
        "id": "yo99kIJHz5pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creación y compilación del modelo"
      ],
      "metadata": {
        "id": "cwyX3l5f0xT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se define una función para facilitar la creación de la red densa\n",
        "def build_model():\n",
        "  #A continuación se crea el modelo para la red, definiendo un valor para las\n",
        "  #entradas con el parámetro input_shape=[len(train_data.keys())], y luego\n",
        "  #se agregan capas de neuronas a la red, con la cantidad definida de neuronas\n",
        "  #por capa y la función de activación sigmoide. Por último, se cuenta con una\n",
        "  #única neurona de salida\n",
        "  model = Sequential([\n",
        "    Dense(24, activation='sigmoid', input_shape=[len(train_data.keys())]),\n",
        "    Dense(24, activation='sigmoid'),\n",
        "    Dense(24, activation='sigmoid'),\n",
        "    Dense(1)\n",
        "  ])\n",
        "\n",
        "  #Se define el optimizador para implementar con la red, así como su tasa de\n",
        "  #aprendizaje y valor de momentum\n",
        "  optimizer = Adam(learning_rate=0.001, beta_1=0.0)\n",
        "\n",
        "  #Se compila el modelo definido, con la función de pérdida tipo Huber y usando\n",
        "  #los errores MAE y MSE como métricas, así como el optimizador definido\n",
        "  model.compile(loss='huber',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  #Finaliza el llamado a la función mediante el retorno del modelo\n",
        "  return model\n",
        "#Se crea el modelo de la red, haciendo un llamado a la función anterior\n",
        "model = build_model()\n",
        "#Con el fin de verificar la creación adecuada del modelo, se muestra un resumen\n",
        "#de este último\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSCzV_Nh0wiT",
        "outputId": "a6f9c8ac-60cc-443d-b985-d1a5dd9f9007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 24)                288       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,513\n",
            "Trainable params: 1,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Entrenamiento"
      ],
      "metadata": {
        "id": "MfZXUob43CSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se define el número de iteraciones para realizar el entrenamiento\n",
        "EPOCHS = 800\n",
        "#Asimismo, se calcula la cantidad y frecuencia de las validaciones, según las\n",
        "#iteraciones realizadas\n",
        "CantVal = int(EPOCHS * 0.1)\n",
        "freqVal = int(EPOCHS / CantVal)\n",
        "#Se entrena a la red neuronal, usando el subconjunto de datos de entrenamiento\n",
        "#Además se define que un 20% de este conjunto se utilizará para validación\n",
        "#El inicio del entrenamiento se indica mediante un mensaje en pantalla\n",
        "print(\"Realizando entrenamiento...\")\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels.to_numpy(),\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=1)\n",
        "#Se indica el final del entrenamiento\n",
        "print(\"Fin del entrenamiento\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWjt-rQr3Emy",
        "outputId": "0fb199dc-00ff-4ccf-ad64-27fc3845ec28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Realizando entrenamiento...\n",
            "Epoch 1/800\n",
            "97/97 [==============================] - 5s 10ms/step - loss: 2.7465 - mae: 3.2410 - mse: 12.5230 - val_loss: 0.8782 - val_mae: 1.3322 - val_mse: 2.2899\n",
            "Epoch 2/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.4681 - mae: 0.8614 - mse: 1.1545 - val_loss: 0.2674 - val_mae: 0.6056 - val_mse: 0.5878\n",
            "Epoch 3/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.3465 - mae: 0.6941 - mse: 0.7918 - val_loss: 0.2561 - val_mae: 0.5471 - val_mse: 0.5592\n",
            "Epoch 4/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.3362 - mae: 0.6696 - mse: 0.7649 - val_loss: 0.2498 - val_mae: 0.5268 - val_mse: 0.5471\n",
            "Epoch 5/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.3270 - mae: 0.6529 - mse: 0.7423 - val_loss: 0.2436 - val_mae: 0.5219 - val_mse: 0.5362\n",
            "Epoch 6/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.3192 - mae: 0.6450 - mse: 0.7240 - val_loss: 0.2380 - val_mae: 0.5160 - val_mse: 0.5257\n",
            "Epoch 7/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.3116 - mae: 0.6392 - mse: 0.7058 - val_loss: 0.2358 - val_mae: 0.5231 - val_mse: 0.5197\n",
            "Epoch 8/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.3040 - mae: 0.6352 - mse: 0.6872 - val_loss: 0.2291 - val_mae: 0.5156 - val_mse: 0.5071\n",
            "Epoch 9/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2972 - mae: 0.6303 - mse: 0.6711 - val_loss: 0.2243 - val_mae: 0.5127 - val_mse: 0.4982\n",
            "Epoch 10/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2906 - mae: 0.6254 - mse: 0.6560 - val_loss: 0.2224 - val_mae: 0.5218 - val_mse: 0.4936\n",
            "Epoch 11/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2851 - mae: 0.6220 - mse: 0.6420 - val_loss: 0.2190 - val_mae: 0.5210 - val_mse: 0.4875\n",
            "Epoch 12/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2799 - mae: 0.6182 - mse: 0.6295 - val_loss: 0.2197 - val_mae: 0.5332 - val_mse: 0.4886\n",
            "Epoch 13/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2753 - mae: 0.6153 - mse: 0.6180 - val_loss: 0.2143 - val_mae: 0.5199 - val_mse: 0.4795\n",
            "Epoch 14/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2720 - mae: 0.6119 - mse: 0.6101 - val_loss: 0.2169 - val_mae: 0.5351 - val_mse: 0.4835\n",
            "Epoch 15/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2690 - mae: 0.6092 - mse: 0.6030 - val_loss: 0.2205 - val_mae: 0.5479 - val_mse: 0.4895\n",
            "Epoch 16/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2671 - mae: 0.6074 - mse: 0.5980 - val_loss: 0.2222 - val_mae: 0.5539 - val_mse: 0.4925\n",
            "Epoch 17/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2658 - mae: 0.6067 - mse: 0.5953 - val_loss: 0.2191 - val_mae: 0.5472 - val_mse: 0.4870\n",
            "Epoch 18/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2643 - mae: 0.6043 - mse: 0.5917 - val_loss: 0.2196 - val_mae: 0.5494 - val_mse: 0.4869\n",
            "Epoch 19/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2635 - mae: 0.6038 - mse: 0.5889 - val_loss: 0.2126 - val_mae: 0.5322 - val_mse: 0.4740\n",
            "Epoch 20/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2628 - mae: 0.6027 - mse: 0.5878 - val_loss: 0.2099 - val_mae: 0.5227 - val_mse: 0.4693\n",
            "Epoch 21/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2624 - mae: 0.6020 - mse: 0.5868 - val_loss: 0.2135 - val_mae: 0.5372 - val_mse: 0.4743\n",
            "Epoch 22/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2617 - mae: 0.6012 - mse: 0.5850 - val_loss: 0.2184 - val_mae: 0.5497 - val_mse: 0.4828\n",
            "Epoch 23/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2612 - mae: 0.6010 - mse: 0.5842 - val_loss: 0.2275 - val_mae: 0.5675 - val_mse: 0.5005\n",
            "Epoch 24/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2612 - mae: 0.6011 - mse: 0.5829 - val_loss: 0.2133 - val_mae: 0.5391 - val_mse: 0.4720\n",
            "Epoch 25/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2600 - mae: 0.5993 - mse: 0.5799 - val_loss: 0.2175 - val_mae: 0.5490 - val_mse: 0.4802\n",
            "Epoch 26/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2599 - mae: 0.5993 - mse: 0.5806 - val_loss: 0.2080 - val_mae: 0.5249 - val_mse: 0.4621\n",
            "Epoch 27/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2598 - mae: 0.5988 - mse: 0.5801 - val_loss: 0.2121 - val_mae: 0.5384 - val_mse: 0.4674\n",
            "Epoch 28/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2587 - mae: 0.5967 - mse: 0.5774 - val_loss: 0.2168 - val_mae: 0.5491 - val_mse: 0.4770\n",
            "Epoch 29/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2594 - mae: 0.5990 - mse: 0.5791 - val_loss: 0.2088 - val_mae: 0.5311 - val_mse: 0.4615\n",
            "Epoch 30/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2579 - mae: 0.5977 - mse: 0.5748 - val_loss: 0.2057 - val_mae: 0.5221 - val_mse: 0.4557\n",
            "Epoch 31/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2584 - mae: 0.5971 - mse: 0.5756 - val_loss: 0.2137 - val_mae: 0.5442 - val_mse: 0.4690\n",
            "Epoch 32/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2577 - mae: 0.5966 - mse: 0.5742 - val_loss: 0.2181 - val_mae: 0.5525 - val_mse: 0.4775\n",
            "Epoch 33/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2573 - mae: 0.5961 - mse: 0.5732 - val_loss: 0.2214 - val_mae: 0.5580 - val_mse: 0.4842\n",
            "Epoch 34/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2567 - mae: 0.5951 - mse: 0.5721 - val_loss: 0.2133 - val_mae: 0.5442 - val_mse: 0.4682\n",
            "Epoch 35/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2567 - mae: 0.5952 - mse: 0.5719 - val_loss: 0.2111 - val_mae: 0.5399 - val_mse: 0.4639\n",
            "Epoch 36/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2558 - mae: 0.5930 - mse: 0.5700 - val_loss: 0.2070 - val_mae: 0.5319 - val_mse: 0.4551\n",
            "Epoch 37/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2557 - mae: 0.5942 - mse: 0.5695 - val_loss: 0.2175 - val_mae: 0.5522 - val_mse: 0.4754\n",
            "Epoch 38/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2553 - mae: 0.5931 - mse: 0.5681 - val_loss: 0.2128 - val_mae: 0.5443 - val_mse: 0.4653\n",
            "Epoch 39/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2551 - mae: 0.5932 - mse: 0.5683 - val_loss: 0.2146 - val_mae: 0.5469 - val_mse: 0.4696\n",
            "Epoch 40/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2539 - mae: 0.5901 - mse: 0.5656 - val_loss: 0.2149 - val_mae: 0.5477 - val_mse: 0.4687\n",
            "Epoch 41/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2541 - mae: 0.5911 - mse: 0.5654 - val_loss: 0.2068 - val_mae: 0.5336 - val_mse: 0.4529\n",
            "Epoch 42/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2537 - mae: 0.5910 - mse: 0.5638 - val_loss: 0.2221 - val_mae: 0.5590 - val_mse: 0.4845\n",
            "Epoch 43/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2538 - mae: 0.5908 - mse: 0.5637 - val_loss: 0.2051 - val_mae: 0.5310 - val_mse: 0.4486\n",
            "Epoch 44/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2526 - mae: 0.5899 - mse: 0.5619 - val_loss: 0.2016 - val_mae: 0.5223 - val_mse: 0.4421\n",
            "Epoch 45/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2523 - mae: 0.5896 - mse: 0.5600 - val_loss: 0.2139 - val_mae: 0.5461 - val_mse: 0.4650\n",
            "Epoch 46/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2519 - mae: 0.5885 - mse: 0.5595 - val_loss: 0.2073 - val_mae: 0.5357 - val_mse: 0.4517\n",
            "Epoch 47/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2515 - mae: 0.5879 - mse: 0.5583 - val_loss: 0.2029 - val_mae: 0.5277 - val_mse: 0.4429\n",
            "Epoch 48/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2513 - mae: 0.5862 - mse: 0.5581 - val_loss: 0.2004 - val_mae: 0.5209 - val_mse: 0.4387\n",
            "Epoch 49/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2511 - mae: 0.5875 - mse: 0.5571 - val_loss: 0.2312 - val_mae: 0.5702 - val_mse: 0.5015\n",
            "Epoch 50/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2503 - mae: 0.5853 - mse: 0.5552 - val_loss: 0.2032 - val_mae: 0.5289 - val_mse: 0.4429\n",
            "Epoch 51/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2497 - mae: 0.5843 - mse: 0.5537 - val_loss: 0.2486 - val_mae: 0.5910 - val_mse: 0.5387\n",
            "Epoch 52/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2498 - mae: 0.5856 - mse: 0.5544 - val_loss: 0.1994 - val_mae: 0.5207 - val_mse: 0.4351\n",
            "Epoch 53/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2481 - mae: 0.5820 - mse: 0.5499 - val_loss: 0.1986 - val_mae: 0.5184 - val_mse: 0.4333\n",
            "Epoch 54/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2494 - mae: 0.5839 - mse: 0.5525 - val_loss: 0.2119 - val_mae: 0.5423 - val_mse: 0.4588\n",
            "Epoch 55/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2473 - mae: 0.5799 - mse: 0.5484 - val_loss: 0.2066 - val_mae: 0.5349 - val_mse: 0.4482\n",
            "Epoch 56/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2477 - mae: 0.5823 - mse: 0.5493 - val_loss: 0.1965 - val_mae: 0.5122 - val_mse: 0.4281\n",
            "Epoch 57/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2473 - mae: 0.5801 - mse: 0.5484 - val_loss: 0.2003 - val_mae: 0.5237 - val_mse: 0.4359\n",
            "Epoch 58/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2473 - mae: 0.5810 - mse: 0.5481 - val_loss: 0.2148 - val_mae: 0.5465 - val_mse: 0.4646\n",
            "Epoch 59/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2462 - mae: 0.5787 - mse: 0.5448 - val_loss: 0.2002 - val_mae: 0.5247 - val_mse: 0.4343\n",
            "Epoch 60/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2458 - mae: 0.5784 - mse: 0.5446 - val_loss: 0.2058 - val_mae: 0.5335 - val_mse: 0.4451\n",
            "Epoch 61/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2454 - mae: 0.5778 - mse: 0.5428 - val_loss: 0.1943 - val_mae: 0.5117 - val_mse: 0.4212\n",
            "Epoch 62/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2458 - mae: 0.5781 - mse: 0.5444 - val_loss: 0.1964 - val_mae: 0.5181 - val_mse: 0.4253\n",
            "Epoch 63/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2439 - mae: 0.5742 - mse: 0.5401 - val_loss: 0.1964 - val_mae: 0.5181 - val_mse: 0.4254\n",
            "Epoch 64/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2435 - mae: 0.5755 - mse: 0.5392 - val_loss: 0.1963 - val_mae: 0.5174 - val_mse: 0.4253\n",
            "Epoch 65/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2434 - mae: 0.5748 - mse: 0.5381 - val_loss: 0.2109 - val_mae: 0.5401 - val_mse: 0.4561\n",
            "Epoch 66/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2443 - mae: 0.5752 - mse: 0.5410 - val_loss: 0.1978 - val_mae: 0.5207 - val_mse: 0.4278\n",
            "Epoch 67/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2438 - mae: 0.5745 - mse: 0.5392 - val_loss: 0.1950 - val_mae: 0.5164 - val_mse: 0.4208\n",
            "Epoch 68/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2431 - mae: 0.5735 - mse: 0.5373 - val_loss: 0.1993 - val_mae: 0.5233 - val_mse: 0.4298\n",
            "Epoch 69/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2430 - mae: 0.5733 - mse: 0.5368 - val_loss: 0.2349 - val_mae: 0.5715 - val_mse: 0.5068\n",
            "Epoch 70/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2429 - mae: 0.5720 - mse: 0.5370 - val_loss: 0.1958 - val_mae: 0.5171 - val_mse: 0.4233\n",
            "Epoch 71/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2425 - mae: 0.5733 - mse: 0.5351 - val_loss: 0.2194 - val_mae: 0.5502 - val_mse: 0.4733\n",
            "Epoch 72/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2421 - mae: 0.5717 - mse: 0.5352 - val_loss: 0.2020 - val_mae: 0.5270 - val_mse: 0.4357\n",
            "Epoch 73/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2406 - mae: 0.5680 - mse: 0.5306 - val_loss: 0.1951 - val_mae: 0.5155 - val_mse: 0.4213\n",
            "Epoch 74/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2415 - mae: 0.5707 - mse: 0.5324 - val_loss: 0.2143 - val_mae: 0.5434 - val_mse: 0.4629\n",
            "Epoch 75/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2408 - mae: 0.5696 - mse: 0.5322 - val_loss: 0.2000 - val_mae: 0.5243 - val_mse: 0.4308\n",
            "Epoch 76/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2410 - mae: 0.5693 - mse: 0.5320 - val_loss: 0.2073 - val_mae: 0.5337 - val_mse: 0.4461\n",
            "Epoch 77/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2400 - mae: 0.5667 - mse: 0.5295 - val_loss: 0.1921 - val_mae: 0.5070 - val_mse: 0.4146\n",
            "Epoch 78/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.5671 - mse: 0.5294 - val_loss: 0.2019 - val_mae: 0.5264 - val_mse: 0.4345\n",
            "Epoch 79/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2400 - mae: 0.5672 - mse: 0.5298 - val_loss: 0.1974 - val_mae: 0.5202 - val_mse: 0.4246\n",
            "Epoch 80/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.5678 - mse: 0.5277 - val_loss: 0.1971 - val_mae: 0.5195 - val_mse: 0.4241\n",
            "Epoch 81/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2388 - mae: 0.5654 - mse: 0.5269 - val_loss: 0.1979 - val_mae: 0.5206 - val_mse: 0.4257\n",
            "Epoch 82/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.2387 - mae: 0.5643 - mse: 0.5267 - val_loss: 0.1998 - val_mae: 0.5226 - val_mse: 0.4287\n",
            "Epoch 83/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2383 - mae: 0.5655 - mse: 0.5248 - val_loss: 0.2035 - val_mae: 0.5275 - val_mse: 0.4371\n",
            "Epoch 84/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2386 - mae: 0.5659 - mse: 0.5257 - val_loss: 0.1921 - val_mae: 0.5071 - val_mse: 0.4140\n",
            "Epoch 85/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2383 - mae: 0.5645 - mse: 0.5257 - val_loss: 0.1912 - val_mae: 0.5090 - val_mse: 0.4107\n",
            "Epoch 86/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2375 - mae: 0.5629 - mse: 0.5237 - val_loss: 0.1955 - val_mae: 0.5167 - val_mse: 0.4204\n",
            "Epoch 87/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2374 - mae: 0.5629 - mse: 0.5226 - val_loss: 0.2021 - val_mae: 0.5258 - val_mse: 0.4342\n",
            "Epoch 88/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2381 - mae: 0.5640 - mse: 0.5247 - val_loss: 0.2013 - val_mae: 0.5241 - val_mse: 0.4320\n",
            "Epoch 89/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2364 - mae: 0.5612 - mse: 0.5208 - val_loss: 0.1940 - val_mae: 0.5135 - val_mse: 0.4160\n",
            "Epoch 90/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2375 - mae: 0.5643 - mse: 0.5227 - val_loss: 0.2134 - val_mae: 0.5410 - val_mse: 0.4586\n",
            "Epoch 91/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2372 - mae: 0.5631 - mse: 0.5220 - val_loss: 0.2092 - val_mae: 0.5349 - val_mse: 0.4485\n",
            "Epoch 92/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2360 - mae: 0.5602 - mse: 0.5203 - val_loss: 0.2004 - val_mae: 0.5228 - val_mse: 0.4302\n",
            "Epoch 93/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2362 - mae: 0.5606 - mse: 0.5207 - val_loss: 0.1988 - val_mae: 0.5203 - val_mse: 0.4265\n",
            "Epoch 94/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2359 - mae: 0.5604 - mse: 0.5195 - val_loss: 0.2011 - val_mae: 0.5236 - val_mse: 0.4315\n",
            "Epoch 95/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2348 - mae: 0.5603 - mse: 0.5154 - val_loss: 0.2157 - val_mae: 0.5446 - val_mse: 0.4625\n",
            "Epoch 96/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2358 - mae: 0.5592 - mse: 0.5193 - val_loss: 0.1951 - val_mae: 0.5150 - val_mse: 0.4184\n",
            "Epoch 97/800\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.2364 - mae: 0.5613 - mse: 0.5204 - val_loss: 0.2004 - val_mae: 0.5222 - val_mse: 0.4295\n",
            "Epoch 98/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2360 - mae: 0.5617 - mse: 0.5188 - val_loss: 0.2045 - val_mae: 0.5279 - val_mse: 0.4385\n",
            "Epoch 99/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2350 - mae: 0.5591 - mse: 0.5167 - val_loss: 0.1947 - val_mae: 0.5140 - val_mse: 0.4173\n",
            "Epoch 100/800\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.2350 - mae: 0.5602 - mse: 0.5164 - val_loss: 0.2040 - val_mae: 0.5270 - val_mse: 0.4370\n",
            "Epoch 101/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2348 - mae: 0.5588 - mse: 0.5161 - val_loss: 0.1876 - val_mae: 0.5010 - val_mse: 0.4020\n",
            "Epoch 102/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2355 - mae: 0.5597 - mse: 0.5183 - val_loss: 0.1949 - val_mae: 0.5139 - val_mse: 0.4173\n",
            "Epoch 103/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2347 - mae: 0.5579 - mse: 0.5167 - val_loss: 0.2036 - val_mae: 0.5265 - val_mse: 0.4357\n",
            "Epoch 104/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2357 - mae: 0.5596 - mse: 0.5181 - val_loss: 0.1913 - val_mae: 0.5079 - val_mse: 0.4099\n",
            "Epoch 105/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2341 - mae: 0.5566 - mse: 0.5152 - val_loss: 0.1924 - val_mae: 0.5103 - val_mse: 0.4113\n",
            "Epoch 106/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2340 - mae: 0.5565 - mse: 0.5140 - val_loss: 0.1942 - val_mae: 0.5129 - val_mse: 0.4149\n",
            "Epoch 107/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2344 - mae: 0.5585 - mse: 0.5151 - val_loss: 0.2027 - val_mae: 0.5253 - val_mse: 0.4331\n",
            "Epoch 108/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2346 - mae: 0.5581 - mse: 0.5154 - val_loss: 0.1970 - val_mae: 0.5169 - val_mse: 0.4215\n",
            "Epoch 109/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2340 - mae: 0.5566 - mse: 0.5150 - val_loss: 0.1915 - val_mae: 0.5089 - val_mse: 0.4089\n",
            "Epoch 110/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2338 - mae: 0.5580 - mse: 0.5136 - val_loss: 0.1967 - val_mae: 0.5166 - val_mse: 0.4206\n",
            "Epoch 111/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2328 - mae: 0.5557 - mse: 0.5110 - val_loss: 0.1873 - val_mae: 0.5019 - val_mse: 0.4005\n",
            "Epoch 112/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2337 - mae: 0.5563 - mse: 0.5133 - val_loss: 0.2098 - val_mae: 0.5355 - val_mse: 0.4487\n",
            "Epoch 113/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2323 - mae: 0.5555 - mse: 0.5110 - val_loss: 0.1970 - val_mae: 0.5166 - val_mse: 0.4217\n",
            "Epoch 114/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2325 - mae: 0.5555 - mse: 0.5104 - val_loss: 0.1916 - val_mae: 0.5087 - val_mse: 0.4094\n",
            "Epoch 115/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2322 - mae: 0.5548 - mse: 0.5106 - val_loss: 0.1871 - val_mae: 0.5017 - val_mse: 0.3991\n",
            "Epoch 116/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2324 - mae: 0.5550 - mse: 0.5096 - val_loss: 0.1887 - val_mae: 0.5042 - val_mse: 0.4031\n",
            "Epoch 117/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2327 - mae: 0.5557 - mse: 0.5109 - val_loss: 0.2066 - val_mae: 0.5311 - val_mse: 0.4417\n",
            "Epoch 118/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2328 - mae: 0.5549 - mse: 0.5109 - val_loss: 0.2059 - val_mae: 0.5304 - val_mse: 0.4397\n",
            "Epoch 119/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2320 - mae: 0.5544 - mse: 0.5102 - val_loss: 0.2016 - val_mae: 0.5239 - val_mse: 0.4304\n",
            "Epoch 120/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2320 - mae: 0.5540 - mse: 0.5091 - val_loss: 0.1896 - val_mae: 0.5058 - val_mse: 0.4044\n",
            "Epoch 121/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2320 - mae: 0.5543 - mse: 0.5095 - val_loss: 0.2000 - val_mae: 0.5214 - val_mse: 0.4266\n",
            "Epoch 122/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2310 - mae: 0.5520 - mse: 0.5070 - val_loss: 0.1916 - val_mae: 0.5088 - val_mse: 0.4086\n",
            "Epoch 123/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2302 - mae: 0.5513 - mse: 0.5052 - val_loss: 0.1868 - val_mae: 0.5013 - val_mse: 0.3980\n",
            "Epoch 124/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2311 - mae: 0.5522 - mse: 0.5071 - val_loss: 0.1879 - val_mae: 0.5010 - val_mse: 0.4016\n",
            "Epoch 125/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2318 - mae: 0.5553 - mse: 0.5085 - val_loss: 0.1957 - val_mae: 0.5151 - val_mse: 0.4176\n",
            "Epoch 126/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2310 - mae: 0.5528 - mse: 0.5074 - val_loss: 0.1997 - val_mae: 0.5210 - val_mse: 0.4264\n",
            "Epoch 127/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2305 - mae: 0.5513 - mse: 0.5053 - val_loss: 0.2004 - val_mae: 0.5223 - val_mse: 0.4273\n",
            "Epoch 128/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2301 - mae: 0.5513 - mse: 0.5050 - val_loss: 0.1945 - val_mae: 0.5135 - val_mse: 0.4149\n",
            "Epoch 129/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2298 - mae: 0.5510 - mse: 0.5033 - val_loss: 0.1871 - val_mae: 0.5012 - val_mse: 0.3993\n",
            "Epoch 130/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2306 - mae: 0.5511 - mse: 0.5058 - val_loss: 0.1920 - val_mae: 0.5101 - val_mse: 0.4094\n",
            "Epoch 131/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2300 - mae: 0.5511 - mse: 0.5041 - val_loss: 0.2107 - val_mae: 0.5379 - val_mse: 0.4494\n",
            "Epoch 132/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2300 - mae: 0.5509 - mse: 0.5053 - val_loss: 0.2017 - val_mae: 0.5243 - val_mse: 0.4300\n",
            "Epoch 133/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2301 - mae: 0.5515 - mse: 0.5038 - val_loss: 0.1928 - val_mae: 0.5109 - val_mse: 0.4113\n",
            "Epoch 134/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2300 - mae: 0.5509 - mse: 0.5044 - val_loss: 0.2109 - val_mae: 0.5384 - val_mse: 0.4500\n",
            "Epoch 135/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2289 - mae: 0.5489 - mse: 0.5022 - val_loss: 0.1918 - val_mae: 0.5099 - val_mse: 0.4089\n",
            "Epoch 136/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2286 - mae: 0.5487 - mse: 0.5014 - val_loss: 0.2165 - val_mae: 0.5461 - val_mse: 0.4621\n",
            "Epoch 137/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2289 - mae: 0.5498 - mse: 0.5023 - val_loss: 0.2022 - val_mae: 0.5252 - val_mse: 0.4312\n",
            "Epoch 138/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2286 - mae: 0.5494 - mse: 0.5006 - val_loss: 0.1976 - val_mae: 0.5185 - val_mse: 0.4210\n",
            "Epoch 139/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2283 - mae: 0.5491 - mse: 0.4999 - val_loss: 0.1994 - val_mae: 0.5211 - val_mse: 0.4249\n",
            "Epoch 140/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2278 - mae: 0.5471 - mse: 0.4989 - val_loss: 0.1872 - val_mae: 0.5013 - val_mse: 0.3993\n",
            "Epoch 141/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2285 - mae: 0.5482 - mse: 0.5008 - val_loss: 0.2079 - val_mae: 0.5340 - val_mse: 0.4434\n",
            "Epoch 142/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2278 - mae: 0.5475 - mse: 0.4986 - val_loss: 0.2112 - val_mae: 0.5396 - val_mse: 0.4510\n",
            "Epoch 143/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2275 - mae: 0.5485 - mse: 0.4981 - val_loss: 0.1979 - val_mae: 0.5188 - val_mse: 0.4220\n",
            "Epoch 144/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2279 - mae: 0.5472 - mse: 0.4989 - val_loss: 0.2106 - val_mae: 0.5382 - val_mse: 0.4492\n",
            "Epoch 145/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2278 - mae: 0.5478 - mse: 0.4985 - val_loss: 0.2034 - val_mae: 0.5274 - val_mse: 0.4327\n",
            "Epoch 146/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2263 - mae: 0.5458 - mse: 0.4954 - val_loss: 0.1926 - val_mae: 0.5115 - val_mse: 0.4097\n",
            "Epoch 147/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2276 - mae: 0.5487 - mse: 0.4988 - val_loss: 0.1857 - val_mae: 0.4998 - val_mse: 0.3951\n",
            "Epoch 148/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2270 - mae: 0.5466 - mse: 0.4982 - val_loss: 0.2017 - val_mae: 0.5246 - val_mse: 0.4296\n",
            "Epoch 149/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2266 - mae: 0.5466 - mse: 0.4954 - val_loss: 0.1996 - val_mae: 0.5222 - val_mse: 0.4248\n",
            "Epoch 150/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2273 - mae: 0.5479 - mse: 0.4984 - val_loss: 0.2018 - val_mae: 0.5253 - val_mse: 0.4297\n",
            "Epoch 151/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2266 - mae: 0.5456 - mse: 0.4955 - val_loss: 0.1978 - val_mae: 0.5182 - val_mse: 0.4218\n",
            "Epoch 152/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2265 - mae: 0.5465 - mse: 0.4950 - val_loss: 0.1975 - val_mae: 0.5188 - val_mse: 0.4208\n",
            "Epoch 153/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2261 - mae: 0.5456 - mse: 0.4949 - val_loss: 0.2038 - val_mae: 0.5284 - val_mse: 0.4343\n",
            "Epoch 154/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2256 - mae: 0.5460 - mse: 0.4932 - val_loss: 0.1955 - val_mae: 0.5163 - val_mse: 0.4159\n",
            "Epoch 155/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2262 - mae: 0.5452 - mse: 0.4955 - val_loss: 0.1892 - val_mae: 0.5063 - val_mse: 0.4028\n",
            "Epoch 156/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2258 - mae: 0.5447 - mse: 0.4940 - val_loss: 0.2138 - val_mae: 0.5441 - val_mse: 0.4550\n",
            "Epoch 157/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2266 - mae: 0.5463 - mse: 0.4958 - val_loss: 0.2150 - val_mae: 0.5458 - val_mse: 0.4577\n",
            "Epoch 158/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2242 - mae: 0.5425 - mse: 0.4906 - val_loss: 0.2008 - val_mae: 0.5247 - val_mse: 0.4271\n",
            "Epoch 159/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2251 - mae: 0.5453 - mse: 0.4918 - val_loss: 0.1900 - val_mae: 0.5080 - val_mse: 0.4048\n",
            "Epoch 160/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2251 - mae: 0.5439 - mse: 0.4921 - val_loss: 0.2182 - val_mae: 0.5510 - val_mse: 0.4653\n",
            "Epoch 161/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2247 - mae: 0.5443 - mse: 0.4907 - val_loss: 0.2010 - val_mae: 0.5249 - val_mse: 0.4276\n",
            "Epoch 162/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2252 - mae: 0.5446 - mse: 0.4932 - val_loss: 0.1970 - val_mae: 0.5182 - val_mse: 0.4197\n",
            "Epoch 163/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2249 - mae: 0.5444 - mse: 0.4919 - val_loss: 0.1894 - val_mae: 0.5073 - val_mse: 0.4026\n",
            "Epoch 164/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2248 - mae: 0.5442 - mse: 0.4916 - val_loss: 0.1897 - val_mae: 0.5070 - val_mse: 0.4036\n",
            "Epoch 165/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2236 - mae: 0.5415 - mse: 0.4891 - val_loss: 0.2032 - val_mae: 0.5286 - val_mse: 0.4322\n",
            "Epoch 166/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2240 - mae: 0.5428 - mse: 0.4897 - val_loss: 0.2321 - val_mae: 0.5721 - val_mse: 0.4958\n",
            "Epoch 167/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2239 - mae: 0.5432 - mse: 0.4889 - val_loss: 0.1949 - val_mae: 0.5158 - val_mse: 0.4144\n",
            "Epoch 168/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2242 - mae: 0.5422 - mse: 0.4901 - val_loss: 0.1904 - val_mae: 0.5085 - val_mse: 0.4049\n",
            "Epoch 169/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2228 - mae: 0.5407 - mse: 0.4865 - val_loss: 0.1886 - val_mae: 0.5066 - val_mse: 0.4006\n",
            "Epoch 170/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2236 - mae: 0.5419 - mse: 0.4894 - val_loss: 0.2089 - val_mae: 0.5370 - val_mse: 0.4446\n",
            "Epoch 171/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2229 - mae: 0.5415 - mse: 0.4863 - val_loss: 0.2002 - val_mae: 0.5239 - val_mse: 0.4256\n",
            "Epoch 172/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2233 - mae: 0.5414 - mse: 0.4883 - val_loss: 0.1862 - val_mae: 0.5020 - val_mse: 0.3957\n",
            "Epoch 173/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2229 - mae: 0.5411 - mse: 0.4873 - val_loss: 0.1965 - val_mae: 0.5183 - val_mse: 0.4182\n",
            "Epoch 174/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2230 - mae: 0.5416 - mse: 0.4877 - val_loss: 0.1922 - val_mae: 0.5122 - val_mse: 0.4082\n",
            "Epoch 175/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2223 - mae: 0.5383 - mse: 0.4864 - val_loss: 0.1845 - val_mae: 0.4962 - val_mse: 0.3925\n",
            "Epoch 176/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2227 - mae: 0.5413 - mse: 0.4866 - val_loss: 0.1868 - val_mae: 0.5001 - val_mse: 0.3975\n",
            "Epoch 177/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2222 - mae: 0.5393 - mse: 0.4851 - val_loss: 0.1935 - val_mae: 0.5142 - val_mse: 0.4112\n",
            "Epoch 178/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2221 - mae: 0.5390 - mse: 0.4856 - val_loss: 0.2022 - val_mae: 0.5279 - val_mse: 0.4298\n",
            "Epoch 179/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2217 - mae: 0.5401 - mse: 0.4840 - val_loss: 0.1884 - val_mae: 0.5055 - val_mse: 0.4003\n",
            "Epoch 180/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2222 - mae: 0.5406 - mse: 0.4861 - val_loss: 0.2012 - val_mae: 0.5260 - val_mse: 0.4280\n",
            "Epoch 181/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2213 - mae: 0.5393 - mse: 0.4824 - val_loss: 0.1966 - val_mae: 0.5194 - val_mse: 0.4172\n",
            "Epoch 182/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2218 - mae: 0.5406 - mse: 0.4846 - val_loss: 0.2189 - val_mae: 0.5528 - val_mse: 0.4663\n",
            "Epoch 183/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2207 - mae: 0.5377 - mse: 0.4822 - val_loss: 0.1970 - val_mae: 0.5205 - val_mse: 0.4187\n",
            "Epoch 184/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2209 - mae: 0.5387 - mse: 0.4822 - val_loss: 0.1953 - val_mae: 0.5169 - val_mse: 0.4151\n",
            "Epoch 185/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2208 - mae: 0.5393 - mse: 0.4814 - val_loss: 0.2019 - val_mae: 0.5257 - val_mse: 0.4303\n",
            "Epoch 186/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2206 - mae: 0.5384 - mse: 0.4816 - val_loss: 0.1944 - val_mae: 0.5156 - val_mse: 0.4134\n",
            "Epoch 187/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2202 - mae: 0.5371 - mse: 0.4811 - val_loss: 0.1946 - val_mae: 0.5163 - val_mse: 0.4137\n",
            "Epoch 188/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2207 - mae: 0.5380 - mse: 0.4818 - val_loss: 0.1928 - val_mae: 0.5137 - val_mse: 0.4096\n",
            "Epoch 189/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2198 - mae: 0.5371 - mse: 0.4794 - val_loss: 0.2043 - val_mae: 0.5321 - val_mse: 0.4347\n",
            "Epoch 190/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2202 - mae: 0.5379 - mse: 0.4814 - val_loss: 0.2028 - val_mae: 0.5282 - val_mse: 0.4319\n",
            "Epoch 191/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2202 - mae: 0.5371 - mse: 0.4802 - val_loss: 0.1863 - val_mae: 0.5024 - val_mse: 0.3959\n",
            "Epoch 192/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2195 - mae: 0.5366 - mse: 0.4793 - val_loss: 0.2094 - val_mae: 0.5389 - val_mse: 0.4450\n",
            "Epoch 193/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2195 - mae: 0.5359 - mse: 0.4794 - val_loss: 0.1921 - val_mae: 0.5127 - val_mse: 0.4080\n",
            "Epoch 194/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2187 - mae: 0.5352 - mse: 0.4778 - val_loss: 0.1894 - val_mae: 0.5089 - val_mse: 0.4017\n",
            "Epoch 195/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2191 - mae: 0.5362 - mse: 0.4776 - val_loss: 0.2094 - val_mae: 0.5395 - val_mse: 0.4454\n",
            "Epoch 196/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2192 - mae: 0.5367 - mse: 0.4790 - val_loss: 0.1943 - val_mae: 0.5152 - val_mse: 0.4132\n",
            "Epoch 197/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2199 - mae: 0.5376 - mse: 0.4798 - val_loss: 0.1933 - val_mae: 0.5144 - val_mse: 0.4107\n",
            "Epoch 198/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2189 - mae: 0.5355 - mse: 0.4776 - val_loss: 0.2033 - val_mae: 0.5301 - val_mse: 0.4320\n",
            "Epoch 199/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2192 - mae: 0.5369 - mse: 0.4786 - val_loss: 0.1997 - val_mae: 0.5240 - val_mse: 0.4251\n",
            "Epoch 200/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2178 - mae: 0.5338 - mse: 0.4753 - val_loss: 0.1909 - val_mae: 0.5100 - val_mse: 0.4056\n",
            "Epoch 201/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2185 - mae: 0.5356 - mse: 0.4766 - val_loss: 0.2066 - val_mae: 0.5356 - val_mse: 0.4392\n",
            "Epoch 202/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2186 - mae: 0.5355 - mse: 0.4760 - val_loss: 0.1981 - val_mae: 0.5227 - val_mse: 0.4210\n",
            "Epoch 203/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2179 - mae: 0.5350 - mse: 0.4763 - val_loss: 0.1970 - val_mae: 0.5206 - val_mse: 0.4186\n",
            "Epoch 204/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2181 - mae: 0.5340 - mse: 0.4761 - val_loss: 0.1992 - val_mae: 0.5243 - val_mse: 0.4226\n",
            "Epoch 205/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2173 - mae: 0.5332 - mse: 0.4739 - val_loss: 0.2004 - val_mae: 0.5268 - val_mse: 0.4256\n",
            "Epoch 206/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2168 - mae: 0.5322 - mse: 0.4723 - val_loss: 0.2038 - val_mae: 0.5324 - val_mse: 0.4335\n",
            "Epoch 207/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2176 - mae: 0.5338 - mse: 0.4748 - val_loss: 0.1934 - val_mae: 0.5156 - val_mse: 0.4108\n",
            "Epoch 208/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2174 - mae: 0.5335 - mse: 0.4737 - val_loss: 0.2036 - val_mae: 0.5300 - val_mse: 0.4333\n",
            "Epoch 209/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2173 - mae: 0.5323 - mse: 0.4738 - val_loss: 0.1940 - val_mae: 0.5167 - val_mse: 0.4116\n",
            "Epoch 210/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2174 - mae: 0.5336 - mse: 0.4745 - val_loss: 0.1949 - val_mae: 0.5174 - val_mse: 0.4139\n",
            "Epoch 211/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2165 - mae: 0.5317 - mse: 0.4722 - val_loss: 0.1952 - val_mae: 0.5176 - val_mse: 0.4147\n",
            "Epoch 212/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2164 - mae: 0.5329 - mse: 0.4708 - val_loss: 0.1976 - val_mae: 0.5216 - val_mse: 0.4199\n",
            "Epoch 213/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2174 - mae: 0.5327 - mse: 0.4740 - val_loss: 0.2009 - val_mae: 0.5261 - val_mse: 0.4273\n",
            "Epoch 214/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2158 - mae: 0.5308 - mse: 0.4705 - val_loss: 0.1862 - val_mae: 0.5026 - val_mse: 0.3951\n",
            "Epoch 215/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2159 - mae: 0.5315 - mse: 0.4703 - val_loss: 0.2139 - val_mae: 0.5457 - val_mse: 0.4556\n",
            "Epoch 216/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2166 - mae: 0.5318 - mse: 0.4721 - val_loss: 0.1872 - val_mae: 0.5048 - val_mse: 0.3975\n",
            "Epoch 217/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2162 - mae: 0.5312 - mse: 0.4717 - val_loss: 0.1974 - val_mae: 0.5217 - val_mse: 0.4190\n",
            "Epoch 218/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2155 - mae: 0.5313 - mse: 0.4696 - val_loss: 0.2093 - val_mae: 0.5389 - val_mse: 0.4456\n",
            "Epoch 219/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2154 - mae: 0.5299 - mse: 0.4684 - val_loss: 0.1959 - val_mae: 0.5193 - val_mse: 0.4157\n",
            "Epoch 220/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2152 - mae: 0.5291 - mse: 0.4688 - val_loss: 0.2107 - val_mae: 0.5415 - val_mse: 0.4484\n",
            "Epoch 221/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2142 - mae: 0.5282 - mse: 0.4657 - val_loss: 0.2033 - val_mae: 0.5304 - val_mse: 0.4315\n",
            "Epoch 222/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2153 - mae: 0.5290 - mse: 0.4695 - val_loss: 0.1844 - val_mae: 0.4978 - val_mse: 0.3912\n",
            "Epoch 223/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2148 - mae: 0.5298 - mse: 0.4680 - val_loss: 0.1904 - val_mae: 0.5108 - val_mse: 0.4035\n",
            "Epoch 224/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2147 - mae: 0.5307 - mse: 0.4671 - val_loss: 0.1886 - val_mae: 0.5054 - val_mse: 0.4006\n",
            "Epoch 225/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2146 - mae: 0.5295 - mse: 0.4659 - val_loss: 0.1997 - val_mae: 0.5244 - val_mse: 0.4240\n",
            "Epoch 226/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2134 - mae: 0.5286 - mse: 0.4636 - val_loss: 0.1971 - val_mae: 0.5196 - val_mse: 0.4187\n",
            "Epoch 227/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2146 - mae: 0.5291 - mse: 0.4673 - val_loss: 0.1912 - val_mae: 0.5104 - val_mse: 0.4058\n",
            "Epoch 228/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2155 - mae: 0.5309 - mse: 0.4693 - val_loss: 0.2002 - val_mae: 0.5256 - val_mse: 0.4245\n",
            "Epoch 229/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2137 - mae: 0.5282 - mse: 0.4651 - val_loss: 0.1991 - val_mae: 0.5236 - val_mse: 0.4224\n",
            "Epoch 230/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2138 - mae: 0.5283 - mse: 0.4652 - val_loss: 0.1934 - val_mae: 0.5141 - val_mse: 0.4105\n",
            "Epoch 231/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2147 - mae: 0.5287 - mse: 0.4679 - val_loss: 0.1967 - val_mae: 0.5206 - val_mse: 0.4170\n",
            "Epoch 232/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2135 - mae: 0.5276 - mse: 0.4651 - val_loss: 0.2045 - val_mae: 0.5318 - val_mse: 0.4342\n",
            "Epoch 233/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2127 - mae: 0.5272 - mse: 0.4632 - val_loss: 0.1995 - val_mae: 0.5235 - val_mse: 0.4238\n",
            "Epoch 234/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2129 - mae: 0.5266 - mse: 0.4640 - val_loss: 0.2030 - val_mae: 0.5282 - val_mse: 0.4312\n",
            "Epoch 235/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2123 - mae: 0.5243 - mse: 0.4620 - val_loss: 0.2046 - val_mae: 0.5301 - val_mse: 0.4351\n",
            "Epoch 236/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2130 - mae: 0.5268 - mse: 0.4637 - val_loss: 0.1922 - val_mae: 0.5127 - val_mse: 0.4076\n",
            "Epoch 237/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2131 - mae: 0.5284 - mse: 0.4643 - val_loss: 0.1905 - val_mae: 0.5060 - val_mse: 0.4045\n",
            "Epoch 238/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2124 - mae: 0.5251 - mse: 0.4617 - val_loss: 0.2217 - val_mae: 0.5556 - val_mse: 0.4713\n",
            "Epoch 239/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2125 - mae: 0.5263 - mse: 0.4625 - val_loss: 0.1987 - val_mae: 0.5232 - val_mse: 0.4214\n",
            "Epoch 240/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2125 - mae: 0.5270 - mse: 0.4626 - val_loss: 0.1942 - val_mae: 0.5149 - val_mse: 0.4119\n",
            "Epoch 241/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2120 - mae: 0.5247 - mse: 0.4621 - val_loss: 0.1909 - val_mae: 0.5113 - val_mse: 0.4044\n",
            "Epoch 242/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2112 - mae: 0.5250 - mse: 0.4592 - val_loss: 0.1936 - val_mae: 0.5122 - val_mse: 0.4112\n",
            "Epoch 243/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2126 - mae: 0.5265 - mse: 0.4628 - val_loss: 0.2037 - val_mae: 0.5302 - val_mse: 0.4325\n",
            "Epoch 244/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2121 - mae: 0.5256 - mse: 0.4621 - val_loss: 0.2091 - val_mae: 0.5373 - val_mse: 0.4448\n",
            "Epoch 245/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2111 - mae: 0.5235 - mse: 0.4595 - val_loss: 0.2016 - val_mae: 0.5269 - val_mse: 0.4278\n",
            "Epoch 246/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2115 - mae: 0.5247 - mse: 0.4611 - val_loss: 0.1953 - val_mae: 0.5163 - val_mse: 0.4143\n",
            "Epoch 247/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2110 - mae: 0.5248 - mse: 0.4587 - val_loss: 0.2065 - val_mae: 0.5332 - val_mse: 0.4387\n",
            "Epoch 248/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2106 - mae: 0.5233 - mse: 0.4580 - val_loss: 0.1968 - val_mae: 0.5196 - val_mse: 0.4174\n",
            "Epoch 249/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2107 - mae: 0.5228 - mse: 0.4578 - val_loss: 0.2087 - val_mae: 0.5364 - val_mse: 0.4434\n",
            "Epoch 250/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2112 - mae: 0.5234 - mse: 0.4590 - val_loss: 0.1981 - val_mae: 0.5204 - val_mse: 0.4206\n",
            "Epoch 251/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2108 - mae: 0.5233 - mse: 0.4588 - val_loss: 0.2115 - val_mae: 0.5412 - val_mse: 0.4491\n",
            "Epoch 252/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2109 - mae: 0.5234 - mse: 0.4591 - val_loss: 0.1944 - val_mae: 0.5146 - val_mse: 0.4125\n",
            "Epoch 253/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2102 - mae: 0.5226 - mse: 0.4566 - val_loss: 0.2035 - val_mae: 0.5286 - val_mse: 0.4320\n",
            "Epoch 254/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2104 - mae: 0.5227 - mse: 0.4567 - val_loss: 0.1952 - val_mae: 0.5167 - val_mse: 0.4135\n",
            "Epoch 255/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2111 - mae: 0.5238 - mse: 0.4589 - val_loss: 0.2049 - val_mae: 0.5312 - val_mse: 0.4348\n",
            "Epoch 256/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2098 - mae: 0.5213 - mse: 0.4562 - val_loss: 0.1936 - val_mae: 0.5116 - val_mse: 0.4107\n",
            "Epoch 257/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2103 - mae: 0.5221 - mse: 0.4575 - val_loss: 0.1910 - val_mae: 0.5091 - val_mse: 0.4056\n",
            "Epoch 258/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2113 - mae: 0.5243 - mse: 0.4593 - val_loss: 0.1905 - val_mae: 0.5084 - val_mse: 0.4044\n",
            "Epoch 259/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2104 - mae: 0.5231 - mse: 0.4571 - val_loss: 0.1965 - val_mae: 0.5183 - val_mse: 0.4164\n",
            "Epoch 260/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2107 - mae: 0.5223 - mse: 0.4576 - val_loss: 0.1989 - val_mae: 0.5215 - val_mse: 0.4215\n",
            "Epoch 261/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2096 - mae: 0.5215 - mse: 0.4562 - val_loss: 0.1921 - val_mae: 0.5111 - val_mse: 0.4076\n",
            "Epoch 262/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2101 - mae: 0.5210 - mse: 0.4564 - val_loss: 0.2047 - val_mae: 0.5298 - val_mse: 0.4345\n",
            "Epoch 263/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2085 - mae: 0.5199 - mse: 0.4517 - val_loss: 0.1962 - val_mae: 0.5171 - val_mse: 0.4161\n",
            "Epoch 264/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2088 - mae: 0.5206 - mse: 0.4537 - val_loss: 0.2048 - val_mae: 0.5282 - val_mse: 0.4349\n",
            "Epoch 265/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2090 - mae: 0.5202 - mse: 0.4540 - val_loss: 0.2304 - val_mae: 0.5658 - val_mse: 0.4904\n",
            "Epoch 266/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2098 - mae: 0.5224 - mse: 0.4557 - val_loss: 0.2211 - val_mae: 0.5538 - val_mse: 0.4706\n",
            "Epoch 267/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2092 - mae: 0.5207 - mse: 0.4540 - val_loss: 0.2043 - val_mae: 0.5297 - val_mse: 0.4335\n",
            "Epoch 268/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2083 - mae: 0.5202 - mse: 0.4527 - val_loss: 0.2086 - val_mae: 0.5351 - val_mse: 0.4433\n",
            "Epoch 269/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2085 - mae: 0.5194 - mse: 0.4519 - val_loss: 0.2032 - val_mae: 0.5284 - val_mse: 0.4310\n",
            "Epoch 270/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2091 - mae: 0.5209 - mse: 0.4534 - val_loss: 0.2295 - val_mae: 0.5648 - val_mse: 0.4889\n",
            "Epoch 271/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2086 - mae: 0.5203 - mse: 0.4526 - val_loss: 0.2032 - val_mae: 0.5276 - val_mse: 0.4309\n",
            "Epoch 272/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2091 - mae: 0.5208 - mse: 0.4545 - val_loss: 0.2131 - val_mae: 0.5417 - val_mse: 0.4528\n",
            "Epoch 273/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2079 - mae: 0.5197 - mse: 0.4522 - val_loss: 0.2393 - val_mae: 0.5787 - val_mse: 0.5101\n",
            "Epoch 274/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2079 - mae: 0.5185 - mse: 0.4519 - val_loss: 0.2072 - val_mae: 0.5329 - val_mse: 0.4389\n",
            "Epoch 275/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2087 - mae: 0.5204 - mse: 0.4527 - val_loss: 0.2067 - val_mae: 0.5313 - val_mse: 0.4390\n",
            "Epoch 276/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2078 - mae: 0.5179 - mse: 0.4519 - val_loss: 0.1973 - val_mae: 0.5174 - val_mse: 0.4186\n",
            "Epoch 277/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2071 - mae: 0.5184 - mse: 0.4487 - val_loss: 0.2028 - val_mae: 0.5267 - val_mse: 0.4304\n",
            "Epoch 278/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2081 - mae: 0.5192 - mse: 0.4516 - val_loss: 0.2062 - val_mae: 0.5325 - val_mse: 0.4374\n",
            "Epoch 279/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2077 - mae: 0.5176 - mse: 0.4516 - val_loss: 0.2226 - val_mae: 0.5545 - val_mse: 0.4740\n",
            "Epoch 280/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2068 - mae: 0.5178 - mse: 0.4486 - val_loss: 0.2143 - val_mae: 0.5429 - val_mse: 0.4559\n",
            "Epoch 281/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2071 - mae: 0.5185 - mse: 0.4499 - val_loss: 0.1936 - val_mae: 0.5124 - val_mse: 0.4110\n",
            "Epoch 282/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2071 - mae: 0.5178 - mse: 0.4501 - val_loss: 0.2134 - val_mae: 0.5416 - val_mse: 0.4539\n",
            "Epoch 283/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2071 - mae: 0.5184 - mse: 0.4489 - val_loss: 0.1998 - val_mae: 0.5225 - val_mse: 0.4232\n",
            "Epoch 284/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2070 - mae: 0.5179 - mse: 0.4488 - val_loss: 0.2057 - val_mae: 0.5295 - val_mse: 0.4372\n",
            "Epoch 285/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2070 - mae: 0.5175 - mse: 0.4496 - val_loss: 0.2092 - val_mae: 0.5351 - val_mse: 0.4445\n",
            "Epoch 286/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2074 - mae: 0.5185 - mse: 0.4506 - val_loss: 0.2111 - val_mae: 0.5373 - val_mse: 0.4485\n",
            "Epoch 287/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2064 - mae: 0.5164 - mse: 0.4481 - val_loss: 0.1993 - val_mae: 0.5213 - val_mse: 0.4224\n",
            "Epoch 288/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2058 - mae: 0.5160 - mse: 0.4465 - val_loss: 0.1995 - val_mae: 0.5198 - val_mse: 0.4238\n",
            "Epoch 289/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2062 - mae: 0.5161 - mse: 0.4470 - val_loss: 0.2177 - val_mae: 0.5471 - val_mse: 0.4629\n",
            "Epoch 290/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2062 - mae: 0.5163 - mse: 0.4475 - val_loss: 0.2021 - val_mae: 0.5250 - val_mse: 0.4284\n",
            "Epoch 291/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2064 - mae: 0.5160 - mse: 0.4478 - val_loss: 0.2117 - val_mae: 0.5397 - val_mse: 0.4495\n",
            "Epoch 292/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2073 - mae: 0.5163 - mse: 0.4499 - val_loss: 0.2049 - val_mae: 0.5295 - val_mse: 0.4345\n",
            "Epoch 293/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2061 - mae: 0.5150 - mse: 0.4475 - val_loss: 0.2021 - val_mae: 0.5248 - val_mse: 0.4291\n",
            "Epoch 294/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2056 - mae: 0.5156 - mse: 0.4453 - val_loss: 0.2205 - val_mae: 0.5514 - val_mse: 0.4693\n",
            "Epoch 295/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2061 - mae: 0.5152 - mse: 0.4482 - val_loss: 0.2140 - val_mae: 0.5422 - val_mse: 0.4548\n",
            "Epoch 296/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2051 - mae: 0.5144 - mse: 0.4455 - val_loss: 0.2094 - val_mae: 0.5353 - val_mse: 0.4447\n",
            "Epoch 297/800\n",
            "97/97 [==============================] - 1s 6ms/step - loss: 0.2056 - mae: 0.5159 - mse: 0.4452 - val_loss: 0.2251 - val_mae: 0.5568 - val_mse: 0.4792\n",
            "Epoch 298/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.2056 - mae: 0.5144 - mse: 0.4463 - val_loss: 0.2175 - val_mae: 0.5461 - val_mse: 0.4629\n",
            "Epoch 299/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2056 - mae: 0.5134 - mse: 0.4465 - val_loss: 0.2134 - val_mae: 0.5408 - val_mse: 0.4538\n",
            "Epoch 300/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.2048 - mae: 0.5137 - mse: 0.4438 - val_loss: 0.2078 - val_mae: 0.5322 - val_mse: 0.4416\n",
            "Epoch 301/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2047 - mae: 0.5140 - mse: 0.4437 - val_loss: 0.2030 - val_mae: 0.5255 - val_mse: 0.4316\n",
            "Epoch 302/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2057 - mae: 0.5159 - mse: 0.4465 - val_loss: 0.2192 - val_mae: 0.5497 - val_mse: 0.4672\n",
            "Epoch 303/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2047 - mae: 0.5136 - mse: 0.4439 - val_loss: 0.1996 - val_mae: 0.5204 - val_mse: 0.4238\n",
            "Epoch 304/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2045 - mae: 0.5125 - mse: 0.4440 - val_loss: 0.2058 - val_mae: 0.5295 - val_mse: 0.4367\n",
            "Epoch 305/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2057 - mae: 0.5144 - mse: 0.4468 - val_loss: 0.2036 - val_mae: 0.5266 - val_mse: 0.4320\n",
            "Epoch 306/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2052 - mae: 0.5146 - mse: 0.4457 - val_loss: 0.2018 - val_mae: 0.5244 - val_mse: 0.4284\n",
            "Epoch 307/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2047 - mae: 0.5138 - mse: 0.4440 - val_loss: 0.2064 - val_mae: 0.5311 - val_mse: 0.4381\n",
            "Epoch 308/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2044 - mae: 0.5129 - mse: 0.4426 - val_loss: 0.2198 - val_mae: 0.5493 - val_mse: 0.4672\n",
            "Epoch 309/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2044 - mae: 0.5124 - mse: 0.4434 - val_loss: 0.1966 - val_mae: 0.5159 - val_mse: 0.4172\n",
            "Epoch 310/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2039 - mae: 0.5129 - mse: 0.4427 - val_loss: 0.1982 - val_mae: 0.5190 - val_mse: 0.4204\n",
            "Epoch 311/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2054 - mae: 0.5146 - mse: 0.4452 - val_loss: 0.2101 - val_mae: 0.5354 - val_mse: 0.4466\n",
            "Epoch 312/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2047 - mae: 0.5128 - mse: 0.4436 - val_loss: 0.2053 - val_mae: 0.5290 - val_mse: 0.4362\n",
            "Epoch 313/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2041 - mae: 0.5126 - mse: 0.4430 - val_loss: 0.2022 - val_mae: 0.5226 - val_mse: 0.4301\n",
            "Epoch 314/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2044 - mae: 0.5132 - mse: 0.4435 - val_loss: 0.2383 - val_mae: 0.5732 - val_mse: 0.5098\n",
            "Epoch 315/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2043 - mae: 0.5113 - mse: 0.4435 - val_loss: 0.2142 - val_mae: 0.5419 - val_mse: 0.4555\n",
            "Epoch 316/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2045 - mae: 0.5140 - mse: 0.4435 - val_loss: 0.2005 - val_mae: 0.5218 - val_mse: 0.4256\n",
            "Epoch 317/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2032 - mae: 0.5113 - mse: 0.4401 - val_loss: 0.2206 - val_mae: 0.5492 - val_mse: 0.4704\n",
            "Epoch 318/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2048 - mae: 0.5141 - mse: 0.4442 - val_loss: 0.2089 - val_mae: 0.5332 - val_mse: 0.4444\n",
            "Epoch 319/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2037 - mae: 0.5115 - mse: 0.4420 - val_loss: 0.2085 - val_mae: 0.5335 - val_mse: 0.4435\n",
            "Epoch 320/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2043 - mae: 0.5128 - mse: 0.4431 - val_loss: 0.2138 - val_mae: 0.5403 - val_mse: 0.4546\n",
            "Epoch 321/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2035 - mae: 0.5114 - mse: 0.4415 - val_loss: 0.2076 - val_mae: 0.5313 - val_mse: 0.4414\n",
            "Epoch 322/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2036 - mae: 0.5123 - mse: 0.4417 - val_loss: 0.2109 - val_mae: 0.5363 - val_mse: 0.4486\n",
            "Epoch 323/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2037 - mae: 0.5115 - mse: 0.4418 - val_loss: 0.2013 - val_mae: 0.5222 - val_mse: 0.4278\n",
            "Epoch 324/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2035 - mae: 0.5104 - mse: 0.4415 - val_loss: 0.2147 - val_mae: 0.5414 - val_mse: 0.4566\n",
            "Epoch 325/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2028 - mae: 0.5095 - mse: 0.4403 - val_loss: 0.2267 - val_mae: 0.5582 - val_mse: 0.4836\n",
            "Epoch 326/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2030 - mae: 0.5109 - mse: 0.4400 - val_loss: 0.2256 - val_mae: 0.5570 - val_mse: 0.4811\n",
            "Epoch 327/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2033 - mae: 0.5106 - mse: 0.4420 - val_loss: 0.2086 - val_mae: 0.5334 - val_mse: 0.4435\n",
            "Epoch 328/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2026 - mae: 0.5098 - mse: 0.4384 - val_loss: 0.2096 - val_mae: 0.5344 - val_mse: 0.4454\n",
            "Epoch 329/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2029 - mae: 0.5117 - mse: 0.4401 - val_loss: 0.2091 - val_mae: 0.5333 - val_mse: 0.4443\n",
            "Epoch 330/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2029 - mae: 0.5102 - mse: 0.4403 - val_loss: 0.2282 - val_mae: 0.5605 - val_mse: 0.4866\n",
            "Epoch 331/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2025 - mae: 0.5096 - mse: 0.4390 - val_loss: 0.2076 - val_mae: 0.5311 - val_mse: 0.4414\n",
            "Epoch 332/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2020 - mae: 0.5095 - mse: 0.4381 - val_loss: 0.2087 - val_mae: 0.5324 - val_mse: 0.4436\n",
            "Epoch 333/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2018 - mae: 0.5083 - mse: 0.4378 - val_loss: 0.2275 - val_mae: 0.5592 - val_mse: 0.4851\n",
            "Epoch 334/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2022 - mae: 0.5083 - mse: 0.4385 - val_loss: 0.2203 - val_mae: 0.5482 - val_mse: 0.4695\n",
            "Epoch 335/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2026 - mae: 0.5092 - mse: 0.4392 - val_loss: 0.2391 - val_mae: 0.5737 - val_mse: 0.5116\n",
            "Epoch 336/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2024 - mae: 0.5101 - mse: 0.4377 - val_loss: 0.2134 - val_mae: 0.5392 - val_mse: 0.4538\n",
            "Epoch 337/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2026 - mae: 0.5102 - mse: 0.4397 - val_loss: 0.2221 - val_mae: 0.5510 - val_mse: 0.4731\n",
            "Epoch 338/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2024 - mae: 0.5088 - mse: 0.4389 - val_loss: 0.2215 - val_mae: 0.5495 - val_mse: 0.4722\n",
            "Epoch 339/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2007 - mae: 0.5069 - mse: 0.4349 - val_loss: 0.2344 - val_mae: 0.5670 - val_mse: 0.5016\n",
            "Epoch 340/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2022 - mae: 0.5086 - mse: 0.4387 - val_loss: 0.2305 - val_mae: 0.5625 - val_mse: 0.4924\n",
            "Epoch 341/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2013 - mae: 0.5071 - mse: 0.4365 - val_loss: 0.2098 - val_mae: 0.5343 - val_mse: 0.4457\n",
            "Epoch 342/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2022 - mae: 0.5096 - mse: 0.4377 - val_loss: 0.2120 - val_mae: 0.5372 - val_mse: 0.4508\n",
            "Epoch 343/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2020 - mae: 0.5095 - mse: 0.4377 - val_loss: 0.2305 - val_mae: 0.5611 - val_mse: 0.4924\n",
            "Epoch 344/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2024 - mae: 0.5101 - mse: 0.4392 - val_loss: 0.2075 - val_mae: 0.5305 - val_mse: 0.4412\n",
            "Epoch 345/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2007 - mae: 0.5064 - mse: 0.4345 - val_loss: 0.2301 - val_mae: 0.5617 - val_mse: 0.4909\n",
            "Epoch 346/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2010 - mae: 0.5070 - mse: 0.4352 - val_loss: 0.2004 - val_mae: 0.5215 - val_mse: 0.4264\n",
            "Epoch 347/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2011 - mae: 0.5078 - mse: 0.4360 - val_loss: 0.2027 - val_mae: 0.5237 - val_mse: 0.4310\n",
            "Epoch 348/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2012 - mae: 0.5089 - mse: 0.4371 - val_loss: 0.2286 - val_mae: 0.5583 - val_mse: 0.4881\n",
            "Epoch 349/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2016 - mae: 0.5091 - mse: 0.4371 - val_loss: 0.2142 - val_mae: 0.5387 - val_mse: 0.4564\n",
            "Epoch 350/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2005 - mae: 0.5063 - mse: 0.4347 - val_loss: 0.2088 - val_mae: 0.5323 - val_mse: 0.4440\n",
            "Epoch 351/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2012 - mae: 0.5063 - mse: 0.4369 - val_loss: 0.2020 - val_mae: 0.5227 - val_mse: 0.4300\n",
            "Epoch 352/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2012 - mae: 0.5076 - mse: 0.4362 - val_loss: 0.2311 - val_mae: 0.5628 - val_mse: 0.4924\n",
            "Epoch 353/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2012 - mae: 0.5088 - mse: 0.4353 - val_loss: 0.2313 - val_mae: 0.5620 - val_mse: 0.4943\n",
            "Epoch 354/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2006 - mae: 0.5061 - mse: 0.4352 - val_loss: 0.2581 - val_mae: 0.5982 - val_mse: 0.5540\n",
            "Epoch 355/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2007 - mae: 0.5066 - mse: 0.4349 - val_loss: 0.2160 - val_mae: 0.5420 - val_mse: 0.4595\n",
            "Epoch 356/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2009 - mae: 0.5076 - mse: 0.4362 - val_loss: 0.2136 - val_mae: 0.5380 - val_mse: 0.4548\n",
            "Epoch 357/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2008 - mae: 0.5061 - mse: 0.4346 - val_loss: 0.2298 - val_mae: 0.5604 - val_mse: 0.4899\n",
            "Epoch 358/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2008 - mae: 0.5081 - mse: 0.4356 - val_loss: 0.2049 - val_mae: 0.5268 - val_mse: 0.4363\n",
            "Epoch 359/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2015 - mae: 0.5081 - mse: 0.4369 - val_loss: 0.2468 - val_mae: 0.5821 - val_mse: 0.5288\n",
            "Epoch 360/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2001 - mae: 0.5057 - mse: 0.4337 - val_loss: 0.2407 - val_mae: 0.5737 - val_mse: 0.5154\n",
            "Epoch 361/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2013 - mae: 0.5075 - mse: 0.4361 - val_loss: 0.2164 - val_mae: 0.5422 - val_mse: 0.4609\n",
            "Epoch 362/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2002 - mae: 0.5051 - mse: 0.4342 - val_loss: 0.2042 - val_mae: 0.5264 - val_mse: 0.4349\n",
            "Epoch 363/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2006 - mae: 0.5074 - mse: 0.4347 - val_loss: 0.2367 - val_mae: 0.5695 - val_mse: 0.5064\n",
            "Epoch 364/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2009 - mae: 0.5071 - mse: 0.4342 - val_loss: 0.2103 - val_mae: 0.5338 - val_mse: 0.4483\n",
            "Epoch 365/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1997 - mae: 0.5048 - mse: 0.4329 - val_loss: 0.2061 - val_mae: 0.5290 - val_mse: 0.4384\n",
            "Epoch 366/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1999 - mae: 0.5052 - mse: 0.4329 - val_loss: 0.2342 - val_mae: 0.5662 - val_mse: 0.5002\n",
            "Epoch 367/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2005 - mae: 0.5059 - mse: 0.4342 - val_loss: 0.2121 - val_mae: 0.5368 - val_mse: 0.4511\n",
            "Epoch 368/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2000 - mae: 0.5055 - mse: 0.4339 - val_loss: 0.2237 - val_mae: 0.5511 - val_mse: 0.4766\n",
            "Epoch 369/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1999 - mae: 0.5052 - mse: 0.4332 - val_loss: 0.2360 - val_mae: 0.5676 - val_mse: 0.5038\n",
            "Epoch 370/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1997 - mae: 0.5037 - mse: 0.4334 - val_loss: 0.2075 - val_mae: 0.5313 - val_mse: 0.4410\n",
            "Epoch 371/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1997 - mae: 0.5064 - mse: 0.4325 - val_loss: 0.2088 - val_mae: 0.5317 - val_mse: 0.4443\n",
            "Epoch 372/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1995 - mae: 0.5040 - mse: 0.4324 - val_loss: 0.2245 - val_mae: 0.5530 - val_mse: 0.4779\n",
            "Epoch 373/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1993 - mae: 0.5045 - mse: 0.4318 - val_loss: 0.2013 - val_mae: 0.5221 - val_mse: 0.4285\n",
            "Epoch 374/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1999 - mae: 0.5052 - mse: 0.4333 - val_loss: 0.2071 - val_mae: 0.5298 - val_mse: 0.4404\n",
            "Epoch 375/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1991 - mae: 0.5040 - mse: 0.4315 - val_loss: 0.2251 - val_mae: 0.5524 - val_mse: 0.4807\n",
            "Epoch 376/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1997 - mae: 0.5054 - mse: 0.4325 - val_loss: 0.2073 - val_mae: 0.5292 - val_mse: 0.4413\n",
            "Epoch 377/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1994 - mae: 0.5047 - mse: 0.4316 - val_loss: 0.2130 - val_mae: 0.5373 - val_mse: 0.4535\n",
            "Epoch 378/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1993 - mae: 0.5044 - mse: 0.4317 - val_loss: 0.2177 - val_mae: 0.5437 - val_mse: 0.4639\n",
            "Epoch 379/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1994 - mae: 0.5058 - mse: 0.4313 - val_loss: 0.2216 - val_mae: 0.5486 - val_mse: 0.4725\n",
            "Epoch 380/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.2001 - mae: 0.5051 - mse: 0.4341 - val_loss: 0.2070 - val_mae: 0.5304 - val_mse: 0.4408\n",
            "Epoch 381/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1981 - mae: 0.5034 - mse: 0.4289 - val_loss: 0.2298 - val_mae: 0.5596 - val_mse: 0.4898\n",
            "Epoch 382/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1988 - mae: 0.5050 - mse: 0.4299 - val_loss: 0.2140 - val_mae: 0.5391 - val_mse: 0.4555\n",
            "Epoch 383/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1989 - mae: 0.5033 - mse: 0.4309 - val_loss: 0.2069 - val_mae: 0.5303 - val_mse: 0.4405\n",
            "Epoch 384/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1990 - mae: 0.5044 - mse: 0.4311 - val_loss: 0.2143 - val_mae: 0.5387 - val_mse: 0.4568\n",
            "Epoch 385/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1994 - mae: 0.5055 - mse: 0.4323 - val_loss: 0.2347 - val_mae: 0.5664 - val_mse: 0.5016\n",
            "Epoch 386/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1987 - mae: 0.5040 - mse: 0.4307 - val_loss: 0.2179 - val_mae: 0.5436 - val_mse: 0.4645\n",
            "Epoch 387/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1977 - mae: 0.5021 - mse: 0.4276 - val_loss: 0.2068 - val_mae: 0.5295 - val_mse: 0.4400\n",
            "Epoch 388/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1984 - mae: 0.5021 - mse: 0.4295 - val_loss: 0.2168 - val_mae: 0.5422 - val_mse: 0.4615\n",
            "Epoch 389/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1980 - mae: 0.5029 - mse: 0.4287 - val_loss: 0.2253 - val_mae: 0.5528 - val_mse: 0.4813\n",
            "Epoch 390/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1988 - mae: 0.5030 - mse: 0.4303 - val_loss: 0.2257 - val_mae: 0.5537 - val_mse: 0.4813\n",
            "Epoch 391/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1978 - mae: 0.5030 - mse: 0.4276 - val_loss: 0.2105 - val_mae: 0.5343 - val_mse: 0.4476\n",
            "Epoch 392/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1982 - mae: 0.5037 - mse: 0.4298 - val_loss: 0.2241 - val_mae: 0.5518 - val_mse: 0.4778\n",
            "Epoch 393/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1986 - mae: 0.5026 - mse: 0.4308 - val_loss: 0.2073 - val_mae: 0.5306 - val_mse: 0.4405\n",
            "Epoch 394/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1981 - mae: 0.5027 - mse: 0.4294 - val_loss: 0.2107 - val_mae: 0.5346 - val_mse: 0.4483\n",
            "Epoch 395/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1977 - mae: 0.5016 - mse: 0.4285 - val_loss: 0.2028 - val_mae: 0.5236 - val_mse: 0.4310\n",
            "Epoch 396/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1978 - mae: 0.5020 - mse: 0.4285 - val_loss: 0.2226 - val_mae: 0.5501 - val_mse: 0.4741\n",
            "Epoch 397/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1972 - mae: 0.5015 - mse: 0.4270 - val_loss: 0.2147 - val_mae: 0.5389 - val_mse: 0.4575\n",
            "Epoch 398/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1983 - mae: 0.5032 - mse: 0.4291 - val_loss: 0.2302 - val_mae: 0.5586 - val_mse: 0.4916\n",
            "Epoch 399/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1981 - mae: 0.5024 - mse: 0.4281 - val_loss: 0.2208 - val_mae: 0.5478 - val_mse: 0.4709\n",
            "Epoch 400/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1980 - mae: 0.5019 - mse: 0.4296 - val_loss: 0.2141 - val_mae: 0.5384 - val_mse: 0.4558\n",
            "Epoch 401/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1983 - mae: 0.5025 - mse: 0.4301 - val_loss: 0.2107 - val_mae: 0.5347 - val_mse: 0.4481\n",
            "Epoch 402/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1968 - mae: 0.5007 - mse: 0.4264 - val_loss: 0.2103 - val_mae: 0.5344 - val_mse: 0.4480\n",
            "Epoch 403/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1984 - mae: 0.5036 - mse: 0.4292 - val_loss: 0.2157 - val_mae: 0.5407 - val_mse: 0.4593\n",
            "Epoch 404/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1967 - mae: 0.5002 - mse: 0.4253 - val_loss: 0.2091 - val_mae: 0.5323 - val_mse: 0.4454\n",
            "Epoch 405/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1987 - mae: 0.5036 - mse: 0.4305 - val_loss: 0.2178 - val_mae: 0.5437 - val_mse: 0.4646\n",
            "Epoch 406/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1971 - mae: 0.5020 - mse: 0.4274 - val_loss: 0.2228 - val_mae: 0.5505 - val_mse: 0.4746\n",
            "Epoch 407/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1981 - mae: 0.5035 - mse: 0.4295 - val_loss: 0.2103 - val_mae: 0.5337 - val_mse: 0.4475\n",
            "Epoch 408/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1972 - mae: 0.5008 - mse: 0.4270 - val_loss: 0.2299 - val_mae: 0.5584 - val_mse: 0.4906\n",
            "Epoch 409/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1975 - mae: 0.5014 - mse: 0.4272 - val_loss: 0.2105 - val_mae: 0.5343 - val_mse: 0.4480\n",
            "Epoch 410/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1973 - mae: 0.5009 - mse: 0.4282 - val_loss: 0.2190 - val_mae: 0.5447 - val_mse: 0.4663\n",
            "Epoch 411/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1968 - mae: 0.5006 - mse: 0.4267 - val_loss: 0.2278 - val_mae: 0.5563 - val_mse: 0.4859\n",
            "Epoch 412/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1970 - mae: 0.5020 - mse: 0.4264 - val_loss: 0.2081 - val_mae: 0.5311 - val_mse: 0.4426\n",
            "Epoch 413/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1962 - mae: 0.5004 - mse: 0.4247 - val_loss: 0.2175 - val_mae: 0.5424 - val_mse: 0.4637\n",
            "Epoch 414/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1974 - mae: 0.5025 - mse: 0.4271 - val_loss: 0.2071 - val_mae: 0.5307 - val_mse: 0.4409\n",
            "Epoch 415/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1976 - mae: 0.5007 - mse: 0.4285 - val_loss: 0.2185 - val_mae: 0.5436 - val_mse: 0.4657\n",
            "Epoch 416/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1963 - mae: 0.5007 - mse: 0.4247 - val_loss: 0.2338 - val_mae: 0.5630 - val_mse: 0.4997\n",
            "Epoch 417/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1969 - mae: 0.5001 - mse: 0.4263 - val_loss: 0.2366 - val_mae: 0.5667 - val_mse: 0.5055\n",
            "Epoch 418/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1966 - mae: 0.4996 - mse: 0.4256 - val_loss: 0.2102 - val_mae: 0.5336 - val_mse: 0.4471\n",
            "Epoch 419/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1967 - mae: 0.5008 - mse: 0.4252 - val_loss: 0.2069 - val_mae: 0.5297 - val_mse: 0.4397\n",
            "Epoch 420/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1966 - mae: 0.5001 - mse: 0.4261 - val_loss: 0.2121 - val_mae: 0.5369 - val_mse: 0.4506\n",
            "Epoch 421/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1964 - mae: 0.5002 - mse: 0.4256 - val_loss: 0.2099 - val_mae: 0.5334 - val_mse: 0.4471\n",
            "Epoch 422/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1958 - mae: 0.4994 - mse: 0.4240 - val_loss: 0.2183 - val_mae: 0.5445 - val_mse: 0.4651\n",
            "Epoch 423/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1963 - mae: 0.5009 - mse: 0.4247 - val_loss: 0.2115 - val_mae: 0.5360 - val_mse: 0.4502\n",
            "Epoch 424/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1964 - mae: 0.5002 - mse: 0.4251 - val_loss: 0.2095 - val_mae: 0.5333 - val_mse: 0.4462\n",
            "Epoch 425/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1969 - mae: 0.5014 - mse: 0.4265 - val_loss: 0.2385 - val_mae: 0.5690 - val_mse: 0.5100\n",
            "Epoch 426/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1964 - mae: 0.5007 - mse: 0.4257 - val_loss: 0.2081 - val_mae: 0.5311 - val_mse: 0.4430\n",
            "Epoch 427/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1955 - mae: 0.4977 - mse: 0.4226 - val_loss: 0.2300 - val_mae: 0.5588 - val_mse: 0.4905\n",
            "Epoch 428/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1957 - mae: 0.4996 - mse: 0.4237 - val_loss: 0.2346 - val_mae: 0.5646 - val_mse: 0.5008\n",
            "Epoch 429/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1959 - mae: 0.4995 - mse: 0.4243 - val_loss: 0.2197 - val_mae: 0.5455 - val_mse: 0.4677\n",
            "Epoch 430/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1956 - mae: 0.4985 - mse: 0.4233 - val_loss: 0.2227 - val_mae: 0.5501 - val_mse: 0.4745\n",
            "Epoch 431/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1957 - mae: 0.4990 - mse: 0.4234 - val_loss: 0.2467 - val_mae: 0.5796 - val_mse: 0.5282\n",
            "Epoch 432/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1961 - mae: 0.4998 - mse: 0.4248 - val_loss: 0.2153 - val_mae: 0.5387 - val_mse: 0.4584\n",
            "Epoch 433/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1955 - mae: 0.4996 - mse: 0.4234 - val_loss: 0.2175 - val_mae: 0.5429 - val_mse: 0.4636\n",
            "Epoch 434/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1964 - mae: 0.5007 - mse: 0.4254 - val_loss: 0.2253 - val_mae: 0.5523 - val_mse: 0.4803\n",
            "Epoch 435/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1955 - mae: 0.4991 - mse: 0.4237 - val_loss: 0.2245 - val_mae: 0.5514 - val_mse: 0.4786\n",
            "Epoch 436/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1966 - mae: 0.5010 - mse: 0.4258 - val_loss: 0.2122 - val_mae: 0.5361 - val_mse: 0.4518\n",
            "Epoch 437/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1957 - mae: 0.4982 - mse: 0.4246 - val_loss: 0.2340 - val_mae: 0.5633 - val_mse: 0.4996\n",
            "Epoch 438/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1959 - mae: 0.4986 - mse: 0.4247 - val_loss: 0.2170 - val_mae: 0.5428 - val_mse: 0.4620\n",
            "Epoch 439/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1958 - mae: 0.4984 - mse: 0.4237 - val_loss: 0.2174 - val_mae: 0.5421 - val_mse: 0.4625\n",
            "Epoch 440/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1957 - mae: 0.4981 - mse: 0.4240 - val_loss: 0.2233 - val_mae: 0.5503 - val_mse: 0.4760\n",
            "Epoch 441/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1957 - mae: 0.4986 - mse: 0.4238 - val_loss: 0.2096 - val_mae: 0.5328 - val_mse: 0.4458\n",
            "Epoch 442/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1950 - mae: 0.4991 - mse: 0.4224 - val_loss: 0.2301 - val_mae: 0.5585 - val_mse: 0.4910\n",
            "Epoch 443/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1951 - mae: 0.4969 - mse: 0.4217 - val_loss: 0.2155 - val_mae: 0.5407 - val_mse: 0.4581\n",
            "Epoch 444/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1952 - mae: 0.4993 - mse: 0.4225 - val_loss: 0.2438 - val_mae: 0.5752 - val_mse: 0.5220\n",
            "Epoch 445/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1953 - mae: 0.4987 - mse: 0.4231 - val_loss: 0.2367 - val_mae: 0.5667 - val_mse: 0.5061\n",
            "Epoch 446/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1955 - mae: 0.4986 - mse: 0.4238 - val_loss: 0.2273 - val_mae: 0.5540 - val_mse: 0.4845\n",
            "Epoch 447/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1955 - mae: 0.4991 - mse: 0.4226 - val_loss: 0.2411 - val_mae: 0.5721 - val_mse: 0.5151\n",
            "Epoch 448/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1949 - mae: 0.4982 - mse: 0.4218 - val_loss: 0.2215 - val_mae: 0.5471 - val_mse: 0.4721\n",
            "Epoch 449/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1950 - mae: 0.4987 - mse: 0.4220 - val_loss: 0.2160 - val_mae: 0.5407 - val_mse: 0.4598\n",
            "Epoch 450/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1951 - mae: 0.4976 - mse: 0.4233 - val_loss: 0.2122 - val_mae: 0.5349 - val_mse: 0.4511\n",
            "Epoch 451/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1946 - mae: 0.4959 - mse: 0.4221 - val_loss: 0.2177 - val_mae: 0.5435 - val_mse: 0.4626\n",
            "Epoch 452/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1947 - mae: 0.4975 - mse: 0.4216 - val_loss: 0.2115 - val_mae: 0.5355 - val_mse: 0.4498\n",
            "Epoch 453/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1953 - mae: 0.4984 - mse: 0.4228 - val_loss: 0.2149 - val_mae: 0.5400 - val_mse: 0.4572\n",
            "Epoch 454/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1953 - mae: 0.4977 - mse: 0.4231 - val_loss: 0.2345 - val_mae: 0.5643 - val_mse: 0.4998\n",
            "Epoch 455/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1947 - mae: 0.4976 - mse: 0.4220 - val_loss: 0.2093 - val_mae: 0.5315 - val_mse: 0.4447\n",
            "Epoch 456/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1945 - mae: 0.4980 - mse: 0.4211 - val_loss: 0.2089 - val_mae: 0.5314 - val_mse: 0.4439\n",
            "Epoch 457/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1952 - mae: 0.4969 - mse: 0.4230 - val_loss: 0.2136 - val_mae: 0.5366 - val_mse: 0.4541\n",
            "Epoch 458/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1946 - mae: 0.4975 - mse: 0.4211 - val_loss: 0.2061 - val_mae: 0.5276 - val_mse: 0.4384\n",
            "Epoch 459/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1944 - mae: 0.4973 - mse: 0.4211 - val_loss: 0.2228 - val_mae: 0.5490 - val_mse: 0.4738\n",
            "Epoch 460/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1941 - mae: 0.4969 - mse: 0.4199 - val_loss: 0.2113 - val_mae: 0.5342 - val_mse: 0.4493\n",
            "Epoch 461/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1944 - mae: 0.4966 - mse: 0.4205 - val_loss: 0.2359 - val_mae: 0.5652 - val_mse: 0.5032\n",
            "Epoch 462/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1943 - mae: 0.4969 - mse: 0.4207 - val_loss: 0.2260 - val_mae: 0.5528 - val_mse: 0.4819\n",
            "Epoch 463/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1940 - mae: 0.4970 - mse: 0.4195 - val_loss: 0.2173 - val_mae: 0.5422 - val_mse: 0.4627\n",
            "Epoch 464/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1938 - mae: 0.4964 - mse: 0.4200 - val_loss: 0.2179 - val_mae: 0.5431 - val_mse: 0.4634\n",
            "Epoch 465/800\n",
            "97/97 [==============================] - 1s 6ms/step - loss: 0.1935 - mae: 0.4954 - mse: 0.4183 - val_loss: 0.2124 - val_mae: 0.5360 - val_mse: 0.4516\n",
            "Epoch 466/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1932 - mae: 0.4948 - mse: 0.4189 - val_loss: 0.2181 - val_mae: 0.5430 - val_mse: 0.4646\n",
            "Epoch 467/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1950 - mae: 0.4989 - mse: 0.4224 - val_loss: 0.2222 - val_mae: 0.5483 - val_mse: 0.4724\n",
            "Epoch 468/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1942 - mae: 0.4967 - mse: 0.4210 - val_loss: 0.2327 - val_mae: 0.5619 - val_mse: 0.4956\n",
            "Epoch 469/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1944 - mae: 0.4974 - mse: 0.4209 - val_loss: 0.2142 - val_mae: 0.5378 - val_mse: 0.4550\n",
            "Epoch 470/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1934 - mae: 0.4960 - mse: 0.4189 - val_loss: 0.2345 - val_mae: 0.5642 - val_mse: 0.4997\n",
            "Epoch 471/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1925 - mae: 0.4957 - mse: 0.4167 - val_loss: 0.2160 - val_mae: 0.5398 - val_mse: 0.4597\n",
            "Epoch 472/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1938 - mae: 0.4957 - mse: 0.4195 - val_loss: 0.2052 - val_mae: 0.5263 - val_mse: 0.4362\n",
            "Epoch 473/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1935 - mae: 0.4944 - mse: 0.4186 - val_loss: 0.2091 - val_mae: 0.5313 - val_mse: 0.4438\n",
            "Epoch 474/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1931 - mae: 0.4946 - mse: 0.4184 - val_loss: 0.2068 - val_mae: 0.5292 - val_mse: 0.4400\n",
            "Epoch 475/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1931 - mae: 0.4959 - mse: 0.4179 - val_loss: 0.2072 - val_mae: 0.5289 - val_mse: 0.4404\n",
            "Epoch 476/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1930 - mae: 0.4944 - mse: 0.4176 - val_loss: 0.2197 - val_mae: 0.5443 - val_mse: 0.4674\n",
            "Epoch 477/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1931 - mae: 0.4963 - mse: 0.4172 - val_loss: 0.2238 - val_mae: 0.5497 - val_mse: 0.4766\n",
            "Epoch 478/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1929 - mae: 0.4955 - mse: 0.4175 - val_loss: 0.2144 - val_mae: 0.5383 - val_mse: 0.4560\n",
            "Epoch 479/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1930 - mae: 0.4952 - mse: 0.4175 - val_loss: 0.2141 - val_mae: 0.5368 - val_mse: 0.4557\n",
            "Epoch 480/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1938 - mae: 0.4967 - mse: 0.4206 - val_loss: 0.2144 - val_mae: 0.5380 - val_mse: 0.4563\n",
            "Epoch 481/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1937 - mae: 0.4969 - mse: 0.4186 - val_loss: 0.2137 - val_mae: 0.5373 - val_mse: 0.4547\n",
            "Epoch 482/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1940 - mae: 0.4960 - mse: 0.4201 - val_loss: 0.2066 - val_mae: 0.5282 - val_mse: 0.4394\n",
            "Epoch 483/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1936 - mae: 0.4967 - mse: 0.4187 - val_loss: 0.2169 - val_mae: 0.5412 - val_mse: 0.4611\n",
            "Epoch 484/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1926 - mae: 0.4950 - mse: 0.4172 - val_loss: 0.2090 - val_mae: 0.5322 - val_mse: 0.4450\n",
            "Epoch 485/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1934 - mae: 0.4945 - mse: 0.4189 - val_loss: 0.2149 - val_mae: 0.5393 - val_mse: 0.4569\n",
            "Epoch 486/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1939 - mae: 0.4974 - mse: 0.4204 - val_loss: 0.2349 - val_mae: 0.5643 - val_mse: 0.5016\n",
            "Epoch 487/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1931 - mae: 0.4955 - mse: 0.4176 - val_loss: 0.2173 - val_mae: 0.5414 - val_mse: 0.4624\n",
            "Epoch 488/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1936 - mae: 0.4961 - mse: 0.4195 - val_loss: 0.2375 - val_mae: 0.5673 - val_mse: 0.5073\n",
            "Epoch 489/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1927 - mae: 0.4941 - mse: 0.4168 - val_loss: 0.2440 - val_mae: 0.5759 - val_mse: 0.5228\n",
            "Epoch 490/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1936 - mae: 0.4962 - mse: 0.4193 - val_loss: 0.2098 - val_mae: 0.5320 - val_mse: 0.4464\n",
            "Epoch 491/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1927 - mae: 0.4952 - mse: 0.4168 - val_loss: 0.2175 - val_mae: 0.5416 - val_mse: 0.4624\n",
            "Epoch 492/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1920 - mae: 0.4945 - mse: 0.4160 - val_loss: 0.2236 - val_mae: 0.5492 - val_mse: 0.4759\n",
            "Epoch 493/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1929 - mae: 0.4960 - mse: 0.4182 - val_loss: 0.2221 - val_mae: 0.5476 - val_mse: 0.4728\n",
            "Epoch 494/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1924 - mae: 0.4932 - mse: 0.4161 - val_loss: 0.2272 - val_mae: 0.5537 - val_mse: 0.4843\n",
            "Epoch 495/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1916 - mae: 0.4929 - mse: 0.4153 - val_loss: 0.2465 - val_mae: 0.5790 - val_mse: 0.5275\n",
            "Epoch 496/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1924 - mae: 0.4942 - mse: 0.4168 - val_loss: 0.2341 - val_mae: 0.5637 - val_mse: 0.4992\n",
            "Epoch 497/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1926 - mae: 0.4944 - mse: 0.4169 - val_loss: 0.2191 - val_mae: 0.5435 - val_mse: 0.4655\n",
            "Epoch 498/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1922 - mae: 0.4933 - mse: 0.4169 - val_loss: 0.2258 - val_mae: 0.5523 - val_mse: 0.4807\n",
            "Epoch 499/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1920 - mae: 0.4938 - mse: 0.4160 - val_loss: 0.2063 - val_mae: 0.5265 - val_mse: 0.4382\n",
            "Epoch 500/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1921 - mae: 0.4933 - mse: 0.4159 - val_loss: 0.2404 - val_mae: 0.5712 - val_mse: 0.5139\n",
            "Epoch 501/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1919 - mae: 0.4934 - mse: 0.4154 - val_loss: 0.2406 - val_mae: 0.5722 - val_mse: 0.5140\n",
            "Epoch 502/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1909 - mae: 0.4916 - mse: 0.4136 - val_loss: 0.2109 - val_mae: 0.5324 - val_mse: 0.4480\n",
            "Epoch 503/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1922 - mae: 0.4946 - mse: 0.4161 - val_loss: 0.2194 - val_mae: 0.5443 - val_mse: 0.4672\n",
            "Epoch 504/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1920 - mae: 0.4939 - mse: 0.4163 - val_loss: 0.2374 - val_mae: 0.5675 - val_mse: 0.5067\n",
            "Epoch 505/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1923 - mae: 0.4940 - mse: 0.4162 - val_loss: 0.2303 - val_mae: 0.5588 - val_mse: 0.4905\n",
            "Epoch 506/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1917 - mae: 0.4944 - mse: 0.4143 - val_loss: 0.2264 - val_mae: 0.5526 - val_mse: 0.4823\n",
            "Epoch 507/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1914 - mae: 0.4929 - mse: 0.4148 - val_loss: 0.2194 - val_mae: 0.5434 - val_mse: 0.4670\n",
            "Epoch 508/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1909 - mae: 0.4925 - mse: 0.4123 - val_loss: 0.2376 - val_mae: 0.5698 - val_mse: 0.5061\n",
            "Epoch 509/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1916 - mae: 0.4938 - mse: 0.4148 - val_loss: 0.2371 - val_mae: 0.5674 - val_mse: 0.5058\n",
            "Epoch 510/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1912 - mae: 0.4935 - mse: 0.4135 - val_loss: 0.2097 - val_mae: 0.5313 - val_mse: 0.4457\n",
            "Epoch 511/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1919 - mae: 0.4947 - mse: 0.4158 - val_loss: 0.2226 - val_mae: 0.5482 - val_mse: 0.4729\n",
            "Epoch 512/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1914 - mae: 0.4926 - mse: 0.4148 - val_loss: 0.2123 - val_mae: 0.5348 - val_mse: 0.4514\n",
            "Epoch 513/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1916 - mae: 0.4935 - mse: 0.4150 - val_loss: 0.2093 - val_mae: 0.5299 - val_mse: 0.4444\n",
            "Epoch 514/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1917 - mae: 0.4933 - mse: 0.4157 - val_loss: 0.2440 - val_mae: 0.5771 - val_mse: 0.5216\n",
            "Epoch 515/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1915 - mae: 0.4934 - mse: 0.4138 - val_loss: 0.2096 - val_mae: 0.5307 - val_mse: 0.4453\n",
            "Epoch 516/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1920 - mae: 0.4935 - mse: 0.4163 - val_loss: 0.2326 - val_mae: 0.5610 - val_mse: 0.4957\n",
            "Epoch 517/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1908 - mae: 0.4908 - mse: 0.4132 - val_loss: 0.2447 - val_mae: 0.5777 - val_mse: 0.5227\n",
            "Epoch 518/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1910 - mae: 0.4921 - mse: 0.4137 - val_loss: 0.2271 - val_mae: 0.5545 - val_mse: 0.4837\n",
            "Epoch 519/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1908 - mae: 0.4927 - mse: 0.4127 - val_loss: 0.2303 - val_mae: 0.5584 - val_mse: 0.4907\n",
            "Epoch 520/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1913 - mae: 0.4934 - mse: 0.4143 - val_loss: 0.2115 - val_mae: 0.5336 - val_mse: 0.4491\n",
            "Epoch 521/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1907 - mae: 0.4931 - mse: 0.4131 - val_loss: 0.2289 - val_mae: 0.5567 - val_mse: 0.4877\n",
            "Epoch 522/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1920 - mae: 0.4941 - mse: 0.4150 - val_loss: 0.2141 - val_mae: 0.5373 - val_mse: 0.4560\n",
            "Epoch 523/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1901 - mae: 0.4901 - mse: 0.4115 - val_loss: 0.2096 - val_mae: 0.5311 - val_mse: 0.4456\n",
            "Epoch 524/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1908 - mae: 0.4908 - mse: 0.4131 - val_loss: 0.2264 - val_mae: 0.5537 - val_mse: 0.4821\n",
            "Epoch 525/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1907 - mae: 0.4924 - mse: 0.4133 - val_loss: 0.2099 - val_mae: 0.5308 - val_mse: 0.4465\n",
            "Epoch 526/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1900 - mae: 0.4917 - mse: 0.4109 - val_loss: 0.2091 - val_mae: 0.5299 - val_mse: 0.4441\n",
            "Epoch 527/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1904 - mae: 0.4914 - mse: 0.4119 - val_loss: 0.2114 - val_mae: 0.5346 - val_mse: 0.4502\n",
            "Epoch 528/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1909 - mae: 0.4920 - mse: 0.4139 - val_loss: 0.2311 - val_mae: 0.5606 - val_mse: 0.4925\n",
            "Epoch 529/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1902 - mae: 0.4920 - mse: 0.4114 - val_loss: 0.2310 - val_mae: 0.5601 - val_mse: 0.4929\n",
            "Epoch 530/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1901 - mae: 0.4913 - mse: 0.4114 - val_loss: 0.2797 - val_mae: 0.6223 - val_mse: 0.6048\n",
            "Epoch 531/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1903 - mae: 0.4927 - mse: 0.4118 - val_loss: 0.2108 - val_mae: 0.5323 - val_mse: 0.4486\n",
            "Epoch 532/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1902 - mae: 0.4925 - mse: 0.4117 - val_loss: 0.2164 - val_mae: 0.5410 - val_mse: 0.4602\n",
            "Epoch 533/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1898 - mae: 0.4907 - mse: 0.4103 - val_loss: 0.2332 - val_mae: 0.5634 - val_mse: 0.4968\n",
            "Epoch 534/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1904 - mae: 0.4923 - mse: 0.4119 - val_loss: 0.2107 - val_mae: 0.5329 - val_mse: 0.4483\n",
            "Epoch 535/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1901 - mae: 0.4922 - mse: 0.4118 - val_loss: 0.2153 - val_mae: 0.5386 - val_mse: 0.4577\n",
            "Epoch 536/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1903 - mae: 0.4928 - mse: 0.4118 - val_loss: 0.2370 - val_mae: 0.5672 - val_mse: 0.5061\n",
            "Epoch 537/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1898 - mae: 0.4908 - mse: 0.4105 - val_loss: 0.2090 - val_mae: 0.5313 - val_mse: 0.4451\n",
            "Epoch 538/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1906 - mae: 0.4917 - mse: 0.4133 - val_loss: 0.2129 - val_mae: 0.5352 - val_mse: 0.4520\n",
            "Epoch 539/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1904 - mae: 0.4924 - mse: 0.4119 - val_loss: 0.2234 - val_mae: 0.5490 - val_mse: 0.4760\n",
            "Epoch 540/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1899 - mae: 0.4909 - mse: 0.4110 - val_loss: 0.2189 - val_mae: 0.5435 - val_mse: 0.4652\n",
            "Epoch 541/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1898 - mae: 0.4914 - mse: 0.4106 - val_loss: 0.2165 - val_mae: 0.5401 - val_mse: 0.4603\n",
            "Epoch 542/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1898 - mae: 0.4908 - mse: 0.4112 - val_loss: 0.2124 - val_mae: 0.5345 - val_mse: 0.4514\n",
            "Epoch 543/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1893 - mae: 0.4895 - mse: 0.4092 - val_loss: 0.2118 - val_mae: 0.5334 - val_mse: 0.4503\n",
            "Epoch 544/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1898 - mae: 0.4909 - mse: 0.4102 - val_loss: 0.2308 - val_mae: 0.5588 - val_mse: 0.4921\n",
            "Epoch 545/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1890 - mae: 0.4885 - mse: 0.4094 - val_loss: 0.2247 - val_mae: 0.5526 - val_mse: 0.4782\n",
            "Epoch 546/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1894 - mae: 0.4896 - mse: 0.4095 - val_loss: 0.2332 - val_mae: 0.5640 - val_mse: 0.4971\n",
            "Epoch 547/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1891 - mae: 0.4904 - mse: 0.4093 - val_loss: 0.2080 - val_mae: 0.5283 - val_mse: 0.4427\n",
            "Epoch 548/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1886 - mae: 0.4907 - mse: 0.4084 - val_loss: 0.2171 - val_mae: 0.5409 - val_mse: 0.4620\n",
            "Epoch 549/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1893 - mae: 0.4905 - mse: 0.4097 - val_loss: 0.2252 - val_mae: 0.5512 - val_mse: 0.4798\n",
            "Epoch 550/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1891 - mae: 0.4893 - mse: 0.4096 - val_loss: 0.2116 - val_mae: 0.5334 - val_mse: 0.4498\n",
            "Epoch 551/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1889 - mae: 0.4890 - mse: 0.4088 - val_loss: 0.2381 - val_mae: 0.5702 - val_mse: 0.5080\n",
            "Epoch 552/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1888 - mae: 0.4899 - mse: 0.4080 - val_loss: 0.2204 - val_mae: 0.5458 - val_mse: 0.4696\n",
            "Epoch 553/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1892 - mae: 0.4901 - mse: 0.4095 - val_loss: 0.2515 - val_mae: 0.5871 - val_mse: 0.5387\n",
            "Epoch 554/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1884 - mae: 0.4884 - mse: 0.4083 - val_loss: 0.2237 - val_mae: 0.5499 - val_mse: 0.4762\n",
            "Epoch 555/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1891 - mae: 0.4902 - mse: 0.4091 - val_loss: 0.2385 - val_mae: 0.5701 - val_mse: 0.5098\n",
            "Epoch 556/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1884 - mae: 0.4891 - mse: 0.4081 - val_loss: 0.2376 - val_mae: 0.5684 - val_mse: 0.5075\n",
            "Epoch 557/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1890 - mae: 0.4903 - mse: 0.4087 - val_loss: 0.2178 - val_mae: 0.5421 - val_mse: 0.4633\n",
            "Epoch 558/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1884 - mae: 0.4889 - mse: 0.4081 - val_loss: 0.2226 - val_mae: 0.5489 - val_mse: 0.4736\n",
            "Epoch 559/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1892 - mae: 0.4911 - mse: 0.4096 - val_loss: 0.2327 - val_mae: 0.5620 - val_mse: 0.4963\n",
            "Epoch 560/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1884 - mae: 0.4887 - mse: 0.4078 - val_loss: 0.2295 - val_mae: 0.5588 - val_mse: 0.4892\n",
            "Epoch 561/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1885 - mae: 0.4900 - mse: 0.4084 - val_loss: 0.2122 - val_mae: 0.5343 - val_mse: 0.4511\n",
            "Epoch 562/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1877 - mae: 0.4878 - mse: 0.4065 - val_loss: 0.2143 - val_mae: 0.5374 - val_mse: 0.4554\n",
            "Epoch 563/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1877 - mae: 0.4893 - mse: 0.4056 - val_loss: 0.2198 - val_mae: 0.5441 - val_mse: 0.4685\n",
            "Epoch 564/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1881 - mae: 0.4883 - mse: 0.4069 - val_loss: 0.2208 - val_mae: 0.5465 - val_mse: 0.4696\n",
            "Epoch 565/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1884 - mae: 0.4892 - mse: 0.4078 - val_loss: 0.2238 - val_mae: 0.5514 - val_mse: 0.4766\n",
            "Epoch 566/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1887 - mae: 0.4897 - mse: 0.4089 - val_loss: 0.2332 - val_mae: 0.5637 - val_mse: 0.4976\n",
            "Epoch 567/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1878 - mae: 0.4888 - mse: 0.4070 - val_loss: 0.2214 - val_mae: 0.5470 - val_mse: 0.4711\n",
            "Epoch 568/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1878 - mae: 0.4874 - mse: 0.4063 - val_loss: 0.2305 - val_mae: 0.5589 - val_mse: 0.4920\n",
            "Epoch 569/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1879 - mae: 0.4882 - mse: 0.4067 - val_loss: 0.2151 - val_mae: 0.5383 - val_mse: 0.4573\n",
            "Epoch 570/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1877 - mae: 0.4884 - mse: 0.4065 - val_loss: 0.2213 - val_mae: 0.5483 - val_mse: 0.4708\n",
            "Epoch 571/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1883 - mae: 0.4895 - mse: 0.4077 - val_loss: 0.2239 - val_mae: 0.5507 - val_mse: 0.4770\n",
            "Epoch 572/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1872 - mae: 0.4868 - mse: 0.4050 - val_loss: 0.2152 - val_mae: 0.5388 - val_mse: 0.4575\n",
            "Epoch 573/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1869 - mae: 0.4862 - mse: 0.4044 - val_loss: 0.2517 - val_mae: 0.5891 - val_mse: 0.5390\n",
            "Epoch 574/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1882 - mae: 0.4888 - mse: 0.4079 - val_loss: 0.2454 - val_mae: 0.5798 - val_mse: 0.5248\n",
            "Epoch 575/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1882 - mae: 0.4890 - mse: 0.4073 - val_loss: 0.2103 - val_mae: 0.5314 - val_mse: 0.4470\n",
            "Epoch 576/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1878 - mae: 0.4890 - mse: 0.4067 - val_loss: 0.2389 - val_mae: 0.5707 - val_mse: 0.5108\n",
            "Epoch 577/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1880 - mae: 0.4886 - mse: 0.4069 - val_loss: 0.2300 - val_mae: 0.5611 - val_mse: 0.4897\n",
            "Epoch 578/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1874 - mae: 0.4877 - mse: 0.4056 - val_loss: 0.2211 - val_mae: 0.5467 - val_mse: 0.4708\n",
            "Epoch 579/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1865 - mae: 0.4865 - mse: 0.4033 - val_loss: 0.2265 - val_mae: 0.5539 - val_mse: 0.4832\n",
            "Epoch 580/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1866 - mae: 0.4868 - mse: 0.4034 - val_loss: 0.2448 - val_mae: 0.5801 - val_mse: 0.5234\n",
            "Epoch 581/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1871 - mae: 0.4877 - mse: 0.4047 - val_loss: 0.2258 - val_mae: 0.5534 - val_mse: 0.4815\n",
            "Epoch 582/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1874 - mae: 0.4890 - mse: 0.4058 - val_loss: 0.2475 - val_mae: 0.5821 - val_mse: 0.5301\n",
            "Epoch 583/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1873 - mae: 0.4877 - mse: 0.4051 - val_loss: 0.2163 - val_mae: 0.5402 - val_mse: 0.4603\n",
            "Epoch 584/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1866 - mae: 0.4851 - mse: 0.4043 - val_loss: 0.2372 - val_mae: 0.5699 - val_mse: 0.5065\n",
            "Epoch 585/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1863 - mae: 0.4860 - mse: 0.4031 - val_loss: 0.2406 - val_mae: 0.5737 - val_mse: 0.5143\n",
            "Epoch 586/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1875 - mae: 0.4890 - mse: 0.4059 - val_loss: 0.2127 - val_mae: 0.5346 - val_mse: 0.4523\n",
            "Epoch 587/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1867 - mae: 0.4861 - mse: 0.4044 - val_loss: 0.2186 - val_mae: 0.5439 - val_mse: 0.4649\n",
            "Epoch 588/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1869 - mae: 0.4877 - mse: 0.4049 - val_loss: 0.2468 - val_mae: 0.5810 - val_mse: 0.5288\n",
            "Epoch 589/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1870 - mae: 0.4851 - mse: 0.4055 - val_loss: 0.2434 - val_mae: 0.5777 - val_mse: 0.5210\n",
            "Epoch 590/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1863 - mae: 0.4871 - mse: 0.4026 - val_loss: 0.2144 - val_mae: 0.5370 - val_mse: 0.4564\n",
            "Epoch 591/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1867 - mae: 0.4866 - mse: 0.4035 - val_loss: 0.2333 - val_mae: 0.5640 - val_mse: 0.4977\n",
            "Epoch 592/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1856 - mae: 0.4844 - mse: 0.4018 - val_loss: 0.2142 - val_mae: 0.5364 - val_mse: 0.4558\n",
            "Epoch 593/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1858 - mae: 0.4860 - mse: 0.4021 - val_loss: 0.2247 - val_mae: 0.5529 - val_mse: 0.4786\n",
            "Epoch 594/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1861 - mae: 0.4868 - mse: 0.4021 - val_loss: 0.2249 - val_mae: 0.5522 - val_mse: 0.4792\n",
            "Epoch 595/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1862 - mae: 0.4864 - mse: 0.4040 - val_loss: 0.2147 - val_mae: 0.5371 - val_mse: 0.4568\n",
            "Epoch 596/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1859 - mae: 0.4841 - mse: 0.4019 - val_loss: 0.2144 - val_mae: 0.5375 - val_mse: 0.4563\n",
            "Epoch 597/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1856 - mae: 0.4846 - mse: 0.4018 - val_loss: 0.2480 - val_mae: 0.5833 - val_mse: 0.5316\n",
            "Epoch 598/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1856 - mae: 0.4852 - mse: 0.4018 - val_loss: 0.2358 - val_mae: 0.5674 - val_mse: 0.5037\n",
            "Epoch 599/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1867 - mae: 0.4861 - mse: 0.4039 - val_loss: 0.2271 - val_mae: 0.5567 - val_mse: 0.4835\n",
            "Epoch 600/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1851 - mae: 0.4850 - mse: 0.4010 - val_loss: 0.2189 - val_mae: 0.5431 - val_mse: 0.4666\n",
            "Epoch 601/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1861 - mae: 0.4860 - mse: 0.4032 - val_loss: 0.2143 - val_mae: 0.5374 - val_mse: 0.4557\n",
            "Epoch 602/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1851 - mae: 0.4848 - mse: 0.4014 - val_loss: 0.2568 - val_mae: 0.5951 - val_mse: 0.5512\n",
            "Epoch 603/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1863 - mae: 0.4865 - mse: 0.4034 - val_loss: 0.2170 - val_mae: 0.5410 - val_mse: 0.4618\n",
            "Epoch 604/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1854 - mae: 0.4848 - mse: 0.4008 - val_loss: 0.2172 - val_mae: 0.5418 - val_mse: 0.4619\n",
            "Epoch 605/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1860 - mae: 0.4859 - mse: 0.4021 - val_loss: 0.2196 - val_mae: 0.5452 - val_mse: 0.4675\n",
            "Epoch 606/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1853 - mae: 0.4860 - mse: 0.4001 - val_loss: 0.2221 - val_mae: 0.5489 - val_mse: 0.4728\n",
            "Epoch 607/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1858 - mae: 0.4850 - mse: 0.4020 - val_loss: 0.2199 - val_mae: 0.5449 - val_mse: 0.4687\n",
            "Epoch 608/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1858 - mae: 0.4857 - mse: 0.4021 - val_loss: 0.2493 - val_mae: 0.5860 - val_mse: 0.5341\n",
            "Epoch 609/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1852 - mae: 0.4843 - mse: 0.4010 - val_loss: 0.2095 - val_mae: 0.5290 - val_mse: 0.4453\n",
            "Epoch 610/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1852 - mae: 0.4858 - mse: 0.4000 - val_loss: 0.2206 - val_mae: 0.5455 - val_mse: 0.4698\n",
            "Epoch 611/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1862 - mae: 0.4856 - mse: 0.4028 - val_loss: 0.2229 - val_mae: 0.5495 - val_mse: 0.4749\n",
            "Epoch 612/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1848 - mae: 0.4839 - mse: 0.4002 - val_loss: 0.2350 - val_mae: 0.5667 - val_mse: 0.5016\n",
            "Epoch 613/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1854 - mae: 0.4856 - mse: 0.4013 - val_loss: 0.2255 - val_mae: 0.5538 - val_mse: 0.4803\n",
            "Epoch 614/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1861 - mae: 0.4860 - mse: 0.4026 - val_loss: 0.2324 - val_mae: 0.5635 - val_mse: 0.4953\n",
            "Epoch 615/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1852 - mae: 0.4847 - mse: 0.4006 - val_loss: 0.2289 - val_mae: 0.5578 - val_mse: 0.4878\n",
            "Epoch 616/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1853 - mae: 0.4855 - mse: 0.4012 - val_loss: 0.2521 - val_mae: 0.5897 - val_mse: 0.5402\n",
            "Epoch 617/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1852 - mae: 0.4851 - mse: 0.4009 - val_loss: 0.2121 - val_mae: 0.5337 - val_mse: 0.4518\n",
            "Epoch 618/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1852 - mae: 0.4849 - mse: 0.4007 - val_loss: 0.2113 - val_mae: 0.5325 - val_mse: 0.4494\n",
            "Epoch 619/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1847 - mae: 0.4843 - mse: 0.3991 - val_loss: 0.2273 - val_mae: 0.5557 - val_mse: 0.4849\n",
            "Epoch 620/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1854 - mae: 0.4859 - mse: 0.4021 - val_loss: 0.2167 - val_mae: 0.5409 - val_mse: 0.4615\n",
            "Epoch 621/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1857 - mae: 0.4866 - mse: 0.4020 - val_loss: 0.2312 - val_mae: 0.5612 - val_mse: 0.4936\n",
            "Epoch 622/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1847 - mae: 0.4845 - mse: 0.3991 - val_loss: 0.2135 - val_mae: 0.5374 - val_mse: 0.4539\n",
            "Epoch 623/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1847 - mae: 0.4836 - mse: 0.3999 - val_loss: 0.2391 - val_mae: 0.5723 - val_mse: 0.5115\n",
            "Epoch 624/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1847 - mae: 0.4842 - mse: 0.3997 - val_loss: 0.2172 - val_mae: 0.5408 - val_mse: 0.4625\n",
            "Epoch 625/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1846 - mae: 0.4842 - mse: 0.4000 - val_loss: 0.2238 - val_mae: 0.5517 - val_mse: 0.4766\n",
            "Epoch 626/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1852 - mae: 0.4850 - mse: 0.4011 - val_loss: 0.2223 - val_mae: 0.5496 - val_mse: 0.4732\n",
            "Epoch 627/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1847 - mae: 0.4839 - mse: 0.3995 - val_loss: 0.2200 - val_mae: 0.5457 - val_mse: 0.4681\n",
            "Epoch 628/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1839 - mae: 0.4821 - mse: 0.3982 - val_loss: 0.2391 - val_mae: 0.5726 - val_mse: 0.5110\n",
            "Epoch 629/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1842 - mae: 0.4837 - mse: 0.3980 - val_loss: 0.2285 - val_mae: 0.5581 - val_mse: 0.4871\n",
            "Epoch 630/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1847 - mae: 0.4843 - mse: 0.3993 - val_loss: 0.2336 - val_mae: 0.5649 - val_mse: 0.4984\n",
            "Epoch 631/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1841 - mae: 0.4840 - mse: 0.3993 - val_loss: 0.2270 - val_mae: 0.5565 - val_mse: 0.4838\n",
            "Epoch 632/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1841 - mae: 0.4825 - mse: 0.3984 - val_loss: 0.2182 - val_mae: 0.5422 - val_mse: 0.4643\n",
            "Epoch 633/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1840 - mae: 0.4843 - mse: 0.3977 - val_loss: 0.2387 - val_mae: 0.5715 - val_mse: 0.5102\n",
            "Epoch 634/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1846 - mae: 0.4834 - mse: 0.3993 - val_loss: 0.2257 - val_mae: 0.5542 - val_mse: 0.4811\n",
            "Epoch 635/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1841 - mae: 0.4841 - mse: 0.3981 - val_loss: 0.2348 - val_mae: 0.5655 - val_mse: 0.5020\n",
            "Epoch 636/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1839 - mae: 0.4818 - mse: 0.3976 - val_loss: 0.2180 - val_mae: 0.5443 - val_mse: 0.4637\n",
            "Epoch 637/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1834 - mae: 0.4824 - mse: 0.3969 - val_loss: 0.2213 - val_mae: 0.5468 - val_mse: 0.4718\n",
            "Epoch 638/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1835 - mae: 0.4829 - mse: 0.3958 - val_loss: 0.2221 - val_mae: 0.5480 - val_mse: 0.4739\n",
            "Epoch 639/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1839 - mae: 0.4827 - mse: 0.3974 - val_loss: 0.2176 - val_mae: 0.5419 - val_mse: 0.4633\n",
            "Epoch 640/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1836 - mae: 0.4817 - mse: 0.3967 - val_loss: 0.2163 - val_mae: 0.5400 - val_mse: 0.4609\n",
            "Epoch 641/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1829 - mae: 0.4805 - mse: 0.3961 - val_loss: 0.2223 - val_mae: 0.5495 - val_mse: 0.4737\n",
            "Epoch 642/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1836 - mae: 0.4830 - mse: 0.3966 - val_loss: 0.2377 - val_mae: 0.5700 - val_mse: 0.5075\n",
            "Epoch 643/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1835 - mae: 0.4828 - mse: 0.3964 - val_loss: 0.2393 - val_mae: 0.5716 - val_mse: 0.5117\n",
            "Epoch 644/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1837 - mae: 0.4815 - mse: 0.3979 - val_loss: 0.2309 - val_mae: 0.5615 - val_mse: 0.4924\n",
            "Epoch 645/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1832 - mae: 0.4835 - mse: 0.3956 - val_loss: 0.2123 - val_mae: 0.5329 - val_mse: 0.4516\n",
            "Epoch 646/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1837 - mae: 0.4830 - mse: 0.3970 - val_loss: 0.2225 - val_mae: 0.5494 - val_mse: 0.4747\n",
            "Epoch 647/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1828 - mae: 0.4808 - mse: 0.3956 - val_loss: 0.2256 - val_mae: 0.5551 - val_mse: 0.4805\n",
            "Epoch 648/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1832 - mae: 0.4826 - mse: 0.3962 - val_loss: 0.2266 - val_mae: 0.5552 - val_mse: 0.4830\n",
            "Epoch 649/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1830 - mae: 0.4810 - mse: 0.3951 - val_loss: 0.2230 - val_mae: 0.5502 - val_mse: 0.4748\n",
            "Epoch 650/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1835 - mae: 0.4831 - mse: 0.3968 - val_loss: 0.2277 - val_mae: 0.5579 - val_mse: 0.4849\n",
            "Epoch 651/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1838 - mae: 0.4837 - mse: 0.3980 - val_loss: 0.2300 - val_mae: 0.5593 - val_mse: 0.4907\n",
            "Epoch 652/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1829 - mae: 0.4811 - mse: 0.3958 - val_loss: 0.2212 - val_mae: 0.5478 - val_mse: 0.4710\n",
            "Epoch 653/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1828 - mae: 0.4823 - mse: 0.3953 - val_loss: 0.2279 - val_mae: 0.5565 - val_mse: 0.4861\n",
            "Epoch 654/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1822 - mae: 0.4807 - mse: 0.3945 - val_loss: 0.2453 - val_mae: 0.5822 - val_mse: 0.5245\n",
            "Epoch 655/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1830 - mae: 0.4823 - mse: 0.3953 - val_loss: 0.2251 - val_mae: 0.5528 - val_mse: 0.4799\n",
            "Epoch 656/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1821 - mae: 0.4808 - mse: 0.3943 - val_loss: 0.2128 - val_mae: 0.5337 - val_mse: 0.4519\n",
            "Epoch 657/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1834 - mae: 0.4827 - mse: 0.3961 - val_loss: 0.2349 - val_mae: 0.5669 - val_mse: 0.5014\n",
            "Epoch 658/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1827 - mae: 0.4813 - mse: 0.3952 - val_loss: 0.2289 - val_mae: 0.5584 - val_mse: 0.4881\n",
            "Epoch 659/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1829 - mae: 0.4821 - mse: 0.3958 - val_loss: 0.2308 - val_mae: 0.5596 - val_mse: 0.4929\n",
            "Epoch 660/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1830 - mae: 0.4819 - mse: 0.3958 - val_loss: 0.2274 - val_mae: 0.5564 - val_mse: 0.4849\n",
            "Epoch 661/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1823 - mae: 0.4800 - mse: 0.3950 - val_loss: 0.2197 - val_mae: 0.5462 - val_mse: 0.4677\n",
            "Epoch 662/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1824 - mae: 0.4813 - mse: 0.3942 - val_loss: 0.2387 - val_mae: 0.5729 - val_mse: 0.5105\n",
            "Epoch 663/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1815 - mae: 0.4803 - mse: 0.3927 - val_loss: 0.2368 - val_mae: 0.5691 - val_mse: 0.5058\n",
            "Epoch 664/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1826 - mae: 0.4804 - mse: 0.3952 - val_loss: 0.2338 - val_mae: 0.5646 - val_mse: 0.4992\n",
            "Epoch 665/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1835 - mae: 0.4816 - mse: 0.3967 - val_loss: 0.2363 - val_mae: 0.5696 - val_mse: 0.5044\n",
            "Epoch 666/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1821 - mae: 0.4801 - mse: 0.3937 - val_loss: 0.2185 - val_mae: 0.5431 - val_mse: 0.4652\n",
            "Epoch 667/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1824 - mae: 0.4810 - mse: 0.3941 - val_loss: 0.2143 - val_mae: 0.5371 - val_mse: 0.4554\n",
            "Epoch 668/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1825 - mae: 0.4817 - mse: 0.3953 - val_loss: 0.2460 - val_mae: 0.5835 - val_mse: 0.5267\n",
            "Epoch 669/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1822 - mae: 0.4814 - mse: 0.3932 - val_loss: 0.2282 - val_mae: 0.5590 - val_mse: 0.4863\n",
            "Epoch 670/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1815 - mae: 0.4811 - mse: 0.3919 - val_loss: 0.2287 - val_mae: 0.5588 - val_mse: 0.4875\n",
            "Epoch 671/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1824 - mae: 0.4806 - mse: 0.3943 - val_loss: 0.2255 - val_mae: 0.5529 - val_mse: 0.4811\n",
            "Epoch 672/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1812 - mae: 0.4783 - mse: 0.3912 - val_loss: 0.2584 - val_mae: 0.5997 - val_mse: 0.5556\n",
            "Epoch 673/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1816 - mae: 0.4798 - mse: 0.3927 - val_loss: 0.2146 - val_mae: 0.5370 - val_mse: 0.4565\n",
            "Epoch 674/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1820 - mae: 0.4811 - mse: 0.3937 - val_loss: 0.2434 - val_mae: 0.5799 - val_mse: 0.5208\n",
            "Epoch 675/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1829 - mae: 0.4828 - mse: 0.3949 - val_loss: 0.2468 - val_mae: 0.5841 - val_mse: 0.5287\n",
            "Epoch 676/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1816 - mae: 0.4796 - mse: 0.3932 - val_loss: 0.2273 - val_mae: 0.5584 - val_mse: 0.4842\n",
            "Epoch 677/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1818 - mae: 0.4808 - mse: 0.3945 - val_loss: 0.2391 - val_mae: 0.5737 - val_mse: 0.5112\n",
            "Epoch 678/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1818 - mae: 0.4813 - mse: 0.3932 - val_loss: 0.2280 - val_mae: 0.5587 - val_mse: 0.4860\n",
            "Epoch 679/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1816 - mae: 0.4793 - mse: 0.3929 - val_loss: 0.2251 - val_mae: 0.5532 - val_mse: 0.4804\n",
            "Epoch 680/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1818 - mae: 0.4808 - mse: 0.3922 - val_loss: 0.2220 - val_mae: 0.5496 - val_mse: 0.4727\n",
            "Epoch 681/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1811 - mae: 0.4790 - mse: 0.3911 - val_loss: 0.2451 - val_mae: 0.5810 - val_mse: 0.5254\n",
            "Epoch 682/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1821 - mae: 0.4807 - mse: 0.3935 - val_loss: 0.2229 - val_mae: 0.5505 - val_mse: 0.4746\n",
            "Epoch 683/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1806 - mae: 0.4790 - mse: 0.3903 - val_loss: 0.2261 - val_mae: 0.5540 - val_mse: 0.4820\n",
            "Epoch 684/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1805 - mae: 0.4781 - mse: 0.3898 - val_loss: 0.2177 - val_mae: 0.5424 - val_mse: 0.4632\n",
            "Epoch 685/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1815 - mae: 0.4797 - mse: 0.3931 - val_loss: 0.2317 - val_mae: 0.5628 - val_mse: 0.4950\n",
            "Epoch 686/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1819 - mae: 0.4811 - mse: 0.3938 - val_loss: 0.2176 - val_mae: 0.5431 - val_mse: 0.4630\n",
            "Epoch 687/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1807 - mae: 0.4793 - mse: 0.3905 - val_loss: 0.2318 - val_mae: 0.5617 - val_mse: 0.4954\n",
            "Epoch 688/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1812 - mae: 0.4798 - mse: 0.3920 - val_loss: 0.2172 - val_mae: 0.5416 - val_mse: 0.4627\n",
            "Epoch 689/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1812 - mae: 0.4786 - mse: 0.3912 - val_loss: 0.2153 - val_mae: 0.5385 - val_mse: 0.4581\n",
            "Epoch 690/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1802 - mae: 0.4792 - mse: 0.3890 - val_loss: 0.2528 - val_mae: 0.5931 - val_mse: 0.5431\n",
            "Epoch 691/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1807 - mae: 0.4784 - mse: 0.3899 - val_loss: 0.2161 - val_mae: 0.5396 - val_mse: 0.4599\n",
            "Epoch 692/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1808 - mae: 0.4779 - mse: 0.3910 - val_loss: 0.2417 - val_mae: 0.5780 - val_mse: 0.5167\n",
            "Epoch 693/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1806 - mae: 0.4791 - mse: 0.3896 - val_loss: 0.2476 - val_mae: 0.5841 - val_mse: 0.5306\n",
            "Epoch 694/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1801 - mae: 0.4776 - mse: 0.3886 - val_loss: 0.2382 - val_mae: 0.5729 - val_mse: 0.5091\n",
            "Epoch 695/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1804 - mae: 0.4777 - mse: 0.3903 - val_loss: 0.2134 - val_mae: 0.5357 - val_mse: 0.4542\n",
            "Epoch 696/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1795 - mae: 0.4772 - mse: 0.3882 - val_loss: 0.2090 - val_mae: 0.5253 - val_mse: 0.4451\n",
            "Epoch 697/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1806 - mae: 0.4782 - mse: 0.3906 - val_loss: 0.2423 - val_mae: 0.5780 - val_mse: 0.5193\n",
            "Epoch 698/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1802 - mae: 0.4766 - mse: 0.3893 - val_loss: 0.2906 - val_mae: 0.6437 - val_mse: 0.6294\n",
            "Epoch 699/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1797 - mae: 0.4765 - mse: 0.3887 - val_loss: 0.2285 - val_mae: 0.5591 - val_mse: 0.4873\n",
            "Epoch 700/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1811 - mae: 0.4799 - mse: 0.3912 - val_loss: 0.2182 - val_mae: 0.5426 - val_mse: 0.4652\n",
            "Epoch 701/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1808 - mae: 0.4779 - mse: 0.3907 - val_loss: 0.2237 - val_mae: 0.5514 - val_mse: 0.4774\n",
            "Epoch 702/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1801 - mae: 0.4767 - mse: 0.3894 - val_loss: 0.2099 - val_mae: 0.5284 - val_mse: 0.4466\n",
            "Epoch 703/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1804 - mae: 0.4785 - mse: 0.3896 - val_loss: 0.2283 - val_mae: 0.5591 - val_mse: 0.4863\n",
            "Epoch 704/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1796 - mae: 0.4773 - mse: 0.3872 - val_loss: 0.2471 - val_mae: 0.5859 - val_mse: 0.5287\n",
            "Epoch 705/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1802 - mae: 0.4789 - mse: 0.3891 - val_loss: 0.2267 - val_mae: 0.5558 - val_mse: 0.4830\n",
            "Epoch 706/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1800 - mae: 0.4764 - mse: 0.3889 - val_loss: 0.2238 - val_mae: 0.5515 - val_mse: 0.4772\n",
            "Epoch 707/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1801 - mae: 0.4772 - mse: 0.3891 - val_loss: 0.2377 - val_mae: 0.5717 - val_mse: 0.5080\n",
            "Epoch 708/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1795 - mae: 0.4770 - mse: 0.3886 - val_loss: 0.2470 - val_mae: 0.5836 - val_mse: 0.5300\n",
            "Epoch 709/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1809 - mae: 0.4789 - mse: 0.3905 - val_loss: 0.2277 - val_mae: 0.5573 - val_mse: 0.4864\n",
            "Epoch 710/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1801 - mae: 0.4775 - mse: 0.3894 - val_loss: 0.2355 - val_mae: 0.5697 - val_mse: 0.5035\n",
            "Epoch 711/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1797 - mae: 0.4770 - mse: 0.3886 - val_loss: 0.2113 - val_mae: 0.5300 - val_mse: 0.4498\n",
            "Epoch 712/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1801 - mae: 0.4777 - mse: 0.3891 - val_loss: 0.2497 - val_mae: 0.5890 - val_mse: 0.5354\n",
            "Epoch 713/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1790 - mae: 0.4761 - mse: 0.3872 - val_loss: 0.2253 - val_mae: 0.5538 - val_mse: 0.4806\n",
            "Epoch 714/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1807 - mae: 0.4792 - mse: 0.3904 - val_loss: 0.2342 - val_mae: 0.5664 - val_mse: 0.5004\n",
            "Epoch 715/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1791 - mae: 0.4767 - mse: 0.3865 - val_loss: 0.2464 - val_mae: 0.5851 - val_mse: 0.5279\n",
            "Epoch 716/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1793 - mae: 0.4768 - mse: 0.3880 - val_loss: 0.2285 - val_mae: 0.5592 - val_mse: 0.4873\n",
            "Epoch 717/800\n",
            "97/97 [==============================] - 1s 6ms/step - loss: 0.1800 - mae: 0.4775 - mse: 0.3891 - val_loss: 0.2424 - val_mae: 0.5788 - val_mse: 0.5189\n",
            "Epoch 718/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1801 - mae: 0.4779 - mse: 0.3887 - val_loss: 0.2450 - val_mae: 0.5826 - val_mse: 0.5250\n",
            "Epoch 719/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1797 - mae: 0.4768 - mse: 0.3877 - val_loss: 0.2407 - val_mae: 0.5774 - val_mse: 0.5147\n",
            "Epoch 720/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1791 - mae: 0.4766 - mse: 0.3867 - val_loss: 0.2433 - val_mae: 0.5784 - val_mse: 0.5209\n",
            "Epoch 721/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1793 - mae: 0.4766 - mse: 0.3869 - val_loss: 0.2147 - val_mae: 0.5371 - val_mse: 0.4576\n",
            "Epoch 722/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1792 - mae: 0.4754 - mse: 0.3869 - val_loss: 0.2221 - val_mae: 0.5495 - val_mse: 0.4732\n",
            "Epoch 723/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1791 - mae: 0.4769 - mse: 0.3871 - val_loss: 0.2562 - val_mae: 0.5982 - val_mse: 0.5502\n",
            "Epoch 724/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1793 - mae: 0.4776 - mse: 0.3874 - val_loss: 0.2190 - val_mae: 0.5447 - val_mse: 0.4666\n",
            "Epoch 725/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1791 - mae: 0.4756 - mse: 0.3869 - val_loss: 0.2370 - val_mae: 0.5712 - val_mse: 0.5070\n",
            "Epoch 726/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1788 - mae: 0.4760 - mse: 0.3862 - val_loss: 0.2273 - val_mae: 0.5571 - val_mse: 0.4855\n",
            "Epoch 727/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1791 - mae: 0.4765 - mse: 0.3869 - val_loss: 0.2195 - val_mae: 0.5454 - val_mse: 0.4679\n",
            "Epoch 728/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1791 - mae: 0.4760 - mse: 0.3864 - val_loss: 0.2161 - val_mae: 0.5404 - val_mse: 0.4598\n",
            "Epoch 729/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1802 - mae: 0.4769 - mse: 0.3899 - val_loss: 0.2327 - val_mae: 0.5662 - val_mse: 0.4969\n",
            "Epoch 730/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1797 - mae: 0.4779 - mse: 0.3881 - val_loss: 0.2333 - val_mae: 0.5655 - val_mse: 0.4987\n",
            "Epoch 731/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1784 - mae: 0.4759 - mse: 0.3859 - val_loss: 0.2349 - val_mae: 0.5688 - val_mse: 0.5023\n",
            "Epoch 732/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1781 - mae: 0.4745 - mse: 0.3844 - val_loss: 0.2126 - val_mae: 0.5322 - val_mse: 0.4532\n",
            "Epoch 733/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1795 - mae: 0.4770 - mse: 0.3871 - val_loss: 0.2328 - val_mae: 0.5659 - val_mse: 0.4964\n",
            "Epoch 734/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1777 - mae: 0.4746 - mse: 0.3833 - val_loss: 0.2223 - val_mae: 0.5500 - val_mse: 0.4735\n",
            "Epoch 735/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1787 - mae: 0.4751 - mse: 0.3861 - val_loss: 0.2296 - val_mae: 0.5600 - val_mse: 0.4907\n",
            "Epoch 736/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1789 - mae: 0.4763 - mse: 0.3863 - val_loss: 0.2164 - val_mae: 0.5386 - val_mse: 0.4619\n",
            "Epoch 737/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1775 - mae: 0.4733 - mse: 0.3832 - val_loss: 0.2515 - val_mae: 0.5908 - val_mse: 0.5401\n",
            "Epoch 738/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1784 - mae: 0.4761 - mse: 0.3855 - val_loss: 0.2332 - val_mae: 0.5672 - val_mse: 0.4982\n",
            "Epoch 739/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1782 - mae: 0.4762 - mse: 0.3843 - val_loss: 0.2211 - val_mae: 0.5476 - val_mse: 0.4721\n",
            "Epoch 740/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1776 - mae: 0.4739 - mse: 0.3829 - val_loss: 0.2134 - val_mae: 0.5360 - val_mse: 0.4541\n",
            "Epoch 741/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1783 - mae: 0.4761 - mse: 0.3854 - val_loss: 0.2294 - val_mae: 0.5605 - val_mse: 0.4902\n",
            "Epoch 742/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1775 - mae: 0.4742 - mse: 0.3836 - val_loss: 0.2334 - val_mae: 0.5658 - val_mse: 0.4983\n",
            "Epoch 743/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1779 - mae: 0.4744 - mse: 0.3843 - val_loss: 0.2485 - val_mae: 0.5884 - val_mse: 0.5325\n",
            "Epoch 744/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1778 - mae: 0.4744 - mse: 0.3846 - val_loss: 0.2473 - val_mae: 0.5859 - val_mse: 0.5307\n",
            "Epoch 745/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1774 - mae: 0.4747 - mse: 0.3831 - val_loss: 0.2193 - val_mae: 0.5453 - val_mse: 0.4671\n",
            "Epoch 746/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1783 - mae: 0.4750 - mse: 0.3855 - val_loss: 0.2200 - val_mae: 0.5462 - val_mse: 0.4692\n",
            "Epoch 747/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1779 - mae: 0.4746 - mse: 0.3841 - val_loss: 0.2446 - val_mae: 0.5829 - val_mse: 0.5243\n",
            "Epoch 748/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1784 - mae: 0.4756 - mse: 0.3852 - val_loss: 0.2315 - val_mae: 0.5633 - val_mse: 0.4945\n",
            "Epoch 749/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1774 - mae: 0.4750 - mse: 0.3829 - val_loss: 0.2302 - val_mae: 0.5616 - val_mse: 0.4921\n",
            "Epoch 750/800\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.1774 - mae: 0.4740 - mse: 0.3835 - val_loss: 0.2308 - val_mae: 0.5629 - val_mse: 0.4934\n",
            "Epoch 751/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1773 - mae: 0.4728 - mse: 0.3828 - val_loss: 0.2146 - val_mae: 0.5373 - val_mse: 0.4572\n",
            "Epoch 752/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1777 - mae: 0.4745 - mse: 0.3838 - val_loss: 0.2184 - val_mae: 0.5438 - val_mse: 0.4662\n",
            "Epoch 753/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1776 - mae: 0.4737 - mse: 0.3836 - val_loss: 0.2342 - val_mae: 0.5683 - val_mse: 0.5008\n",
            "Epoch 754/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1765 - mae: 0.4719 - mse: 0.3814 - val_loss: 0.2228 - val_mae: 0.5514 - val_mse: 0.4750\n",
            "Epoch 755/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1777 - mae: 0.4739 - mse: 0.3840 - val_loss: 0.2273 - val_mae: 0.5575 - val_mse: 0.4860\n",
            "Epoch 756/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1766 - mae: 0.4720 - mse: 0.3814 - val_loss: 0.2259 - val_mae: 0.5557 - val_mse: 0.4821\n",
            "Epoch 757/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1768 - mae: 0.4733 - mse: 0.3809 - val_loss: 0.2296 - val_mae: 0.5607 - val_mse: 0.4907\n",
            "Epoch 758/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1780 - mae: 0.4762 - mse: 0.3834 - val_loss: 0.2337 - val_mae: 0.5671 - val_mse: 0.4998\n",
            "Epoch 759/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1786 - mae: 0.4754 - mse: 0.3859 - val_loss: 0.2382 - val_mae: 0.5729 - val_mse: 0.5098\n",
            "Epoch 760/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1772 - mae: 0.4743 - mse: 0.3826 - val_loss: 0.2423 - val_mae: 0.5798 - val_mse: 0.5189\n",
            "Epoch 761/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1768 - mae: 0.4735 - mse: 0.3817 - val_loss: 0.2512 - val_mae: 0.5907 - val_mse: 0.5399\n",
            "Epoch 762/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1763 - mae: 0.4720 - mse: 0.3811 - val_loss: 0.2434 - val_mae: 0.5804 - val_mse: 0.5228\n",
            "Epoch 763/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1764 - mae: 0.4725 - mse: 0.3816 - val_loss: 0.2284 - val_mae: 0.5599 - val_mse: 0.4879\n",
            "Epoch 764/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1763 - mae: 0.4721 - mse: 0.3810 - val_loss: 0.2477 - val_mae: 0.5865 - val_mse: 0.5322\n",
            "Epoch 765/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1767 - mae: 0.4725 - mse: 0.3813 - val_loss: 0.2453 - val_mae: 0.5829 - val_mse: 0.5265\n",
            "Epoch 766/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1763 - mae: 0.4721 - mse: 0.3808 - val_loss: 0.2208 - val_mae: 0.5478 - val_mse: 0.4708\n",
            "Epoch 767/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1762 - mae: 0.4722 - mse: 0.3801 - val_loss: 0.2169 - val_mae: 0.5417 - val_mse: 0.4632\n",
            "Epoch 768/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1764 - mae: 0.4719 - mse: 0.3820 - val_loss: 0.2365 - val_mae: 0.5715 - val_mse: 0.5063\n",
            "Epoch 769/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1767 - mae: 0.4739 - mse: 0.3819 - val_loss: 0.2308 - val_mae: 0.5636 - val_mse: 0.4930\n",
            "Epoch 770/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1760 - mae: 0.4719 - mse: 0.3794 - val_loss: 0.2336 - val_mae: 0.5680 - val_mse: 0.4996\n",
            "Epoch 771/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1754 - mae: 0.4709 - mse: 0.3782 - val_loss: 0.2255 - val_mae: 0.5556 - val_mse: 0.4820\n",
            "Epoch 772/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1757 - mae: 0.4711 - mse: 0.3787 - val_loss: 0.2134 - val_mae: 0.5352 - val_mse: 0.4548\n",
            "Epoch 773/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1761 - mae: 0.4713 - mse: 0.3802 - val_loss: 0.2301 - val_mae: 0.5623 - val_mse: 0.4917\n",
            "Epoch 774/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1756 - mae: 0.4711 - mse: 0.3791 - val_loss: 0.2139 - val_mae: 0.5363 - val_mse: 0.4561\n",
            "Epoch 775/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1760 - mae: 0.4710 - mse: 0.3805 - val_loss: 0.2624 - val_mae: 0.6062 - val_mse: 0.5663\n",
            "Epoch 776/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1761 - mae: 0.4715 - mse: 0.3803 - val_loss: 0.2268 - val_mae: 0.5574 - val_mse: 0.4856\n",
            "Epoch 777/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1757 - mae: 0.4712 - mse: 0.3794 - val_loss: 0.2395 - val_mae: 0.5755 - val_mse: 0.5136\n",
            "Epoch 778/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1755 - mae: 0.4696 - mse: 0.3789 - val_loss: 0.2305 - val_mae: 0.5628 - val_mse: 0.4926\n",
            "Epoch 779/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1752 - mae: 0.4711 - mse: 0.3786 - val_loss: 0.2270 - val_mae: 0.5582 - val_mse: 0.4855\n",
            "Epoch 780/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1768 - mae: 0.4718 - mse: 0.3815 - val_loss: 0.2457 - val_mae: 0.5850 - val_mse: 0.5276\n",
            "Epoch 781/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1760 - mae: 0.4718 - mse: 0.3807 - val_loss: 0.2337 - val_mae: 0.5678 - val_mse: 0.5011\n",
            "Epoch 782/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1763 - mae: 0.4720 - mse: 0.3807 - val_loss: 0.2246 - val_mae: 0.5545 - val_mse: 0.4791\n",
            "Epoch 783/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1757 - mae: 0.4710 - mse: 0.3786 - val_loss: 0.2348 - val_mae: 0.5689 - val_mse: 0.5038\n",
            "Epoch 784/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1750 - mae: 0.4702 - mse: 0.3773 - val_loss: 0.2356 - val_mae: 0.5715 - val_mse: 0.5039\n",
            "Epoch 785/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1758 - mae: 0.4712 - mse: 0.3794 - val_loss: 0.2431 - val_mae: 0.5820 - val_mse: 0.5208\n",
            "Epoch 786/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1757 - mae: 0.4706 - mse: 0.3796 - val_loss: 0.2270 - val_mae: 0.5578 - val_mse: 0.4850\n",
            "Epoch 787/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1750 - mae: 0.4703 - mse: 0.3782 - val_loss: 0.2211 - val_mae: 0.5486 - val_mse: 0.4728\n",
            "Epoch 788/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1739 - mae: 0.4685 - mse: 0.3756 - val_loss: 0.2200 - val_mae: 0.5482 - val_mse: 0.4699\n",
            "Epoch 789/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1752 - mae: 0.4697 - mse: 0.3782 - val_loss: 0.2263 - val_mae: 0.5570 - val_mse: 0.4839\n",
            "Epoch 790/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1743 - mae: 0.4688 - mse: 0.3758 - val_loss: 0.2281 - val_mae: 0.5605 - val_mse: 0.4876\n",
            "Epoch 791/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1752 - mae: 0.4705 - mse: 0.3786 - val_loss: 0.2451 - val_mae: 0.5832 - val_mse: 0.5272\n",
            "Epoch 792/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1753 - mae: 0.4705 - mse: 0.3780 - val_loss: 0.2247 - val_mae: 0.5542 - val_mse: 0.4807\n",
            "Epoch 793/800\n",
            "97/97 [==============================] - 0s 5ms/step - loss: 0.1728 - mae: 0.4667 - mse: 0.3729 - val_loss: 0.2408 - val_mae: 0.5777 - val_mse: 0.5168\n",
            "Epoch 794/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1750 - mae: 0.4697 - mse: 0.3789 - val_loss: 0.2274 - val_mae: 0.5584 - val_mse: 0.4867\n",
            "Epoch 795/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1749 - mae: 0.4700 - mse: 0.3774 - val_loss: 0.2287 - val_mae: 0.5613 - val_mse: 0.4889\n",
            "Epoch 796/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1744 - mae: 0.4688 - mse: 0.3758 - val_loss: 0.2320 - val_mae: 0.5651 - val_mse: 0.4974\n",
            "Epoch 797/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1742 - mae: 0.4681 - mse: 0.3752 - val_loss: 0.2444 - val_mae: 0.5839 - val_mse: 0.5243\n",
            "Epoch 798/800\n",
            "97/97 [==============================] - 1s 6ms/step - loss: 0.1754 - mae: 0.4716 - mse: 0.3787 - val_loss: 0.2298 - val_mae: 0.5624 - val_mse: 0.4923\n",
            "Epoch 799/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1735 - mae: 0.4672 - mse: 0.3749 - val_loss: 0.2385 - val_mae: 0.5746 - val_mse: 0.5114\n",
            "Epoch 800/800\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 0.1745 - mae: 0.4700 - mse: 0.3763 - val_loss: 0.2200 - val_mae: 0.5469 - val_mse: 0.4708\n",
            "Fin del entrenamiento\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gráficas de errores absoluto y cuadrático promedios"
      ],
      "metadata": {
        "id": "LL942W-14TP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================ Gráficas de Huber y MSE ================\n",
        "#Luego del entrenamiento, se obtienen los datos de pérdida para el entrenamiento\n",
        "#y la validación\n",
        "huber = history.history['loss']\n",
        "val_huber = history.history['val_loss']\n",
        "mse = history.history['mse']\n",
        "val_mse = history.history['val_mse']\n",
        "#Se crean arrays para definir los ejes horizontales de las pérdidas anteriores\n",
        "#en la gráfica\n",
        "x_huber = []\n",
        "x_mse = []\n",
        "x_valhuber = []\n",
        "x_valmse = []\n",
        "#Se agregan los valores a cada eje x del entrenamiento, que corresponden a cada\n",
        "#iteración\n",
        "for i in range(EPOCHS):\n",
        "  x_huber.append(i + 1)\n",
        "  x_mse.append(i + 1)\n",
        "#Se agregan los valores a cada eje x de validación, de acuerdo con la frecuencia \n",
        "#de validación definida anteriormente\n",
        "for i in range(EPOCHS):\n",
        "  x_valhuber.append((i + 1) * freqVal/10)\n",
        "  x_valmse.append((i + 1) * freqVal/10)\n",
        "#Para graficar de mejor forma los resultados, se usa un subplot con 2 espacios\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n",
        "#Se configuran los nombres de cada eje en las gráficas\n",
        "axs[0].set_xlabel(\"Iteración\")\n",
        "axs[0].set_ylabel(\"Huber\")\n",
        "axs[1].set_xlabel(\"Iteración\")\n",
        "axs[1].set_ylabel(\"MSE\")\n",
        "#Se grafican los datos de error de huber para el entrenamiento y la validación\n",
        "axs[0].plot(x_huber, huber, label=\"Error de entrenamiento\")\n",
        "axs[0].plot(x_valhuber, val_huber, label=\"Error de validación\")\n",
        "#Se grafican los datos de error cuadrático para el entrenamiento y la validación\n",
        "axs[1].plot(x_mse, mse, label=\"Error de entrenamiento\")\n",
        "axs[1].plot(x_valmse, val_mse, label=\"Error de validación\")\n",
        "#Limita los ejes de las gráficas a valores entre 0 y 1, para observar cada error\n",
        "axs[0].set_ylim([0,1])\n",
        "axs[1].set_ylim([0,1])\n",
        "#Muestra las leyendas para identificar las curvas\n",
        "axs[0].legend()\n",
        "axs[1].legend()\n",
        "#Despliega las gráficas resultantes\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "f1hZvvRU4yK0",
        "outputId": "1bdc8d50-7486-48b6-bcf6-baafd4e874ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluación de pruebas"
      ],
      "metadata": {
        "id": "jaDblDea7xeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Para evaluar completamente el funcionamiento del modelo, se realiza una serie\n",
        "#de predicciones usando el subconjunto de prueba que se definió anteriormente\n",
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "#Para observar cuánto distan los valores predichos de los valores reales, se\n",
        "#realiza una gráfica de dispersión entre dichos datos\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "#Se colocan los nombres de los ejes\n",
        "plt.xlabel('Valores reales')\n",
        "plt.ylabel('Valores predichos')\n",
        "#Se definen las dimensiones de la gráfica\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "#Se establecen límites para cada uno de los ejes, de modo que se aproveche el\n",
        "#espacio lo más que se pueda\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "#Se dibuja la recta ideal en la cual se encontrarían los datos, si el error de\n",
        "#la red fuera cero\n",
        "_ = plt.plot([-100, 100], [-100, 100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "YDScy9Kv6KDg",
        "outputId": "c3ffcd5b-77bf-47e8-f7cd-c8fee848cc7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAEGCAYAAAC9wNNmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAaAElEQVR4nO3de5QcZZnH8e9vJmGdAEmIxEuGS7IcFwRBAoMBswcWUBEEzAKyRHHFy7JXQY8bl6h7wHNQQC7rBcSNgKiEiCTZCIJcFLLrhU2YECCGi4tEgQFkFMI1QJg8+0dVw2RS3VM93W/X29XP55w+0/1Od/WTyfymqt5+37dkZjjnyqOr6AKcc83loXauZDzUzpWMh9q5kvFQO1cy44ouYLjtt9/epk+fXnQZzkVv1apVfzSzqVnfiyrU06dPp7+/v+gynIuepN9X+54ffjtXMh5q50rGQ+1cyXionSsZD7VzJeOhdq5kPNTOlYyH2rmS8VA7VzIeaudKxkPtXMl4qJ1rMyvXPVnz+x5q59rIynVPctJ3VtZ8jofauTZRCfSbJr2u5vM81M61geGB/sHf7V/zuR5q5yI3MtBvmOh7aufaVr2BBg+1c9EaS6DBQ+1clMYaaPBQOxedRgINHmrnotJooMFD7Vw0mhFo8FA7F4VmBRo81M4VrpmBBg+1c4VqdqDBQ+1cYUIEGjzUzhUiVKDBQ+1cy4UMNHionWup0IEGD7VzLdOKQIOH2rmWaFWgwUPtXHCtDDREdtF51z6WrR7g3Bvv59H1G5g2uYd5h+3KnJm9RZcVnVYHGjzUbgyWrR5g/tI1bNg4BMDA+g3MX7oGwIM9TBGBBj/8dmNw7o33vxroig0bhzj3xvsLqig+RQUaPNRuDB5dv6Gu9k5TZKDBQ+3GYNrknrraO0nRgQYPtRuDeYftSs/47s3aesZ3M++wXQuqKA4xBBoCd5RJ+jTwCcCANcBHzezFkO/pwqt0hrVT73fo3vpYAg0BQy2pFzgF2N3MNkj6IXACcHmo93StM2dmb9QhHi50b31MgYbwh9/jgB5J44AJwKOB38+5LYTsrY8t0BAw1GY2AJwHPAQ8BjxtZjeNfJ6kkyX1S+ofHBwMVY7rYKF662MMNAQMtaTtgPcDM4BpwNaSThz5PDNbYGZ9ZtY3derUUOW4Dhaitz7WQEPYw+93AevMbNDMNgJLgXcGfD/nMjW7tz7mQEPYUD8E7C9pgiQBhwL3Bnw/5zLNmdnLsfv20i0B0C1x7L5j6+iLPdAQ9px6BbAYuIPk46wuYEGo93OummWrB1iyaoAhMwCGzFiyaoBlqwfq2k47BBoCf05tZqcDp4d8D1cuX1i2hkUrHmbIjG6JubN25Mw5eza0zVq933n31u0SaPBZWi4iX1i2hiv+96FXHw+Zvfq4kWA32vvdToEGHybqIrJoxcN1tefVSO93rUAvWz3A7LNvYcZp1zH77FvqPpwPxUPtolE5583bnte8w3ZlfJc2axvfpVF7v0cL9LzFdzGwfgNGMkpt3uK7ogi2h9pFo9I7nbe9HptGeTzSaIfcX7x2LRuHNv9js3HI+OK1axuutVEeaheNubN2rKs9ry9eu5ahTZsHcGhT9QDmOYd+6oWNma+t1t5KHmoXjb6dp9A94jC5u0v07Tyloe3WE8B26xTL4qF20Tj3xvsz96itWiapnkBP7hlfV3sreahdNEJNvBhf5bd8eHu9e+g9pm1bV3sreahdNEItk/RKlV6xSvtYDrlve/DJutpbyUPtojH99dnhrdaeV7UPxIyxn0NvqrLRau2t5KF20fjVb7P3ctXam6HdO8WyeKhdNGrtUUMpW6DBx367MQox8aIIZQs0eKjdGISaeFGEsgUa/PDbjUGoiReuOXxP7eoWauKFSzS6RrmH2tWtW8oMcDMmXnS6ZqxR7offrm6hJl6EsHJd8YNB6tGMNcpHDbWk2ZK2Tu+fKOkCSTvXW6wrjzPn7MmJ+++02UJ+J+6/U3SdZJWBJe2kGUNl8+ypLwZekPR24DPAb4Hv5X4HV0p9O0/hTZNeh0g+6210JlWzDR8pFkJXlTONau15NWOobJ5Qv2JmRrIw/4VmdhFQ/Kj1kol1aZwsMa/6AVsO/Qwh1DDRZqxRnifUz0qaD3wYuE5SF1D8/LISqXSODA/J/KVrognJSDGv+tHu86HnzOzlrGP2pHdyDwJ6J/dw1jF7Nr33+2+ADwIfM7PHJe0EnDu2kl2WZixh20qxrvrR7oGuaPSKoqPuqc3scWAhMEnSkcCLZubn1E0Uah5xJylLoJshT+/38cBK4APA8cAKSceFLqyTTKqyWka1drc5D/Tm8hx+fx7Yz8yeAJA0FfgpySV1XBNUG7PRjLEcZZl4UY0Hekt5Qt1VCXTqT/iglaZaX+VctFp7XmWaeJHFA50tTzhvkHSjpJMknQRcB1wftqzOEmoZnzJPvPBAV5eno2weydUq90pvC8zs30IX1kmaff3kirJOvPBA15ZrQoeZLQGWBK6lY1U+vmhkZk6WMk688ECPbtRQSzoGOAd4A6D0ZmY2MXBtHaXRzyazzJ2142bn1MPb21FMge5S9uixRoeJNkOePfVXgKPM7N7QxbjmqnSGlaH3O6ZAQ9yrieYJ9R880OE1OjG+7GIKdOyqhjo97Abol3QVsAx4qfJ9M1sauLaO0YyJ8VnK9JFWbIGe3DOe9Ru2/Mgx9svuHJXeJgIvAO8Z1nZkno1LmixpsaT7JN0r6YBGCy6jZkyMz7Iw43y6VnvMYgo0wBlH71FXeytV3VOb2UebsP2vATeY2XGStgImNGGbpRNq7HcR62iHElOgAfp/n72iSv/vnyz8tCnP2O/vSpo87PF2ki7L8bpJwIHApQBm9rKZrW+k2LIKNfjEhRPzwJ48I8r2Gh5GM3sKmJnjdTOAQeA7klZLuqSyLJLbXKjBJy6cmAf25Al1l6TtKg8kTSFfr/k4YB/gYjObCTwPnDbySZJOltQvqX9wcDBn2eXSjInxrrWqDeCJYWBPnnCeD9wm6WqSgSfHAV/K8bpHgEfMbEX6eDEZoTazBSTDUOnr6yv+z1xBQgw+aSfttupnzAN78oz9/h5wDPAH4HHgGDP7fo7XPQ48LKlyDHkocE8Dtbo6VdtnFL8v2Vw7rvp55pw9mb3L5ostzt5lShQfFdb6nHqimT2THm4/Dlw57HtTzCzPn9ZPAgvTnu8HgWb0qJdSiMEn7dD7PXyk2IODzxddTm7LVg9w24hL7N722ydZtnqg8COuWnvqSohXAf3DbpXHozKzO82sz8z2MrM5aSebGyHUwoMxn/dBa1b9DGX+0rvZNKJtU9petFqfUx+Zfp3RunI6U6iFB2PuoY1tLHe9NmwcGena7a1U6/B7n1ovNLM7ml9OZwo1+KR3cg8DGdvoLfjz71YHWmSfcsRxvNJ8tQ6/z09vFwErSHqov53evyh8aZ0j1OCTGD//LmIP/c5dsq8eUq09j1BX6GiGqqE2s4PN7GDgMWCf9Nx4X5KBJ3GuMt+mQoVvzsxejt23d7NrXh27b3EfnRV1yH3HQ9kDGau15/HBWTvV1d5KeQaf7GpmayoPzOzXwFvDldR5Qg0+WbZ6gKtWPvzqOfSQGVetfLiQK38UeQ4d4vw35osE5hl8crekS4Ar0scfAorv4iuZEINPzrhmLRtHzNrfuMk445q1Ld1bt3unWDV9O0/h1vsGeXT9hqguEpgn1B8F/hE4NX38PyRXwnSRy5rvW6s9hLIGOtQc+GYYNdRm9qKkbwHXm1ljE3xdRylroCHu65/lmXp5NHAncEP6eG9J14QuzLW3Mgca4r7+WZ6OstOBdwDrIRklRjKt0rlMZQ80xD0HPk+oN5rZ0yPaih+S5KLUCYGGOMcAVOTpKFsr6YNAt6S3AKcAvwpblmtXnRBoCHcBhmbIE+pPklz58iWSSR43AmeGLMq1r04IdEWsc+BrhlpSN3BdOrLs860pyTXLdhPG81TGlTO3mxBuGdsYAx3rGPhQap5Tm9kQsCldRNC1mdOP2oPuEYORu7vE6UeFW8Y2tkBDcv47vnvzn8P4bkVx/htCnsPv54A1km4mWWcMADM7JVhVrmmGRowoG/m4Y4z8Z5f4x5Cn93sp8O8kI8lWDbu5yH2uyoT9au1lde6N92cOl230YgmxyjOi7LvpckS7kfx9u9/MXg5emWvYC1UmLFRrL6uYB4qEkGdE2RHAb4GvAxcCD0g6PHRhLk7ttuonwOQqHYPV2ttdnnPqC4CDzewBAEm7ANcBPwlZmItPO676CVBt9aYIVnUKIs859bOVQKceBJ4NVI9rognjs/97q7XXMnykWLt5usqstGrt7S7P/26/pOslnSTpI8C1wO2Sjhl2uVsXoS8fs9cWy+t0KWmvRzuv+glxj9MOIc/h9+tIFvI/KH08CPSQXNLWSHrHXYNCrPvdjKGMZRjLPe+wXTeb+wzxjNMOIU/vty/AH9iy1QPMu/quVz92GVi/gXlX3wU0PuG+kaGMrQ50qBFwMY/TDiHPntoFFsuyQ8MVsYfefputMkO9/TZbNbztWMdph1B/j4lruhiWHRquqEPu/3si+7I71dpdNt9Tl1y95+plOIfudHkGn5wqaaISl0q6Q9J7WlFcp6h2ztjouWS91+jyQJdDnsPvj5nZM8B7gO2ADwNnB62qw5x+1B6Zs4ganU1Va3G8kTzQ5ZHn8Lvy23YE8H0zWytFctnEkgjVO5s1hzirPZZAd9o1r0LJE+pVkm4iWWxwvqRtYYureLoGheid7ZYyr3A5/FK2sQQaYMJW3Tz/8lBmu8svT6g/DuwNPGhmL0h6PX7x+LYw2qVsYwo0wAsZga7V7rLlOac2YHeSBQcBtiYZZeYiV225nt7JPQ0FutZ2G9FpwzlDyRPqbwIHAHPTx8/il7JtCwfvNjWzfY9p2za0hw61PFDMy+62kzyH37PMbB9JqwHM7Kl00QQXuVvvG8xsv/meJ5gxdevGDrkDLA/UacM5Q8kT6o3pqqIGIGkqdXSUpa/tBwbM7MgxVenGpFrvt9HYqp+1lgcqcqy6S+Q5/P468F/AGyR9CfgF8OU63uNU4N4x1OYCaqRTrNOWB2o3NUMtqQtYB3wWOAt4DJhjZlfn2bikHYD3AZc0WKeLSE+VRRaqtbvWqnn4bWabJF1kZjOB+8aw/a+S/EHYttoTJJ0MnAyw0047jeEtXDV5Pqceiw2vZJ99VWt3rZXnT+vPJB1b7ygySUcCT5hZzeWEzWyBmfWZWd/Uqdm9tW5sDn1r9s9z7qwdG9pup6351W7yhPrvgauBlyU9m96eyfG62cDRkn4H/AA4RNIVYy/V1WPluidZ/ps/btHeJejbeUpD2662p2/0CMA1x6ihNrNtzazLzMan97c1s4k5XjffzHYws+nACcAtZnZiE2p2o6gMLNmUcTWOTUbDi9hX29M3egTgmiPXfGpJRwMHpg+Xm9mPw5XkGjF8pNiDg9mLCzTaS33mnD0BWLTiYYbM6JaYO2vHV9tdsUYNtaSzgf2AhWnTqZJmm9n8vG9iZsuB5WMp0OU3cujnX3/zV5mfVTdj2OWZc/b0EEcqzzn1EcC7zewyM7sMeC/Jx1QuIlljuX3YZWfKu5zRZKByvRW/rG1kqk3OCDnsMsSSxq458oT6LGC1pFtJ5qsfCJwWtCqX22izrUIMu6wsk1RZVaWyTFLl/Vyx8vR+LwL2J1m0fwlwgJldFbowN7qi5kPXs0ySa72qe2pJ+4xoeiT9Ok3SNDO7I1xZbjRFLnDgY7/jVuvw+/wa3zPgkCbX4nIqesWSaZN7gvWqu8ZVDbWZHdzKQlw+RQcaOu/aVO0m7+CTt5EsafTqb5CZfS9UUS5bDIEGX8wgdnkGn5wO/BVJqK8HDieZU+2hbqFYAl3hixnEK8/gk+OAQ4HH0ytgvh3/rLqlYgu0i1ueUG8ws03AK5ImAk8APnK/RTzQrl55zqn7JU0Gvg2sAp4DbgtalQM80G5san1OfRFwpZn9U9r0LUk3ABPN7O6WVNfBPNBurGrtqX8DnCfpzcAPgUVmtro1ZXU2D7RrRNVzajP7mpkdABwE/Am4TNJ9kk6X9Bctq7DDeKBdo/KM/f69mZ2TLj44F5iDL/kbhAfaNUOei86Pk3SUpIXAT4D7gWOCV9ZhPNCuWWp1lL2bZM98BLCSZPHAk80se40cN2YeaNdMtTrK5gNXAp8xs6daVE/H8UC7Zqs1ocNnYQXmgXYh+HVSCuKBdqF4qAvggXYheahbzAPtQvNQt5AH2rWCh7pFPNCuVTzULeCBdq3koQ7MA+1azUMdkAfaFcFDHYgH2hXFQx2AB9oVyUPdZB5oVzQPdRN5oF0MPNRN4oF2sfBQN4EH2sXEQ90gD7SLTbBQS9pR0q2S7pG0VtKpod6rKB5oF6NcF8gbo1dIVk25Q9K2wCpJN5vZPQHfs2U80C5WwfbUZvZY5cL0ZvYsyQqkpbiimgfaxawl59SSpgMzgRUZ3ztZUr+k/sHBwVaU0xAPtItd8FBL2gZYAnzKzJ4Z+X0zW2BmfWbWN3Xq1NDlNMQD7dpB0FBLGk8S6IVmtjTke4XmgXbtImTvt4BLgXvN7IJQ79MKHmjXTkLuqWcDHwYOkXRnejsi4PsF4YF27SbYR1pm9gtAobbfCh5o1458RFkVHmjXrjzUGTzQrp15qEfwQLt256EexgPtysBDnfJAu7LwUOOBduXS8aH2QLuy6ehQe6BdGXVsqD3Qrqw6MtQeaFdmHRdqD7Qru44KtQfadYKOCbUH2nWKjgi1B9p1ktKH2gPtOk2pQ+2Bdp2otKH2QLtOVcpQe6BdJytdqD3QrtOVKtQeaOdKFGoPtHOJUoTaA+3ca9o+1B5o5zbX1qH2QDu3pbYNtQfauWxtGWoPtHPVtV2oPdDO1dZWofZAOze6tgm1B9q5fNoi1B5o5/KLPtQeaOfqE3WoPdDO1S/aUHugnRubKEPtgXZu7KILtQfaucYEDbWk90q6X9IDkk4b7fnPv/SKB9q5BgULtaRu4CLgcGB3YK6k3Wu95nd/esED7VyDQu6p3wE8YGYPmtnLwA+A99d6wfhueaCda9C4gNvuBR4e9vgRYNbIJ0k6GTg5ffjSGyf1/DpgTc20PfDHoouog9cbThG17lztGyFDnYuZLQAWAEjqN7O+gkvKpZ1qBa83pNhqDXn4PQDsOOzxDmmbcy6gkKG+HXiLpBmStgJOAK4J+H7OOQIefpvZK5L+BbgR6AYuM7O1o7xsQah6AminWsHrDSmqWmVmRdfgnGui6EaUOeca46F2rmSiCHW9w0mLJGlHSbdKukfSWkmnFl3TaCR1S1ot6cdF1zIaSZMlLZZ0n6R7JR1QdE21SPp0+nvwa0mLJBU+cqrwUI9lOGnBXgE+Y2a7A/sD/xx5vQCnAvcWXUROXwNuMLPdgLcTcd2SeoFTgD4zextJh/AJxVYVQagZw3DSIpnZY2Z2R3r/WZJfut5iq6pO0g7A+4BLiq5lNJImAQcClwKY2ctmtr7YqkY1DuiRNA6YADxacD1RhDprOGm0IRlO0nRgJrCi2Epq+irwWWBT0YXkMAMYBL6Tni5cImnroouqxswGgPOAh4DHgKfN7KZiq4oj1G1J0jbAEuBTZvZM0fVkkXQk8ISZrSq6lpzGAfsAF5vZTOB5INo+FknbkRxVzgCmAVtLOrHYquIIddsNJ5U0niTQC81sadH11DAbOFrS70hOaw6RdEWxJdX0CPCImVWOfBaThDxW7wLWmdmgmW0ElgLvLLimKELdVsNJJYnknO9eM7ug6HpqMbP5ZraDmU0n+bneYmaF70mqMbPHgYcl7Zo2HQrcU2BJo3kI2F/ShPT34lAi6NiLYZbWWIaTFmk28GFgjaQ707bPmdn1BdZUJp8EFqZ/4B8EPlpwPVWZ2QpJi4E7SD4VWU0EQ0Z9mKhzJRPD4bdzrok81M6VjIfauZLxUDtXMh5q50rGQx2hdBbYYSPaPiXp4hqvWS4pmsXvapF0kqQLi66jrDzUcVrElrN9TkjbmyKdHdeM7RQ+1sFtzkMdp8XA+9IBGJWJI9OAn0u6WFJ/Oof3i1kvljRX0pp0ju85w9qfk3S+pLuAAySdKGmlpDsl/Wc677pb0uXpa9dI+nTG9i+X9C1JK4CvSNpF0g2SVkn6uaTd0ucdJWlFOjnjp5LemLGtqZKWSLo9vc1O2w9K67ozff22Df9UO4WZ+S3CG/Bj4P3p/dOA89L7U9Kv3cByYK/08XKgjyT8DwFTSUYM3gLMSZ9jwPHp/bcC1wLj08ffBP4W2Be4eVgdkzNquzytrzt9/DPgLen9WSTDUQG247UBTp8Azk/vnwRcmN6/EvjL9P5OJMNvSWubnd7fBhhX9P9Ju9z80ClelUPwH6VfP562H59e1WQc8GaShSXuHva6/YDlZjYIIGkhyRzlZcAQyUQUSMYp7wvcngxbpgd4giRMfy7pG8B1QLWphFeb2VA6W+2dwNXpdgD+LP26A3CVpDcDWwHrMrbzLmD3Ya+dmG7zl8AFaf1LzeyRKnW4ETzU8foR8B+S9gEmmNkqSTOAfwX2M7OnJF0O1LN8zotmNpTeF/BdM5s/8kmS3g4cBvwDcDzwsYxtPZ9+7QLWm9neGc/5BnCBmV0j6a+AMzKe0wXsb2Yvjmg/W9J1wBHALyUdZmb31fzXOcDPqaNlZs8BtwKX8VoH2USSMD2dnp8envHSlcBBkrZPO8PmAv+d8byfAcdJegOApCmSdpa0PdBlZkuALzDK1EdL5pKvk/SBdDtK/ygATOK1abQfqbKJm0gmcZC+fu/06y5mtsbMziGZybdbrTrcazzUcVtEsk7XIgAzu4tkJtB9JOeivxz5AjN7jOQc/FbgLmCVmf0o43n3kIT2Jkl3AzeTHM73AsvTGWhXAFvsyTN8CPh42gG3lteWozqD5LB8FdUvIHcK0Cfpbkn3kBwdAHwq7ay7G9gI/CRHHQ6fpeVc6fie2rmS8VA7VzIeaudKxkPtXMl4qJ0rGQ+1cyXjoXauZP4fiV5XaaIkHFkAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#En adición a lo anterior, se realiza un histograma en donde se indica la\n",
        "#cantidad de veces que sucedió cada posible error en la predicción\n",
        "#Para ello, se calcula el error de predicción, al sustraer los valores reales\n",
        "#de los valores predichos\n",
        "error = test_predictions - test_labels\n",
        "#Se grafica el histograma correctamente\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Error de predicción\")\n",
        "_ = plt.ylabel(\"Cantidad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "kjjz_X8i6hMS",
        "outputId": "e4365511-cd99-4c8e-dbe9-6a9449394048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Carga de combinaciones adicionales de entrada"
      ],
      "metadata": {
        "id": "rnRq7Wjmk5Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================ Carga de datos externos ================\n",
        "#Primero se cargan los datos a partir de un nuevo archivo .csv\n",
        "data_whitewine = pd.read_csv('winequality-white1.csv', header=0)\n",
        "print(data_whitewine)\n",
        "#Como estos datos solo incluyen los parámetros de entrada, se procede a su\n",
        "#normalización\n",
        "normed_data_whitewine = scaler.fit_transform(data_whitewine)\n",
        "#Luego, se calculan las calidades de vino\n",
        "qual_preds = model.predict(normed_data_whitewine).flatten()\n",
        "print(\"\\nQualities:\",qual_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jlq6VGck6CW",
        "outputId": "eab2698c-b9e8-4082-a4b4-f88b0d73c7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
            "0            5.9              0.66         0.58             2.3         77   \n",
            "1            8.7              0.16         0.26             9.3         25   \n",
            "2            7.2              0.64         0.42             6.3         56   \n",
            "\n",
            "   free sulfur dioxide  total sulfur dioxide  density   pH  sulphates  alcohol  \n",
            "0                   52                    12   0.9733  4.2       0.56     10.2  \n",
            "1                   16                    34   0.9933  3.2       0.65     12.2  \n",
            "2                   15                    22   0.9018  1.2       1.08      8.2  \n",
            "\n",
            "Qualities: [6.2012486 5.2582245 6.2887864]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ceteris paribus"
      ],
      "metadata": {
        "id": "MrgRgMqCb-jl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 1"
      ],
      "metadata": {
        "id": "MX-5IypHgea9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================ Carga de datos externos ================\n",
        "#Primero se cargan los datos a partir de un nuevo archivo .csv\n",
        "data_whitewine = pd.read_csv('winequality-white_ceteri1.csv', header=0)\n",
        "print(data_whitewine)\n",
        "#Como estos datos solo incluyen los parámetros de entrada, se procede a su\n",
        "#normalización\n",
        "normed_data_whitewine = scaler.fit_transform(data_whitewine)\n",
        "#Luego, se calculan las calidades de vino\n",
        "qual_preds = model.predict(normed_data_whitewine).flatten()\n",
        "print(\"\\nQualities:\",qual_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUPB2z0scBsY",
        "outputId": "ec598c39-9cbd-4548-bd4a-e46547ac4b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
            "0            7.20             0.230        0.320             8.5     0.0580   \n",
            "1            8.64             0.230        0.320             8.5     0.0580   \n",
            "2            5.76             0.230        0.320             8.5     0.0580   \n",
            "3            7.20             0.276        0.320             8.5     0.0580   \n",
            "4            7.20             0.184        0.320             8.5     0.0580   \n",
            "5            7.20             0.230        0.384             8.5     0.0580   \n",
            "6            7.20             0.230        0.256             8.5     0.0580   \n",
            "7            7.20             0.230        0.320            10.2     0.0580   \n",
            "8            7.20             0.230        0.320             6.8     0.0580   \n",
            "9            7.20             0.230        0.320             8.5     0.0696   \n",
            "10           7.20             0.230        0.320             8.5     0.0464   \n",
            "11           7.20             0.230        0.320             8.5     0.0580   \n",
            "12           7.20             0.230        0.320             8.5     0.0580   \n",
            "13           7.20             0.230        0.320             8.5     0.0580   \n",
            "14           7.20             0.230        0.320             8.5     0.0580   \n",
            "15           7.20             0.230        0.320             8.5     0.0580   \n",
            "16           7.20             0.230        0.320             8.5     0.0580   \n",
            "17           7.20             0.230        0.320             8.5     0.0580   \n",
            "18           7.20             0.230        0.320             8.5     0.0580   \n",
            "19           7.20             0.230        0.320             8.5     0.0580   \n",
            "20           7.20             0.230        0.320             8.5     0.0580   \n",
            "21           7.20             0.230        0.320             8.5     0.0580   \n",
            "22           7.20             0.230        0.320             8.5     0.0580   \n",
            "\n",
            "    free sulfur dioxide  total sulfur dioxide  density     pH  sulphates  \\\n",
            "0                  47.0                 186.0  0.99560  3.190       0.40   \n",
            "1                  47.0                 186.0  0.99560  3.190       0.40   \n",
            "2                  47.0                 186.0  0.99560  3.190       0.40   \n",
            "3                  47.0                 186.0  0.99560  3.190       0.40   \n",
            "4                  47.0                 186.0  0.99560  3.190       0.40   \n",
            "5                  47.0                 186.0  0.99560  3.190       0.40   \n",
            "6                  47.0                 186.0  0.99560  3.190       0.40   \n",
            "7                  47.0                 186.0  0.99560  3.190       0.40   \n",
            "8                  47.0                 186.0  0.99560  3.190       0.40   \n",
            "9                  47.0                 186.0  0.99560  3.190       0.40   \n",
            "10                 47.0                 186.0  0.99560  3.190       0.40   \n",
            "11                 56.4                 186.0  0.99560  3.190       0.40   \n",
            "12                 37.6                 186.0  0.99560  3.190       0.40   \n",
            "13                 47.0                 223.2  0.99560  3.190       0.40   \n",
            "14                 47.0                 148.8  0.99560  3.190       0.40   \n",
            "15                 47.0                 186.0  1.19472  3.190       0.40   \n",
            "16                 47.0                 186.0  0.79648  3.190       0.40   \n",
            "17                 47.0                 186.0  0.99560  3.828       0.40   \n",
            "18                 47.0                 186.0  0.99560  2.552       0.40   \n",
            "19                 47.0                 186.0  0.99560  3.190       0.48   \n",
            "20                 47.0                 186.0  0.99560  3.190       0.32   \n",
            "21                 47.0                 186.0  0.99560  3.190       0.40   \n",
            "22                 47.0                 186.0  0.99560  3.190       0.40   \n",
            "\n",
            "    alcohol  \n",
            "0      9.90  \n",
            "1      9.90  \n",
            "2      9.90  \n",
            "3      9.90  \n",
            "4      9.90  \n",
            "5      9.90  \n",
            "6      9.90  \n",
            "7      9.90  \n",
            "8      9.90  \n",
            "9      9.90  \n",
            "10     9.90  \n",
            "11     9.90  \n",
            "12     9.90  \n",
            "13     9.90  \n",
            "14     9.90  \n",
            "15     9.90  \n",
            "16     9.90  \n",
            "17     9.90  \n",
            "18     9.90  \n",
            "19     9.90  \n",
            "20     9.90  \n",
            "21    11.88  \n",
            "22     7.92  \n",
            "\n",
            "Qualities: [5.807594  5.6948295 6.5283513 5.2125897 6.742825  6.2965302 5.317132\n",
            " 5.7358284 4.3622856 5.417573  5.9870896 5.8072    4.0528975 5.251931\n",
            " 6.179679  5.4161305 6.9214783 6.645699  5.7420373 5.8997173 6.090334\n",
            " 6.1718707 5.8050537]\n"
          ]
        }
      ]
    }
  ]
}