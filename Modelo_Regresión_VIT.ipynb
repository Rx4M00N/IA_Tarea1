{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcetvXmgQoEDA39FlHKKH4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rx4M00N/IA_Tarea1/blob/main/Modelo_Regresi%C3%B3n_VIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementación Modelo VIT\n",
        "Regresión para obtener calidad en muestras de vino tinto.\n",
        "\n",
        "Elaborado por: Joshua Corvera y Ricardo Luna.\n",
        "\n",
        "MT-8008 Inteligencia Artificial, grupo 1, II Semestre 2022."
      ],
      "metadata": {
        "id": "yHZGrDfxy9qD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importación de librerías"
      ],
      "metadata": {
        "id": "z4abSetmzcEE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDYuimN4y4rl"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Normalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Carga de datos a partir de archivo .csv"
      ],
      "metadata": {
        "id": "wrwJZ9FOzqAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se cargan los datos desde un .csv\n",
        "datos_vinotinto = pd.read_csv('winequality-red.csv', header=0)\n",
        "#Se revisa el arreglo cargado y se elimiman datos nulos\n",
        "datos_vinotinto = datos_vinotinto.dropna()\n",
        "#Muestra el arreglo cargado en pantalla\n",
        "print(datos_vinotinto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfgQAh8zzjnC",
        "outputId": "84ace004-461f-4f6e-ad1c-f1f689eed6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
            "0               7.4             0.700         0.00             1.9      0.076   \n",
            "1               7.8             0.880         0.00             2.6      0.098   \n",
            "2               7.8             0.760         0.04             2.3      0.092   \n",
            "3              11.2             0.280         0.56             1.9      0.075   \n",
            "4               7.4             0.700         0.00             1.9      0.076   \n",
            "...             ...               ...          ...             ...        ...   \n",
            "1594            6.2             0.600         0.08             2.0      0.090   \n",
            "1595            5.9             0.550         0.10             2.2      0.062   \n",
            "1596            6.3             0.510         0.13             2.3      0.076   \n",
            "1597            5.9             0.645         0.12             2.0      0.075   \n",
            "1598            6.0             0.310         0.47             3.6      0.067   \n",
            "\n",
            "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
            "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
            "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
            "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
            "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
            "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
            "...                   ...                   ...      ...   ...        ...   \n",
            "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
            "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
            "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
            "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
            "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
            "\n",
            "      alcohol  quality  \n",
            "0         9.4        5  \n",
            "1         9.8        5  \n",
            "2         9.8        5  \n",
            "3         9.8        6  \n",
            "4         9.4        5  \n",
            "...       ...      ...  \n",
            "1594     10.5        5  \n",
            "1595     11.2        6  \n",
            "1596     11.0        6  \n",
            "1597     10.2        5  \n",
            "1598     11.0        6  \n",
            "\n",
            "[1599 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Formato de los datos y separación en subconjuntos"
      ],
      "metadata": {
        "id": "s2cXARY-zzqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============== Dar formato a los datos de entrenamiento ===============\n",
        "#Se define un porcentaje de los datos que se usará para entrenar.\n",
        "#En este caso se usan 80% de los datos para entrenamiento y validación, y 20%\n",
        "#para pruebas\n",
        "p_train = 0.80\n",
        "#Se seleccionan datos al azar, mediante la asignación temporal de flags\n",
        "datos_vinotinto['is_train'] = np.random.uniform(0, 1, len(datos_vinotinto)) <= p_train\n",
        "#Se dividen los datos en subconjuntos, según los flags asginados\n",
        "train, test = datos_vinotinto[datos_vinotinto['is_train']==True], datos_vinotinto[datos_vinotinto['is_train']==False]\n",
        "#Se eliminan los flags del conjunto original\n",
        "datos_vinotinto = datos_vinotinto.drop('is_train', 1)\n",
        "#Se imprimen las cantidades de datos de entrenamiento y de prueba\n",
        "print(\"Ejemplos usados para entrenar: \", len(train))\n",
        "print(\"Ejemplos usados para test: \", len(test))\n",
        "#Se eliminan los flags temporales de los subconjuntos de prueba y entrenamiento\n",
        "train.pop('is_train')\n",
        "test.pop('is_train')\n",
        "#Se separan las etiquetas de las entradas, para cada subconjunto de datos\n",
        "train_labels = train.pop('quality')\n",
        "train_data = train\n",
        "test_labels = test.pop('quality')\n",
        "test_data = test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H_qOHSozyr6",
        "outputId": "969dc448-f801-435c-d385-78a887b77fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplos usados para entrenar:  1274\n",
            "Ejemplos usados para test:  325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Normalización de datos "
      ],
      "metadata": {
        "id": "TkJ4skFy0LdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea un objeto tipo scaler, que se encargará de normalizar los datos de cada\n",
        "#subconjunto\n",
        "scaler = StandardScaler()\n",
        "#Se normalizan los subconjuntos de entrenamiento y prueba \n",
        "normed_train_data = scaler.fit_transform(train_data)\n",
        "normed_test_data = scaler.fit_transform(test_data)"
      ],
      "metadata": {
        "id": "yo99kIJHz5pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creación y compilación del modelo"
      ],
      "metadata": {
        "id": "cwyX3l5f0xT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se define una función para facilitar la creación de la red densa\n",
        "def build_model():\n",
        "  #A continuación se crea el modelo para la red, definiendo un valor para las\n",
        "  #entradas con el parámetro input_shape=[len(train_data.keys())], y luego\n",
        "  #se agregan capas de neuronas a la red, con la cantidad definida de neuronas\n",
        "  #por capa y la función de activación sigmoide. Por último, se cuenta con una\n",
        "  #única neurona de salida\n",
        "  model = Sequential([\n",
        "    Dense(32, activation='sigmoid', input_shape=[len(train_data.keys())]),\n",
        "    Dense(32, activation='sigmoid'),\n",
        "    #Dense(16, activation='sigmoid'),\n",
        "    Dense(1)\n",
        "  ])\n",
        "\n",
        "  #Se define el optimizador para implementar con la red, así como su tasa de\n",
        "  #aprendizaje y valor de momentum\n",
        "  optimizer = Adam(learning_rate=0.001, beta_1=0.9)\n",
        "\n",
        "  #Se compila el modelo definido, con la función de pérdida tipo Huber y usando\n",
        "  #los errores MAE y MSE como métricas, así como el optimizador definido\n",
        "  model.compile(loss='huber',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  #Finaliza el llamado a la función mediante el retorno del modelo\n",
        "  return model\n",
        "#Se crea el modelo de la red, haciendo un llamado a la función anterior\n",
        "model = build_model()\n",
        "#Con el fin de verificar la creación adecuada del modelo, se muestra un resumen\n",
        "#de este último\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSCzV_Nh0wiT",
        "outputId": "7ecf42e1-2205-4922-fd25-361dd2389cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 32)                384       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,473\n",
            "Trainable params: 1,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Entrenamiento"
      ],
      "metadata": {
        "id": "MfZXUob43CSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se define el número de iteraciones para realizar el entrenamiento\n",
        "EPOCHS = 1000\n",
        "#Asimismo, se calcula la cantidad y frecuencia de las validaciones, según las\n",
        "#iteraciones realizadas\n",
        "CantVal = int(EPOCHS * 0.1)\n",
        "freqVal = int(EPOCHS / CantVal)\n",
        "#Se entrena a la red neuronal, usando el subconjunto de datos de entrenamiento\n",
        "#Además se define que un 20% de este conjunto se utilizará para validación\n",
        "#El inicio del entrenamiento se indica mediante un mensaje en pantalla\n",
        "print(\"Realizando entrenamiento...\")\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels.to_numpy(),\n",
        "  epochs=EPOCHS, validation_split = 0.2, validation_freq=freqVal, verbose=1)\n",
        "#Se indica el final del entrenamiento\n",
        "print(\"Fin del entrenamiento\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWjt-rQr3Emy",
        "outputId": "ca397520-6246-45b1-8df6-dc025f8b4100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Realizando entrenamiento...\n",
            "Epoch 1/1000\n",
            "32/32 [==============================] - 1s 2ms/step - loss: 4.5179 - mae: 5.0179 - mse: 25.9853\n",
            "Epoch 2/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.3096 - mae: 3.8095 - mse: 15.2925\n",
            "Epoch 3/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.1212 - mae: 2.6183 - mse: 7.6094\n",
            "Epoch 4/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.0520 - mae: 1.5224 - mse: 2.9900\n",
            "Epoch 5/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4462 - mae: 0.7906 - mse: 1.0789\n",
            "Epoch 6/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2891 - mae: 0.6689 - mse: 0.6462\n",
            "Epoch 7/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2644 - mae: 0.6331 - mse: 0.5789\n",
            "Epoch 8/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2525 - mae: 0.6086 - mse: 0.5502\n",
            "Epoch 9/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2434 - mae: 0.5876 - mse: 0.5285\n",
            "Epoch 10/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2364 - mae: 0.5700 - mse: 0.5122 - val_loss: 0.2370 - val_mae: 0.5612 - val_mse: 0.5326\n",
            "Epoch 11/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2307 - mae: 0.5547 - mse: 0.4989\n",
            "Epoch 12/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2259 - mae: 0.5444 - mse: 0.4879\n",
            "Epoch 13/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2225 - mae: 0.5370 - mse: 0.4802\n",
            "Epoch 14/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2199 - mae: 0.5314 - mse: 0.4742\n",
            "Epoch 15/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2177 - mae: 0.5289 - mse: 0.4694\n",
            "Epoch 16/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2162 - mae: 0.5270 - mse: 0.4661\n",
            "Epoch 17/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2144 - mae: 0.5234 - mse: 0.4620\n",
            "Epoch 18/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2134 - mae: 0.5228 - mse: 0.4601\n",
            "Epoch 19/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2121 - mae: 0.5188 - mse: 0.4566\n",
            "Epoch 20/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2115 - mae: 0.5216 - mse: 0.4564 - val_loss: 0.2337 - val_mae: 0.5290 - val_mse: 0.5162\n",
            "Epoch 21/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2102 - mae: 0.5170 - mse: 0.4528\n",
            "Epoch 22/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2098 - mae: 0.5190 - mse: 0.4522\n",
            "Epoch 23/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2090 - mae: 0.5159 - mse: 0.4501\n",
            "Epoch 24/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2084 - mae: 0.5163 - mse: 0.4488\n",
            "Epoch 25/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2080 - mae: 0.5159 - mse: 0.4485\n",
            "Epoch 26/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2076 - mae: 0.5157 - mse: 0.4478\n",
            "Epoch 27/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2075 - mae: 0.5125 - mse: 0.4466\n",
            "Epoch 28/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2064 - mae: 0.5123 - mse: 0.4444\n",
            "Epoch 29/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2068 - mae: 0.5153 - mse: 0.4461\n",
            "Epoch 30/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2057 - mae: 0.5116 - mse: 0.4429 - val_loss: 0.2299 - val_mae: 0.5240 - val_mse: 0.5053\n",
            "Epoch 31/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2052 - mae: 0.5137 - mse: 0.4422\n",
            "Epoch 32/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2049 - mae: 0.5111 - mse: 0.4412\n",
            "Epoch 33/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2045 - mae: 0.5117 - mse: 0.4406\n",
            "Epoch 34/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2046 - mae: 0.5101 - mse: 0.4403\n",
            "Epoch 35/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2047 - mae: 0.5151 - mse: 0.4415\n",
            "Epoch 36/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2035 - mae: 0.5086 - mse: 0.4379\n",
            "Epoch 37/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2033 - mae: 0.5094 - mse: 0.4374\n",
            "Epoch 38/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2035 - mae: 0.5110 - mse: 0.4378\n",
            "Epoch 39/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2025 - mae: 0.5109 - mse: 0.4364\n",
            "Epoch 40/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2023 - mae: 0.5080 - mse: 0.4352 - val_loss: 0.2284 - val_mae: 0.5242 - val_mse: 0.5017\n",
            "Epoch 41/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2023 - mae: 0.5103 - mse: 0.4354\n",
            "Epoch 42/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2017 - mae: 0.5085 - mse: 0.4341\n",
            "Epoch 43/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2015 - mae: 0.5076 - mse: 0.4333\n",
            "Epoch 44/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2016 - mae: 0.5107 - mse: 0.4345\n",
            "Epoch 45/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2014 - mae: 0.5061 - mse: 0.4332\n",
            "Epoch 46/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2006 - mae: 0.5075 - mse: 0.4316\n",
            "Epoch 47/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2007 - mae: 0.5077 - mse: 0.4316\n",
            "Epoch 48/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2002 - mae: 0.5070 - mse: 0.4306\n",
            "Epoch 49/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2009 - mae: 0.5090 - mse: 0.4327\n",
            "Epoch 50/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2006 - mae: 0.5046 - mse: 0.4310 - val_loss: 0.2318 - val_mae: 0.5315 - val_mse: 0.5095\n",
            "Epoch 51/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1999 - mae: 0.5068 - mse: 0.4299\n",
            "Epoch 52/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1999 - mae: 0.5061 - mse: 0.4295\n",
            "Epoch 53/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2007 - mae: 0.5077 - mse: 0.4323\n",
            "Epoch 54/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1991 - mae: 0.5058 - mse: 0.4287\n",
            "Epoch 55/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1991 - mae: 0.5044 - mse: 0.4277\n",
            "Epoch 56/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1987 - mae: 0.5055 - mse: 0.4271\n",
            "Epoch 57/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1985 - mae: 0.5039 - mse: 0.4265\n",
            "Epoch 58/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1982 - mae: 0.5049 - mse: 0.4263\n",
            "Epoch 59/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1980 - mae: 0.5023 - mse: 0.4252\n",
            "Epoch 60/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1988 - mae: 0.5057 - mse: 0.4276 - val_loss: 0.2308 - val_mae: 0.5313 - val_mse: 0.5073\n",
            "Epoch 61/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1986 - mae: 0.5049 - mse: 0.4274\n",
            "Epoch 62/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1975 - mae: 0.5032 - mse: 0.4246\n",
            "Epoch 63/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1976 - mae: 0.5043 - mse: 0.4244\n",
            "Epoch 64/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1972 - mae: 0.5021 - mse: 0.4236\n",
            "Epoch 65/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1972 - mae: 0.5012 - mse: 0.4236\n",
            "Epoch 66/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1968 - mae: 0.5021 - mse: 0.4227\n",
            "Epoch 67/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1966 - mae: 0.5011 - mse: 0.4222\n",
            "Epoch 68/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1963 - mae: 0.5032 - mse: 0.4225\n",
            "Epoch 69/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1960 - mae: 0.4984 - mse: 0.4203\n",
            "Epoch 70/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1969 - mae: 0.5039 - mse: 0.4228 - val_loss: 0.2230 - val_mae: 0.5204 - val_mse: 0.4887\n",
            "Epoch 71/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1959 - mae: 0.5005 - mse: 0.4206\n",
            "Epoch 72/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1957 - mae: 0.5024 - mse: 0.4203\n",
            "Epoch 73/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1954 - mae: 0.4999 - mse: 0.4195\n",
            "Epoch 74/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1953 - mae: 0.4983 - mse: 0.4183\n",
            "Epoch 75/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1948 - mae: 0.5006 - mse: 0.4187\n",
            "Epoch 76/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1958 - mae: 0.4992 - mse: 0.4197\n",
            "Epoch 77/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1948 - mae: 0.4989 - mse: 0.4182\n",
            "Epoch 78/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1950 - mae: 0.4994 - mse: 0.4187\n",
            "Epoch 79/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1946 - mae: 0.4989 - mse: 0.4178\n",
            "Epoch 80/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1946 - mae: 0.4996 - mse: 0.4172 - val_loss: 0.2097 - val_mae: 0.5023 - val_mse: 0.4574\n",
            "Epoch 81/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1961 - mae: 0.4986 - mse: 0.4206\n",
            "Epoch 82/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1933 - mae: 0.4965 - mse: 0.4142\n",
            "Epoch 83/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1940 - mae: 0.4977 - mse: 0.4162\n",
            "Epoch 84/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1935 - mae: 0.4986 - mse: 0.4155\n",
            "Epoch 85/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1927 - mae: 0.4941 - mse: 0.4124\n",
            "Epoch 86/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1931 - mae: 0.4984 - mse: 0.4148\n",
            "Epoch 87/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1952 - mae: 0.4993 - mse: 0.4188\n",
            "Epoch 88/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1926 - mae: 0.4941 - mse: 0.4128\n",
            "Epoch 89/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1923 - mae: 0.4951 - mse: 0.4123\n",
            "Epoch 90/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1921 - mae: 0.4943 - mse: 0.4116 - val_loss: 0.2213 - val_mae: 0.5214 - val_mse: 0.4845\n",
            "Epoch 91/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1920 - mae: 0.4950 - mse: 0.4109\n",
            "Epoch 92/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1917 - mae: 0.4950 - mse: 0.4112\n",
            "Epoch 93/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1934 - mae: 0.4969 - mse: 0.4152\n",
            "Epoch 94/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1918 - mae: 0.4938 - mse: 0.4109\n",
            "Epoch 95/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1928 - mae: 0.4972 - mse: 0.4130\n",
            "Epoch 96/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1913 - mae: 0.4920 - mse: 0.4092\n",
            "Epoch 97/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1912 - mae: 0.4935 - mse: 0.4099\n",
            "Epoch 98/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1913 - mae: 0.4932 - mse: 0.4091\n",
            "Epoch 99/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1911 - mae: 0.4919 - mse: 0.4089\n",
            "Epoch 100/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1908 - mae: 0.4917 - mse: 0.4078 - val_loss: 0.2158 - val_mae: 0.5150 - val_mse: 0.4718\n",
            "Epoch 101/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1905 - mae: 0.4936 - mse: 0.4083\n",
            "Epoch 102/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1900 - mae: 0.4923 - mse: 0.4062\n",
            "Epoch 103/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1897 - mae: 0.4907 - mse: 0.4057\n",
            "Epoch 104/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1893 - mae: 0.4903 - mse: 0.4050\n",
            "Epoch 105/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1904 - mae: 0.4930 - mse: 0.4074\n",
            "Epoch 106/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1914 - mae: 0.4933 - mse: 0.4090\n",
            "Epoch 107/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1887 - mae: 0.4879 - mse: 0.4033\n",
            "Epoch 108/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1890 - mae: 0.4886 - mse: 0.4044\n",
            "Epoch 109/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1888 - mae: 0.4922 - mse: 0.4033\n",
            "Epoch 110/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1888 - mae: 0.4904 - mse: 0.4037 - val_loss: 0.2053 - val_mae: 0.5017 - val_mse: 0.4477\n",
            "Epoch 111/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1885 - mae: 0.4886 - mse: 0.4029\n",
            "Epoch 112/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1895 - mae: 0.4886 - mse: 0.4055\n",
            "Epoch 113/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1879 - mae: 0.4879 - mse: 0.4017\n",
            "Epoch 114/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1882 - mae: 0.4885 - mse: 0.4020\n",
            "Epoch 115/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1876 - mae: 0.4867 - mse: 0.4003\n",
            "Epoch 116/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1875 - mae: 0.4866 - mse: 0.4003\n",
            "Epoch 117/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1873 - mae: 0.4868 - mse: 0.4001\n",
            "Epoch 118/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1872 - mae: 0.4876 - mse: 0.3999\n",
            "Epoch 119/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1877 - mae: 0.4879 - mse: 0.4012\n",
            "Epoch 120/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1865 - mae: 0.4849 - mse: 0.3978 - val_loss: 0.2164 - val_mae: 0.5169 - val_mse: 0.4743\n",
            "Epoch 121/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1867 - mae: 0.4868 - mse: 0.3987\n",
            "Epoch 122/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1864 - mae: 0.4859 - mse: 0.3983\n",
            "Epoch 123/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1861 - mae: 0.4854 - mse: 0.3976\n",
            "Epoch 124/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1865 - mae: 0.4864 - mse: 0.3980\n",
            "Epoch 125/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1859 - mae: 0.4831 - mse: 0.3963\n",
            "Epoch 126/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1857 - mae: 0.4850 - mse: 0.3968\n",
            "Epoch 127/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1854 - mae: 0.4848 - mse: 0.3958\n",
            "Epoch 128/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1855 - mae: 0.4836 - mse: 0.3957\n",
            "Epoch 129/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1853 - mae: 0.4853 - mse: 0.3960\n",
            "Epoch 130/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1851 - mae: 0.4831 - mse: 0.3948 - val_loss: 0.2063 - val_mae: 0.5057 - val_mse: 0.4508\n",
            "Epoch 131/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1845 - mae: 0.4816 - mse: 0.3931\n",
            "Epoch 132/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1850 - mae: 0.4838 - mse: 0.3955\n",
            "Epoch 133/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1858 - mae: 0.4868 - mse: 0.3962\n",
            "Epoch 134/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1835 - mae: 0.4811 - mse: 0.3906\n",
            "Epoch 135/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1833 - mae: 0.4824 - mse: 0.3908\n",
            "Epoch 136/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1841 - mae: 0.4779 - mse: 0.3925\n",
            "Epoch 137/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1848 - mae: 0.4825 - mse: 0.3940\n",
            "Epoch 138/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1845 - mae: 0.4845 - mse: 0.3933\n",
            "Epoch 139/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1850 - mae: 0.4806 - mse: 0.3932\n",
            "Epoch 140/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1839 - mae: 0.4841 - mse: 0.3920 - val_loss: 0.2072 - val_mae: 0.5072 - val_mse: 0.4532\n",
            "Epoch 141/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1835 - mae: 0.4807 - mse: 0.3909\n",
            "Epoch 142/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1828 - mae: 0.4796 - mse: 0.3884\n",
            "Epoch 143/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1828 - mae: 0.4807 - mse: 0.3891\n",
            "Epoch 144/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1825 - mae: 0.4788 - mse: 0.3882\n",
            "Epoch 145/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1838 - mae: 0.4832 - mse: 0.3912\n",
            "Epoch 146/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1828 - mae: 0.4798 - mse: 0.3892\n",
            "Epoch 147/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1816 - mae: 0.4808 - mse: 0.3861\n",
            "Epoch 148/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1827 - mae: 0.4813 - mse: 0.3888\n",
            "Epoch 149/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1815 - mae: 0.4773 - mse: 0.3852\n",
            "Epoch 150/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1841 - mae: 0.4834 - mse: 0.3919 - val_loss: 0.2179 - val_mae: 0.5219 - val_mse: 0.4783\n",
            "Epoch 151/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1815 - mae: 0.4782 - mse: 0.3856\n",
            "Epoch 152/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1815 - mae: 0.4780 - mse: 0.3860\n",
            "Epoch 153/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1813 - mae: 0.4771 - mse: 0.3848\n",
            "Epoch 154/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1823 - mae: 0.4798 - mse: 0.3880\n",
            "Epoch 155/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1815 - mae: 0.4781 - mse: 0.3850\n",
            "Epoch 156/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1807 - mae: 0.4782 - mse: 0.3839\n",
            "Epoch 157/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1805 - mae: 0.4766 - mse: 0.3832\n",
            "Epoch 158/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1809 - mae: 0.4783 - mse: 0.3845\n",
            "Epoch 159/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1807 - mae: 0.4760 - mse: 0.3839\n",
            "Epoch 160/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1808 - mae: 0.4787 - mse: 0.3834 - val_loss: 0.2013 - val_mae: 0.5012 - val_mse: 0.4399\n",
            "Epoch 161/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1796 - mae: 0.4750 - mse: 0.3811\n",
            "Epoch 162/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1797 - mae: 0.4785 - mse: 0.3815\n",
            "Epoch 163/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1799 - mae: 0.4764 - mse: 0.3818\n",
            "Epoch 164/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1817 - mae: 0.4772 - mse: 0.3859\n",
            "Epoch 165/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1803 - mae: 0.4779 - mse: 0.3824\n",
            "Epoch 166/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1802 - mae: 0.4779 - mse: 0.3825\n",
            "Epoch 167/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1824 - mae: 0.4805 - mse: 0.3866\n",
            "Epoch 168/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1788 - mae: 0.4758 - mse: 0.3795\n",
            "Epoch 169/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1784 - mae: 0.4734 - mse: 0.3784\n",
            "Epoch 170/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1793 - mae: 0.4753 - mse: 0.3797 - val_loss: 0.2074 - val_mae: 0.5096 - val_mse: 0.4548\n",
            "Epoch 171/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1785 - mae: 0.4744 - mse: 0.3789\n",
            "Epoch 172/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1780 - mae: 0.4716 - mse: 0.3772\n",
            "Epoch 173/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1781 - mae: 0.4745 - mse: 0.3778\n",
            "Epoch 174/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1779 - mae: 0.4741 - mse: 0.3769\n",
            "Epoch 175/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1786 - mae: 0.4744 - mse: 0.3791\n",
            "Epoch 176/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1779 - mae: 0.4733 - mse: 0.3770\n",
            "Epoch 177/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1776 - mae: 0.4724 - mse: 0.3762\n",
            "Epoch 178/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1772 - mae: 0.4722 - mse: 0.3751\n",
            "Epoch 179/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1772 - mae: 0.4725 - mse: 0.3754\n",
            "Epoch 180/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1769 - mae: 0.4714 - mse: 0.3744 - val_loss: 0.2032 - val_mae: 0.5045 - val_mse: 0.4453\n",
            "Epoch 181/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1775 - mae: 0.4750 - mse: 0.3762\n",
            "Epoch 182/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1770 - mae: 0.4724 - mse: 0.3753\n",
            "Epoch 183/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1769 - mae: 0.4693 - mse: 0.3742\n",
            "Epoch 184/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1776 - mae: 0.4725 - mse: 0.3757\n",
            "Epoch 185/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1790 - mae: 0.4760 - mse: 0.3815\n",
            "Epoch 186/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1778 - mae: 0.4733 - mse: 0.3759\n",
            "Epoch 187/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1774 - mae: 0.4724 - mse: 0.3750\n",
            "Epoch 188/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1757 - mae: 0.4700 - mse: 0.3717\n",
            "Epoch 189/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1758 - mae: 0.4717 - mse: 0.3721\n",
            "Epoch 190/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1774 - mae: 0.4716 - mse: 0.3744 - val_loss: 0.1959 - val_mae: 0.4939 - val_mse: 0.4290\n",
            "Epoch 191/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1772 - mae: 0.4735 - mse: 0.3742\n",
            "Epoch 192/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1777 - mae: 0.4744 - mse: 0.3759\n",
            "Epoch 193/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1767 - mae: 0.4751 - mse: 0.3736\n",
            "Epoch 194/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1751 - mae: 0.4713 - mse: 0.3702\n",
            "Epoch 195/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1765 - mae: 0.4720 - mse: 0.3727\n",
            "Epoch 196/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1757 - mae: 0.4716 - mse: 0.3709\n",
            "Epoch 197/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1750 - mae: 0.4687 - mse: 0.3703\n",
            "Epoch 198/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1754 - mae: 0.4712 - mse: 0.3702\n",
            "Epoch 199/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1747 - mae: 0.4709 - mse: 0.3690\n",
            "Epoch 200/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1753 - mae: 0.4708 - mse: 0.3698 - val_loss: 0.1996 - val_mae: 0.5010 - val_mse: 0.4378\n",
            "Epoch 201/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1744 - mae: 0.4696 - mse: 0.3688\n",
            "Epoch 202/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1753 - mae: 0.4713 - mse: 0.3701\n",
            "Epoch 203/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1760 - mae: 0.4713 - mse: 0.3722\n",
            "Epoch 204/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1761 - mae: 0.4724 - mse: 0.3720\n",
            "Epoch 205/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1738 - mae: 0.4690 - mse: 0.3674\n",
            "Epoch 206/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1756 - mae: 0.4703 - mse: 0.3709\n",
            "Epoch 207/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1766 - mae: 0.4744 - mse: 0.3745\n",
            "Epoch 208/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1729 - mae: 0.4692 - mse: 0.3654\n",
            "Epoch 209/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1757 - mae: 0.4729 - mse: 0.3720\n",
            "Epoch 210/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1738 - mae: 0.4706 - mse: 0.3668 - val_loss: 0.1961 - val_mae: 0.4945 - val_mse: 0.4292\n",
            "Epoch 211/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1729 - mae: 0.4666 - mse: 0.3647\n",
            "Epoch 212/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1748 - mae: 0.4712 - mse: 0.3697\n",
            "Epoch 213/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1748 - mae: 0.4717 - mse: 0.3690\n",
            "Epoch 214/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1733 - mae: 0.4683 - mse: 0.3656\n",
            "Epoch 215/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1737 - mae: 0.4694 - mse: 0.3663\n",
            "Epoch 216/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1745 - mae: 0.4728 - mse: 0.3681\n",
            "Epoch 217/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1736 - mae: 0.4692 - mse: 0.3661\n",
            "Epoch 218/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1727 - mae: 0.4666 - mse: 0.3646\n",
            "Epoch 219/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1727 - mae: 0.4682 - mse: 0.3639\n",
            "Epoch 220/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1722 - mae: 0.4669 - mse: 0.3635 - val_loss: 0.2152 - val_mae: 0.5232 - val_mse: 0.4743\n",
            "Epoch 221/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1740 - mae: 0.4707 - mse: 0.3667\n",
            "Epoch 222/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1718 - mae: 0.4658 - mse: 0.3624\n",
            "Epoch 223/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1719 - mae: 0.4664 - mse: 0.3627\n",
            "Epoch 224/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1710 - mae: 0.4668 - mse: 0.3604\n",
            "Epoch 225/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1728 - mae: 0.4675 - mse: 0.3636\n",
            "Epoch 226/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1714 - mae: 0.4652 - mse: 0.3613\n",
            "Epoch 227/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1713 - mae: 0.4662 - mse: 0.3615\n",
            "Epoch 228/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1720 - mae: 0.4667 - mse: 0.3630\n",
            "Epoch 229/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1709 - mae: 0.4654 - mse: 0.3603\n",
            "Epoch 230/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1715 - mae: 0.4658 - mse: 0.3614 - val_loss: 0.2073 - val_mae: 0.5132 - val_mse: 0.4562\n",
            "Epoch 231/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1722 - mae: 0.4659 - mse: 0.3635\n",
            "Epoch 232/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1714 - mae: 0.4664 - mse: 0.3619\n",
            "Epoch 233/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1715 - mae: 0.4662 - mse: 0.3620\n",
            "Epoch 234/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1719 - mae: 0.4674 - mse: 0.3630\n",
            "Epoch 235/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1741 - mae: 0.4706 - mse: 0.3665\n",
            "Epoch 236/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1726 - mae: 0.4679 - mse: 0.3643\n",
            "Epoch 237/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1706 - mae: 0.4645 - mse: 0.3593\n",
            "Epoch 238/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1706 - mae: 0.4668 - mse: 0.3595\n",
            "Epoch 239/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1699 - mae: 0.4644 - mse: 0.3582\n",
            "Epoch 240/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1697 - mae: 0.4645 - mse: 0.3577 - val_loss: 0.1957 - val_mae: 0.4952 - val_mse: 0.4297\n",
            "Epoch 241/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1706 - mae: 0.4671 - mse: 0.3592\n",
            "Epoch 242/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1702 - mae: 0.4642 - mse: 0.3589\n",
            "Epoch 243/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1713 - mae: 0.4639 - mse: 0.3612\n",
            "Epoch 244/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1691 - mae: 0.4632 - mse: 0.3561\n",
            "Epoch 245/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1711 - mae: 0.4677 - mse: 0.3602\n",
            "Epoch 246/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1696 - mae: 0.4647 - mse: 0.3573\n",
            "Epoch 247/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1692 - mae: 0.4639 - mse: 0.3564\n",
            "Epoch 248/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1697 - mae: 0.4633 - mse: 0.3578\n",
            "Epoch 249/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1688 - mae: 0.4628 - mse: 0.3551\n",
            "Epoch 250/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1693 - mae: 0.4634 - mse: 0.3567 - val_loss: 0.2105 - val_mae: 0.5180 - val_mse: 0.4642\n",
            "Epoch 251/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1704 - mae: 0.4663 - mse: 0.3592\n",
            "Epoch 252/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1698 - mae: 0.4637 - mse: 0.3576\n",
            "Epoch 253/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1689 - mae: 0.4623 - mse: 0.3556\n",
            "Epoch 254/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1693 - mae: 0.4626 - mse: 0.3563\n",
            "Epoch 255/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1696 - mae: 0.4641 - mse: 0.3580\n",
            "Epoch 256/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1688 - mae: 0.4605 - mse: 0.3556\n",
            "Epoch 257/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1689 - mae: 0.4633 - mse: 0.3559\n",
            "Epoch 258/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1692 - mae: 0.4652 - mse: 0.3565\n",
            "Epoch 259/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1695 - mae: 0.4651 - mse: 0.3567\n",
            "Epoch 260/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1705 - mae: 0.4646 - mse: 0.3593 - val_loss: 0.1932 - val_mae: 0.4920 - val_mse: 0.4252\n",
            "Epoch 261/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1691 - mae: 0.4652 - mse: 0.3567\n",
            "Epoch 262/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1684 - mae: 0.4627 - mse: 0.3542\n",
            "Epoch 263/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1673 - mae: 0.4594 - mse: 0.3520\n",
            "Epoch 264/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1677 - mae: 0.4616 - mse: 0.3532\n",
            "Epoch 265/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1672 - mae: 0.4608 - mse: 0.3518\n",
            "Epoch 266/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1672 - mae: 0.4599 - mse: 0.3520\n",
            "Epoch 267/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1674 - mae: 0.4609 - mse: 0.3521\n",
            "Epoch 268/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1673 - mae: 0.4605 - mse: 0.3524\n",
            "Epoch 269/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1667 - mae: 0.4593 - mse: 0.3506\n",
            "Epoch 270/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.4607 - mse: 0.3503 - val_loss: 0.1977 - val_mae: 0.4988 - val_mse: 0.4361\n",
            "Epoch 271/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1666 - mae: 0.4578 - mse: 0.3506\n",
            "Epoch 272/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1673 - mae: 0.4595 - mse: 0.3523\n",
            "Epoch 273/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1667 - mae: 0.4609 - mse: 0.3511\n",
            "Epoch 274/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1666 - mae: 0.4593 - mse: 0.3512\n",
            "Epoch 275/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1672 - mae: 0.4604 - mse: 0.3516\n",
            "Epoch 276/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1657 - mae: 0.4581 - mse: 0.3487\n",
            "Epoch 277/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1665 - mae: 0.4598 - mse: 0.3505\n",
            "Epoch 278/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1658 - mae: 0.4582 - mse: 0.3489\n",
            "Epoch 279/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1671 - mae: 0.4568 - mse: 0.3523\n",
            "Epoch 280/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1669 - mae: 0.4610 - mse: 0.3512 - val_loss: 0.2008 - val_mae: 0.5029 - val_mse: 0.4438\n",
            "Epoch 281/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1654 - mae: 0.4565 - mse: 0.3482\n",
            "Epoch 282/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1678 - mae: 0.4583 - mse: 0.3540\n",
            "Epoch 283/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1659 - mae: 0.4578 - mse: 0.3498\n",
            "Epoch 284/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1647 - mae: 0.4562 - mse: 0.3467\n",
            "Epoch 285/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1662 - mae: 0.4597 - mse: 0.3495\n",
            "Epoch 286/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1642 - mae: 0.4561 - mse: 0.3461\n",
            "Epoch 287/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1644 - mae: 0.4573 - mse: 0.3459\n",
            "Epoch 288/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1646 - mae: 0.4578 - mse: 0.3459\n",
            "Epoch 289/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1649 - mae: 0.4573 - mse: 0.3471\n",
            "Epoch 290/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1643 - mae: 0.4556 - mse: 0.3457 - val_loss: 0.2029 - val_mae: 0.5079 - val_mse: 0.4486\n",
            "Epoch 291/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1640 - mae: 0.4548 - mse: 0.3452\n",
            "Epoch 292/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1649 - mae: 0.4576 - mse: 0.3474\n",
            "Epoch 293/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1648 - mae: 0.4563 - mse: 0.3467\n",
            "Epoch 294/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1659 - mae: 0.4565 - mse: 0.3487\n",
            "Epoch 295/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1652 - mae: 0.4561 - mse: 0.3484\n",
            "Epoch 296/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1646 - mae: 0.4586 - mse: 0.3458\n",
            "Epoch 297/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1638 - mae: 0.4547 - mse: 0.3444\n",
            "Epoch 298/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1631 - mae: 0.4526 - mse: 0.3425\n",
            "Epoch 299/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1641 - mae: 0.4557 - mse: 0.3455\n",
            "Epoch 300/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1632 - mae: 0.4531 - mse: 0.3430 - val_loss: 0.2134 - val_mae: 0.5250 - val_mse: 0.4728\n",
            "Epoch 301/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1630 - mae: 0.4544 - mse: 0.3431\n",
            "Epoch 302/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1626 - mae: 0.4535 - mse: 0.3418\n",
            "Epoch 303/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1640 - mae: 0.4568 - mse: 0.3446\n",
            "Epoch 304/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1637 - mae: 0.4524 - mse: 0.3440\n",
            "Epoch 305/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1621 - mae: 0.4521 - mse: 0.3407\n",
            "Epoch 306/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1624 - mae: 0.4524 - mse: 0.3418\n",
            "Epoch 307/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1625 - mae: 0.4520 - mse: 0.3421\n",
            "Epoch 308/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1623 - mae: 0.4534 - mse: 0.3412\n",
            "Epoch 309/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1629 - mae: 0.4547 - mse: 0.3425\n",
            "Epoch 310/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1635 - mae: 0.4538 - mse: 0.3443 - val_loss: 0.2054 - val_mae: 0.5121 - val_mse: 0.4548\n",
            "Epoch 311/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1624 - mae: 0.4522 - mse: 0.3418\n",
            "Epoch 312/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1620 - mae: 0.4521 - mse: 0.3403\n",
            "Epoch 313/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1623 - mae: 0.4538 - mse: 0.3407\n",
            "Epoch 314/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1613 - mae: 0.4506 - mse: 0.3391\n",
            "Epoch 315/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1614 - mae: 0.4506 - mse: 0.3385\n",
            "Epoch 316/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1612 - mae: 0.4503 - mse: 0.3385\n",
            "Epoch 317/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1585 - mae: 0.4469 - mse: 0.3323\n",
            "Epoch 318/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1638 - mae: 0.4563 - mse: 0.3438\n",
            "Epoch 319/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1611 - mae: 0.4511 - mse: 0.3381\n",
            "Epoch 320/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1617 - mae: 0.4514 - mse: 0.3397 - val_loss: 0.2025 - val_mae: 0.5076 - val_mse: 0.4493\n",
            "Epoch 321/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1600 - mae: 0.4494 - mse: 0.3362\n",
            "Epoch 322/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1604 - mae: 0.4477 - mse: 0.3371\n",
            "Epoch 323/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1593 - mae: 0.4484 - mse: 0.3347\n",
            "Epoch 324/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1602 - mae: 0.4480 - mse: 0.3366\n",
            "Epoch 325/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1599 - mae: 0.4481 - mse: 0.3359\n",
            "Epoch 326/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1593 - mae: 0.4483 - mse: 0.3352\n",
            "Epoch 327/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1593 - mae: 0.4461 - mse: 0.3343\n",
            "Epoch 328/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1601 - mae: 0.4493 - mse: 0.3364\n",
            "Epoch 329/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1602 - mae: 0.4467 - mse: 0.3367\n",
            "Epoch 330/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1596 - mae: 0.4488 - mse: 0.3351 - val_loss: 0.2053 - val_mae: 0.5135 - val_mse: 0.4567\n",
            "Epoch 331/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1585 - mae: 0.4473 - mse: 0.3331\n",
            "Epoch 332/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1587 - mae: 0.4457 - mse: 0.3332\n",
            "Epoch 333/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1589 - mae: 0.4464 - mse: 0.3340\n",
            "Epoch 334/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1587 - mae: 0.4456 - mse: 0.3327\n",
            "Epoch 335/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1583 - mae: 0.4470 - mse: 0.3329\n",
            "Epoch 336/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1585 - mae: 0.4452 - mse: 0.3333\n",
            "Epoch 337/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1590 - mae: 0.4475 - mse: 0.3340\n",
            "Epoch 338/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1607 - mae: 0.4492 - mse: 0.3373\n",
            "Epoch 339/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1585 - mae: 0.4432 - mse: 0.3323\n",
            "Epoch 340/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1585 - mae: 0.4469 - mse: 0.3331 - val_loss: 0.2090 - val_mae: 0.5197 - val_mse: 0.4657\n",
            "Epoch 341/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1588 - mae: 0.4482 - mse: 0.3332\n",
            "Epoch 342/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1574 - mae: 0.4441 - mse: 0.3307\n",
            "Epoch 343/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1576 - mae: 0.4465 - mse: 0.3304\n",
            "Epoch 344/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1585 - mae: 0.4452 - mse: 0.3328\n",
            "Epoch 345/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1590 - mae: 0.4458 - mse: 0.3335\n",
            "Epoch 346/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1582 - mae: 0.4471 - mse: 0.3316\n",
            "Epoch 347/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1573 - mae: 0.4447 - mse: 0.3297\n",
            "Epoch 348/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1564 - mae: 0.4420 - mse: 0.3279\n",
            "Epoch 349/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1565 - mae: 0.4413 - mse: 0.3287\n",
            "Epoch 350/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1575 - mae: 0.4448 - mse: 0.3309 - val_loss: 0.2090 - val_mae: 0.5199 - val_mse: 0.4666\n",
            "Epoch 351/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1557 - mae: 0.4442 - mse: 0.3259\n",
            "Epoch 352/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1581 - mae: 0.4426 - mse: 0.3314\n",
            "Epoch 353/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1559 - mae: 0.4413 - mse: 0.3270\n",
            "Epoch 354/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1560 - mae: 0.4411 - mse: 0.3271\n",
            "Epoch 355/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1561 - mae: 0.4413 - mse: 0.3280\n",
            "Epoch 356/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1560 - mae: 0.4407 - mse: 0.3279\n",
            "Epoch 357/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1554 - mae: 0.4402 - mse: 0.3258\n",
            "Epoch 358/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1548 - mae: 0.4399 - mse: 0.3247\n",
            "Epoch 359/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1549 - mae: 0.4400 - mse: 0.3249\n",
            "Epoch 360/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1565 - mae: 0.4431 - mse: 0.3281 - val_loss: 0.2066 - val_mae: 0.5151 - val_mse: 0.4627\n",
            "Epoch 361/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1552 - mae: 0.4404 - mse: 0.3261\n",
            "Epoch 362/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1552 - mae: 0.4424 - mse: 0.3255\n",
            "Epoch 363/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1550 - mae: 0.4395 - mse: 0.3249\n",
            "Epoch 364/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1548 - mae: 0.4379 - mse: 0.3248\n",
            "Epoch 365/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1547 - mae: 0.4385 - mse: 0.3243\n",
            "Epoch 366/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1557 - mae: 0.4415 - mse: 0.3267\n",
            "Epoch 367/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1546 - mae: 0.4403 - mse: 0.3242\n",
            "Epoch 368/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1545 - mae: 0.4389 - mse: 0.3240\n",
            "Epoch 369/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1557 - mae: 0.4407 - mse: 0.3273\n",
            "Epoch 370/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1536 - mae: 0.4352 - mse: 0.3223 - val_loss: 0.2148 - val_mae: 0.5296 - val_mse: 0.4821\n",
            "Epoch 371/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1535 - mae: 0.4384 - mse: 0.3221\n",
            "Epoch 372/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1544 - mae: 0.4407 - mse: 0.3231\n",
            "Epoch 373/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1551 - mae: 0.4427 - mse: 0.3257\n",
            "Epoch 374/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1543 - mae: 0.4366 - mse: 0.3240\n",
            "Epoch 375/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1535 - mae: 0.4365 - mse: 0.3215\n",
            "Epoch 376/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1541 - mae: 0.4368 - mse: 0.3237\n",
            "Epoch 377/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1536 - mae: 0.4364 - mse: 0.3218\n",
            "Epoch 378/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1528 - mae: 0.4359 - mse: 0.3205\n",
            "Epoch 379/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1541 - mae: 0.4385 - mse: 0.3230\n",
            "Epoch 380/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1558 - mae: 0.4395 - mse: 0.3270 - val_loss: 0.2138 - val_mae: 0.5276 - val_mse: 0.4807\n",
            "Epoch 381/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1522 - mae: 0.4342 - mse: 0.3190\n",
            "Epoch 382/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1520 - mae: 0.4339 - mse: 0.3188\n",
            "Epoch 383/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1519 - mae: 0.4349 - mse: 0.3186\n",
            "Epoch 384/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1518 - mae: 0.4350 - mse: 0.3178\n",
            "Epoch 385/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1518 - mae: 0.4324 - mse: 0.3181\n",
            "Epoch 386/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1519 - mae: 0.4344 - mse: 0.3189\n",
            "Epoch 387/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1515 - mae: 0.4331 - mse: 0.3173\n",
            "Epoch 388/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1511 - mae: 0.4343 - mse: 0.3171\n",
            "Epoch 389/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1513 - mae: 0.4332 - mse: 0.3171\n",
            "Epoch 390/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1512 - mae: 0.4313 - mse: 0.3165 - val_loss: 0.2197 - val_mae: 0.5384 - val_mse: 0.4947\n",
            "Epoch 391/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1519 - mae: 0.4341 - mse: 0.3182\n",
            "Epoch 392/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1511 - mae: 0.4316 - mse: 0.3169\n",
            "Epoch 393/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1509 - mae: 0.4323 - mse: 0.3162\n",
            "Epoch 394/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1507 - mae: 0.4337 - mse: 0.3162\n",
            "Epoch 395/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1507 - mae: 0.4328 - mse: 0.3153\n",
            "Epoch 396/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1506 - mae: 0.4324 - mse: 0.3157\n",
            "Epoch 397/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1495 - mae: 0.4301 - mse: 0.3130\n",
            "Epoch 398/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1502 - mae: 0.4327 - mse: 0.3142\n",
            "Epoch 399/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1499 - mae: 0.4306 - mse: 0.3137\n",
            "Epoch 400/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1482 - mae: 0.4294 - mse: 0.3097 - val_loss: 0.2127 - val_mae: 0.5175 - val_mse: 0.4819\n",
            "Epoch 401/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1533 - mae: 0.4352 - mse: 0.3207\n",
            "Epoch 402/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1512 - mae: 0.4322 - mse: 0.3168\n",
            "Epoch 403/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1500 - mae: 0.4317 - mse: 0.3144\n",
            "Epoch 404/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1487 - mae: 0.4313 - mse: 0.3116\n",
            "Epoch 405/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1489 - mae: 0.4296 - mse: 0.3117\n",
            "Epoch 406/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1499 - mae: 0.4306 - mse: 0.3137\n",
            "Epoch 407/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1489 - mae: 0.4287 - mse: 0.3122\n",
            "Epoch 408/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1480 - mae: 0.4279 - mse: 0.3099\n",
            "Epoch 409/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1503 - mae: 0.4322 - mse: 0.3147\n",
            "Epoch 410/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1493 - mae: 0.4300 - mse: 0.3123 - val_loss: 0.2168 - val_mae: 0.5339 - val_mse: 0.4901\n",
            "Epoch 411/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1490 - mae: 0.4291 - mse: 0.3117\n",
            "Epoch 412/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1481 - mae: 0.4288 - mse: 0.3102\n",
            "Epoch 413/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1487 - mae: 0.4288 - mse: 0.3104\n",
            "Epoch 414/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1488 - mae: 0.4276 - mse: 0.3120\n",
            "Epoch 415/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1477 - mae: 0.4272 - mse: 0.3091\n",
            "Epoch 416/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1487 - mae: 0.4295 - mse: 0.3114\n",
            "Epoch 417/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1475 - mae: 0.4267 - mse: 0.3086\n",
            "Epoch 418/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1485 - mae: 0.4274 - mse: 0.3110\n",
            "Epoch 419/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1474 - mae: 0.4265 - mse: 0.3085\n",
            "Epoch 420/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1484 - mae: 0.4266 - mse: 0.3109 - val_loss: 0.2142 - val_mae: 0.5272 - val_mse: 0.4865\n",
            "Epoch 421/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1463 - mae: 0.4261 - mse: 0.3062\n",
            "Epoch 422/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1477 - mae: 0.4269 - mse: 0.3092\n",
            "Epoch 423/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1505 - mae: 0.4325 - mse: 0.3161\n",
            "Epoch 424/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1469 - mae: 0.4268 - mse: 0.3073\n",
            "Epoch 425/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1457 - mae: 0.4239 - mse: 0.3047\n",
            "Epoch 426/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1470 - mae: 0.4243 - mse: 0.3075\n",
            "Epoch 427/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1471 - mae: 0.4260 - mse: 0.3076\n",
            "Epoch 428/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1477 - mae: 0.4260 - mse: 0.3077\n",
            "Epoch 429/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1488 - mae: 0.4287 - mse: 0.3115\n",
            "Epoch 430/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1463 - mae: 0.4274 - mse: 0.3052 - val_loss: 0.2235 - val_mae: 0.5433 - val_mse: 0.5074\n",
            "Epoch 431/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1456 - mae: 0.4228 - mse: 0.3043\n",
            "Epoch 432/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1455 - mae: 0.4224 - mse: 0.3043\n",
            "Epoch 433/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1471 - mae: 0.4253 - mse: 0.3075\n",
            "Epoch 434/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1459 - mae: 0.4257 - mse: 0.3050\n",
            "Epoch 435/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1447 - mae: 0.4233 - mse: 0.3023\n",
            "Epoch 436/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1448 - mae: 0.4225 - mse: 0.3027\n",
            "Epoch 437/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1471 - mae: 0.4239 - mse: 0.3074\n",
            "Epoch 438/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1451 - mae: 0.4240 - mse: 0.3036\n",
            "Epoch 439/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1441 - mae: 0.4207 - mse: 0.3012\n",
            "Epoch 440/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1455 - mae: 0.4226 - mse: 0.3044 - val_loss: 0.2251 - val_mae: 0.5459 - val_mse: 0.5126\n",
            "Epoch 441/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1443 - mae: 0.4213 - mse: 0.3016\n",
            "Epoch 442/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1446 - mae: 0.4233 - mse: 0.3022\n",
            "Epoch 443/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1440 - mae: 0.4196 - mse: 0.3008\n",
            "Epoch 444/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1437 - mae: 0.4211 - mse: 0.3003\n",
            "Epoch 445/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1461 - mae: 0.4248 - mse: 0.3056\n",
            "Epoch 446/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1444 - mae: 0.4211 - mse: 0.3020\n",
            "Epoch 447/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1434 - mae: 0.4208 - mse: 0.2992\n",
            "Epoch 448/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1441 - mae: 0.4197 - mse: 0.3012\n",
            "Epoch 449/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1451 - mae: 0.4230 - mse: 0.3032\n",
            "Epoch 450/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1426 - mae: 0.4192 - mse: 0.2981 - val_loss: 0.2181 - val_mae: 0.5333 - val_mse: 0.4976\n",
            "Epoch 451/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1437 - mae: 0.4199 - mse: 0.3004\n",
            "Epoch 452/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1435 - mae: 0.4196 - mse: 0.3002\n",
            "Epoch 453/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1434 - mae: 0.4196 - mse: 0.2993\n",
            "Epoch 454/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1425 - mae: 0.4184 - mse: 0.2975\n",
            "Epoch 455/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1431 - mae: 0.4195 - mse: 0.2992\n",
            "Epoch 456/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1441 - mae: 0.4201 - mse: 0.3004\n",
            "Epoch 457/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1437 - mae: 0.4198 - mse: 0.2996\n",
            "Epoch 458/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1423 - mae: 0.4187 - mse: 0.2975\n",
            "Epoch 459/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1421 - mae: 0.4181 - mse: 0.2968\n",
            "Epoch 460/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1431 - mae: 0.4203 - mse: 0.2985 - val_loss: 0.2197 - val_mae: 0.5357 - val_mse: 0.5017\n",
            "Epoch 461/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1427 - mae: 0.4186 - mse: 0.2979\n",
            "Epoch 462/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1419 - mae: 0.4186 - mse: 0.2963\n",
            "Epoch 463/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1435 - mae: 0.4182 - mse: 0.2996\n",
            "Epoch 464/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1437 - mae: 0.4215 - mse: 0.3006\n",
            "Epoch 465/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1419 - mae: 0.4175 - mse: 0.2959\n",
            "Epoch 466/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1416 - mae: 0.4174 - mse: 0.2953\n",
            "Epoch 467/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1412 - mae: 0.4166 - mse: 0.2950\n",
            "Epoch 468/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1413 - mae: 0.4169 - mse: 0.2951\n",
            "Epoch 469/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1422 - mae: 0.4153 - mse: 0.2972\n",
            "Epoch 470/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1413 - mae: 0.4144 - mse: 0.2950 - val_loss: 0.2276 - val_mae: 0.5494 - val_mse: 0.5203\n",
            "Epoch 471/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1410 - mae: 0.4175 - mse: 0.2939\n",
            "Epoch 472/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1408 - mae: 0.4152 - mse: 0.2933\n",
            "Epoch 473/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1412 - mae: 0.4139 - mse: 0.2946\n",
            "Epoch 474/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1416 - mae: 0.4173 - mse: 0.2953\n",
            "Epoch 475/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1408 - mae: 0.4151 - mse: 0.2934\n",
            "Epoch 476/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1399 - mae: 0.4146 - mse: 0.2917\n",
            "Epoch 477/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1404 - mae: 0.4154 - mse: 0.2928\n",
            "Epoch 478/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1434 - mae: 0.4137 - mse: 0.2995\n",
            "Epoch 479/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1400 - mae: 0.4153 - mse: 0.2925\n",
            "Epoch 480/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1407 - mae: 0.4164 - mse: 0.2932 - val_loss: 0.2196 - val_mae: 0.5324 - val_mse: 0.5042\n",
            "Epoch 481/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1404 - mae: 0.4142 - mse: 0.2927\n",
            "Epoch 482/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1415 - mae: 0.4142 - mse: 0.2953\n",
            "Epoch 483/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1394 - mae: 0.4155 - mse: 0.2907\n",
            "Epoch 484/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1400 - mae: 0.4144 - mse: 0.2917\n",
            "Epoch 485/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1398 - mae: 0.4135 - mse: 0.2912\n",
            "Epoch 486/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1389 - mae: 0.4123 - mse: 0.2898\n",
            "Epoch 487/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1381 - mae: 0.4101 - mse: 0.2879\n",
            "Epoch 488/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1391 - mae: 0.4113 - mse: 0.2899\n",
            "Epoch 489/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1391 - mae: 0.4125 - mse: 0.2896\n",
            "Epoch 490/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1388 - mae: 0.4121 - mse: 0.2893 - val_loss: 0.2237 - val_mae: 0.5406 - val_mse: 0.5131\n",
            "Epoch 491/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1378 - mae: 0.4107 - mse: 0.2871\n",
            "Epoch 492/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1380 - mae: 0.4100 - mse: 0.2877\n",
            "Epoch 493/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1387 - mae: 0.4114 - mse: 0.2893\n",
            "Epoch 494/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1392 - mae: 0.4137 - mse: 0.2906\n",
            "Epoch 495/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1374 - mae: 0.4064 - mse: 0.2865\n",
            "Epoch 496/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1396 - mae: 0.4144 - mse: 0.2904\n",
            "Epoch 497/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1378 - mae: 0.4118 - mse: 0.2867\n",
            "Epoch 498/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1380 - mae: 0.4099 - mse: 0.2875\n",
            "Epoch 499/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1370 - mae: 0.4089 - mse: 0.2853\n",
            "Epoch 500/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1384 - mae: 0.4082 - mse: 0.2885 - val_loss: 0.2246 - val_mae: 0.5432 - val_mse: 0.5154\n",
            "Epoch 501/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1380 - mae: 0.4103 - mse: 0.2875\n",
            "Epoch 502/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1382 - mae: 0.4116 - mse: 0.2877\n",
            "Epoch 503/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1383 - mae: 0.4093 - mse: 0.2883\n",
            "Epoch 504/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1393 - mae: 0.4108 - mse: 0.2904\n",
            "Epoch 505/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1375 - mae: 0.4115 - mse: 0.2868\n",
            "Epoch 506/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1365 - mae: 0.4083 - mse: 0.2840\n",
            "Epoch 507/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1384 - mae: 0.4103 - mse: 0.2882\n",
            "Epoch 508/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1375 - mae: 0.4088 - mse: 0.2862\n",
            "Epoch 509/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1371 - mae: 0.4080 - mse: 0.2857\n",
            "Epoch 510/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1369 - mae: 0.4122 - mse: 0.2855 - val_loss: 0.2251 - val_mae: 0.5425 - val_mse: 0.5159\n",
            "Epoch 511/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1371 - mae: 0.4063 - mse: 0.2857\n",
            "Epoch 512/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1360 - mae: 0.4071 - mse: 0.2828\n",
            "Epoch 513/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1358 - mae: 0.4076 - mse: 0.2831\n",
            "Epoch 514/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1383 - mae: 0.4124 - mse: 0.2879\n",
            "Epoch 515/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1369 - mae: 0.4099 - mse: 0.2849\n",
            "Epoch 516/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1361 - mae: 0.4041 - mse: 0.2835\n",
            "Epoch 517/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1363 - mae: 0.4080 - mse: 0.2833\n",
            "Epoch 518/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1359 - mae: 0.4059 - mse: 0.2825\n",
            "Epoch 519/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1353 - mae: 0.4058 - mse: 0.2817\n",
            "Epoch 520/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1370 - mae: 0.4104 - mse: 0.2853 - val_loss: 0.2269 - val_mae: 0.5453 - val_mse: 0.5207\n",
            "Epoch 521/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1354 - mae: 0.4049 - mse: 0.2817\n",
            "Epoch 522/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1368 - mae: 0.4098 - mse: 0.2847\n",
            "Epoch 523/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1364 - mae: 0.4075 - mse: 0.2841\n",
            "Epoch 524/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1360 - mae: 0.4079 - mse: 0.2828\n",
            "Epoch 525/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1346 - mae: 0.4021 - mse: 0.2799\n",
            "Epoch 526/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1346 - mae: 0.4055 - mse: 0.2797\n",
            "Epoch 527/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1347 - mae: 0.4038 - mse: 0.2806\n",
            "Epoch 528/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1352 - mae: 0.4038 - mse: 0.2812\n",
            "Epoch 529/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1355 - mae: 0.4070 - mse: 0.2815\n",
            "Epoch 530/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1346 - mae: 0.4028 - mse: 0.2800 - val_loss: 0.2299 - val_mae: 0.5492 - val_mse: 0.5274\n",
            "Epoch 531/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1338 - mae: 0.4041 - mse: 0.2780\n",
            "Epoch 532/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1346 - mae: 0.4054 - mse: 0.2805\n",
            "Epoch 533/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1357 - mae: 0.4080 - mse: 0.2817\n",
            "Epoch 534/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1346 - mae: 0.4033 - mse: 0.2799\n",
            "Epoch 535/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1351 - mae: 0.4055 - mse: 0.2803\n",
            "Epoch 536/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1347 - mae: 0.4050 - mse: 0.2802\n",
            "Epoch 537/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1345 - mae: 0.4033 - mse: 0.2789\n",
            "Epoch 538/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1329 - mae: 0.4011 - mse: 0.2764\n",
            "Epoch 539/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1343 - mae: 0.4029 - mse: 0.2794\n",
            "Epoch 540/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1335 - mae: 0.4036 - mse: 0.2773 - val_loss: 0.2424 - val_mae: 0.5696 - val_mse: 0.5553\n",
            "Epoch 541/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1337 - mae: 0.4031 - mse: 0.2784\n",
            "Epoch 542/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1327 - mae: 0.4009 - mse: 0.2754\n",
            "Epoch 543/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1339 - mae: 0.4035 - mse: 0.2783\n",
            "Epoch 544/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1338 - mae: 0.4028 - mse: 0.2782\n",
            "Epoch 545/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1350 - mae: 0.4047 - mse: 0.2804\n",
            "Epoch 546/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1334 - mae: 0.4023 - mse: 0.2775\n",
            "Epoch 547/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1336 - mae: 0.4009 - mse: 0.2773\n",
            "Epoch 548/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1334 - mae: 0.4039 - mse: 0.2770\n",
            "Epoch 549/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1326 - mae: 0.4018 - mse: 0.2753\n",
            "Epoch 550/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1319 - mae: 0.3994 - mse: 0.2742 - val_loss: 0.2399 - val_mae: 0.5671 - val_mse: 0.5503\n",
            "Epoch 551/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1323 - mae: 0.4007 - mse: 0.2744\n",
            "Epoch 552/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1326 - mae: 0.4005 - mse: 0.2751\n",
            "Epoch 553/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1337 - mae: 0.4045 - mse: 0.2779\n",
            "Epoch 554/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1332 - mae: 0.4021 - mse: 0.2761\n",
            "Epoch 555/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1337 - mae: 0.4018 - mse: 0.2774\n",
            "Epoch 556/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1321 - mae: 0.4029 - mse: 0.2739\n",
            "Epoch 557/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1327 - mae: 0.4011 - mse: 0.2758\n",
            "Epoch 558/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1328 - mae: 0.4009 - mse: 0.2758\n",
            "Epoch 559/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1315 - mae: 0.3986 - mse: 0.2728\n",
            "Epoch 560/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1316 - mae: 0.3977 - mse: 0.2729 - val_loss: 0.2284 - val_mae: 0.5454 - val_mse: 0.5256\n",
            "Epoch 561/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1323 - mae: 0.4004 - mse: 0.2751\n",
            "Epoch 562/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1320 - mae: 0.4004 - mse: 0.2740\n",
            "Epoch 563/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1324 - mae: 0.4009 - mse: 0.2747\n",
            "Epoch 564/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1310 - mae: 0.3984 - mse: 0.2717\n",
            "Epoch 565/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1339 - mae: 0.4008 - mse: 0.2780\n",
            "Epoch 566/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1314 - mae: 0.4004 - mse: 0.2727\n",
            "Epoch 567/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1305 - mae: 0.3968 - mse: 0.2701\n",
            "Epoch 568/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1330 - mae: 0.4021 - mse: 0.2763\n",
            "Epoch 569/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1332 - mae: 0.4051 - mse: 0.2758\n",
            "Epoch 570/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1303 - mae: 0.3970 - mse: 0.2700 - val_loss: 0.2380 - val_mae: 0.5633 - val_mse: 0.5461\n",
            "Epoch 571/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1304 - mae: 0.3979 - mse: 0.2702\n",
            "Epoch 572/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1300 - mae: 0.3971 - mse: 0.2694\n",
            "Epoch 573/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1304 - mae: 0.3951 - mse: 0.2705\n",
            "Epoch 574/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1311 - mae: 0.3994 - mse: 0.2720\n",
            "Epoch 575/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1317 - mae: 0.4023 - mse: 0.2732\n",
            "Epoch 576/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1304 - mae: 0.3967 - mse: 0.2699\n",
            "Epoch 577/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1299 - mae: 0.3957 - mse: 0.2690\n",
            "Epoch 578/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1294 - mae: 0.3955 - mse: 0.2681\n",
            "Epoch 579/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1304 - mae: 0.3980 - mse: 0.2702\n",
            "Epoch 580/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1289 - mae: 0.3938 - mse: 0.2673 - val_loss: 0.2343 - val_mae: 0.5557 - val_mse: 0.5380\n",
            "Epoch 581/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1293 - mae: 0.3954 - mse: 0.2683\n",
            "Epoch 582/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1315 - mae: 0.4001 - mse: 0.2720\n",
            "Epoch 583/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1302 - mae: 0.3971 - mse: 0.2701\n",
            "Epoch 584/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1288 - mae: 0.3951 - mse: 0.2666\n",
            "Epoch 585/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1294 - mae: 0.3946 - mse: 0.2680\n",
            "Epoch 586/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1287 - mae: 0.3947 - mse: 0.2663\n",
            "Epoch 587/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1301 - mae: 0.3966 - mse: 0.2695\n",
            "Epoch 588/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1288 - mae: 0.3960 - mse: 0.2669\n",
            "Epoch 589/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1293 - mae: 0.3960 - mse: 0.2677\n",
            "Epoch 590/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1292 - mae: 0.3950 - mse: 0.2678 - val_loss: 0.2355 - val_mae: 0.5578 - val_mse: 0.5425\n",
            "Epoch 591/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1289 - mae: 0.3965 - mse: 0.2671\n",
            "Epoch 592/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1310 - mae: 0.3968 - mse: 0.2707\n",
            "Epoch 593/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1282 - mae: 0.3954 - mse: 0.2657\n",
            "Epoch 594/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1306 - mae: 0.3988 - mse: 0.2704\n",
            "Epoch 595/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1287 - mae: 0.3934 - mse: 0.2670\n",
            "Epoch 596/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1286 - mae: 0.3945 - mse: 0.2662\n",
            "Epoch 597/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1284 - mae: 0.3921 - mse: 0.2666\n",
            "Epoch 598/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1290 - mae: 0.3950 - mse: 0.2669\n",
            "Epoch 599/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1277 - mae: 0.3934 - mse: 0.2647\n",
            "Epoch 600/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1308 - mae: 0.3961 - mse: 0.2709 - val_loss: 0.2382 - val_mae: 0.5615 - val_mse: 0.5468\n",
            "Epoch 601/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1281 - mae: 0.3934 - mse: 0.2651\n",
            "Epoch 602/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1282 - mae: 0.3950 - mse: 0.2651\n",
            "Epoch 603/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1283 - mae: 0.3946 - mse: 0.2654\n",
            "Epoch 604/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1287 - mae: 0.3927 - mse: 0.2665\n",
            "Epoch 605/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1271 - mae: 0.3918 - mse: 0.2626\n",
            "Epoch 606/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1294 - mae: 0.3937 - mse: 0.2678\n",
            "Epoch 607/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1275 - mae: 0.3933 - mse: 0.2634\n",
            "Epoch 608/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1276 - mae: 0.3927 - mse: 0.2644\n",
            "Epoch 609/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1274 - mae: 0.3926 - mse: 0.2636\n",
            "Epoch 610/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1275 - mae: 0.3924 - mse: 0.2636 - val_loss: 0.2392 - val_mae: 0.5626 - val_mse: 0.5502\n",
            "Epoch 611/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1275 - mae: 0.3905 - mse: 0.2637\n",
            "Epoch 612/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1287 - mae: 0.3964 - mse: 0.2666\n",
            "Epoch 613/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1284 - mae: 0.3933 - mse: 0.2655\n",
            "Epoch 614/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1267 - mae: 0.3895 - mse: 0.2621\n",
            "Epoch 615/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1266 - mae: 0.3929 - mse: 0.2614\n",
            "Epoch 616/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1271 - mae: 0.3914 - mse: 0.2628\n",
            "Epoch 617/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1289 - mae: 0.3924 - mse: 0.2667\n",
            "Epoch 618/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1278 - mae: 0.3933 - mse: 0.2646\n",
            "Epoch 619/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1275 - mae: 0.3950 - mse: 0.2634\n",
            "Epoch 620/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1263 - mae: 0.3914 - mse: 0.2613 - val_loss: 0.2352 - val_mae: 0.5563 - val_mse: 0.5413\n",
            "Epoch 621/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1265 - mae: 0.3899 - mse: 0.2615\n",
            "Epoch 622/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1267 - mae: 0.3915 - mse: 0.2620\n",
            "Epoch 623/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1276 - mae: 0.3925 - mse: 0.2639\n",
            "Epoch 624/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1273 - mae: 0.3915 - mse: 0.2637\n",
            "Epoch 625/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1268 - mae: 0.3923 - mse: 0.2623\n",
            "Epoch 626/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1257 - mae: 0.3886 - mse: 0.2602\n",
            "Epoch 627/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1275 - mae: 0.3933 - mse: 0.2633\n",
            "Epoch 628/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1269 - mae: 0.3940 - mse: 0.2625\n",
            "Epoch 629/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1284 - mae: 0.3938 - mse: 0.2655\n",
            "Epoch 630/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1254 - mae: 0.3914 - mse: 0.2589 - val_loss: 0.2499 - val_mae: 0.5782 - val_mse: 0.5732\n",
            "Epoch 631/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1275 - mae: 0.3911 - mse: 0.2636\n",
            "Epoch 632/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1272 - mae: 0.3942 - mse: 0.2628\n",
            "Epoch 633/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1262 - mae: 0.3911 - mse: 0.2605\n",
            "Epoch 634/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1248 - mae: 0.3872 - mse: 0.2577\n",
            "Epoch 635/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1263 - mae: 0.3903 - mse: 0.2609\n",
            "Epoch 636/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1249 - mae: 0.3883 - mse: 0.2574\n",
            "Epoch 637/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1242 - mae: 0.3880 - mse: 0.2569\n",
            "Epoch 638/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1259 - mae: 0.3885 - mse: 0.2600\n",
            "Epoch 639/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1257 - mae: 0.3888 - mse: 0.2595\n",
            "Epoch 640/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1250 - mae: 0.3888 - mse: 0.2581 - val_loss: 0.2422 - val_mae: 0.5674 - val_mse: 0.5571\n",
            "Epoch 641/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1247 - mae: 0.3879 - mse: 0.2577\n",
            "Epoch 642/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1259 - mae: 0.3907 - mse: 0.2600\n",
            "Epoch 643/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1288 - mae: 0.3951 - mse: 0.2662\n",
            "Epoch 644/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1247 - mae: 0.3890 - mse: 0.2573\n",
            "Epoch 645/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1256 - mae: 0.3866 - mse: 0.2598\n",
            "Epoch 646/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1246 - mae: 0.3870 - mse: 0.2572\n",
            "Epoch 647/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1235 - mae: 0.3867 - mse: 0.2550\n",
            "Epoch 648/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1236 - mae: 0.3849 - mse: 0.2549\n",
            "Epoch 649/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1239 - mae: 0.3869 - mse: 0.2560\n",
            "Epoch 650/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1254 - mae: 0.3885 - mse: 0.2586 - val_loss: 0.2499 - val_mae: 0.5785 - val_mse: 0.5750\n",
            "Epoch 651/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1248 - mae: 0.3897 - mse: 0.2574\n",
            "Epoch 652/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1238 - mae: 0.3871 - mse: 0.2553\n",
            "Epoch 653/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1239 - mae: 0.3851 - mse: 0.2560\n",
            "Epoch 654/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1248 - mae: 0.3886 - mse: 0.2579\n",
            "Epoch 655/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1243 - mae: 0.3857 - mse: 0.2566\n",
            "Epoch 656/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1230 - mae: 0.3835 - mse: 0.2536\n",
            "Epoch 657/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1235 - mae: 0.3875 - mse: 0.2548\n",
            "Epoch 658/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1223 - mae: 0.3833 - mse: 0.2523\n",
            "Epoch 659/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1253 - mae: 0.3900 - mse: 0.2583\n",
            "Epoch 660/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1239 - mae: 0.3849 - mse: 0.2558 - val_loss: 0.2398 - val_mae: 0.5624 - val_mse: 0.5530\n",
            "Epoch 661/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1237 - mae: 0.3856 - mse: 0.2551\n",
            "Epoch 662/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1235 - mae: 0.3862 - mse: 0.2549\n",
            "Epoch 663/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1227 - mae: 0.3841 - mse: 0.2531\n",
            "Epoch 664/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1261 - mae: 0.3913 - mse: 0.2597\n",
            "Epoch 665/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1233 - mae: 0.3845 - mse: 0.2543\n",
            "Epoch 666/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1239 - mae: 0.3864 - mse: 0.2557\n",
            "Epoch 667/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1222 - mae: 0.3836 - mse: 0.2521\n",
            "Epoch 668/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1233 - mae: 0.3848 - mse: 0.2546\n",
            "Epoch 669/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1226 - mae: 0.3845 - mse: 0.2525\n",
            "Epoch 670/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1225 - mae: 0.3839 - mse: 0.2523 - val_loss: 0.2399 - val_mae: 0.5626 - val_mse: 0.5532\n",
            "Epoch 671/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1226 - mae: 0.3859 - mse: 0.2527\n",
            "Epoch 672/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1225 - mae: 0.3851 - mse: 0.2528\n",
            "Epoch 673/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1255 - mae: 0.3888 - mse: 0.2588\n",
            "Epoch 674/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1218 - mae: 0.3825 - mse: 0.2506\n",
            "Epoch 675/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1231 - mae: 0.3854 - mse: 0.2542\n",
            "Epoch 676/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1215 - mae: 0.3800 - mse: 0.2505\n",
            "Epoch 677/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1231 - mae: 0.3857 - mse: 0.2543\n",
            "Epoch 678/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1213 - mae: 0.3817 - mse: 0.2500\n",
            "Epoch 679/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1218 - mae: 0.3827 - mse: 0.2508\n",
            "Epoch 680/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1219 - mae: 0.3843 - mse: 0.2513 - val_loss: 0.2432 - val_mae: 0.5676 - val_mse: 0.5609\n",
            "Epoch 681/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1216 - mae: 0.3816 - mse: 0.2503\n",
            "Epoch 682/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1223 - mae: 0.3845 - mse: 0.2519\n",
            "Epoch 683/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1218 - mae: 0.3830 - mse: 0.2515\n",
            "Epoch 684/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1232 - mae: 0.3853 - mse: 0.2546\n",
            "Epoch 685/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1252 - mae: 0.3903 - mse: 0.2582\n",
            "Epoch 686/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1216 - mae: 0.3846 - mse: 0.2506\n",
            "Epoch 687/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1208 - mae: 0.3818 - mse: 0.2487\n",
            "Epoch 688/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1215 - mae: 0.3836 - mse: 0.2502\n",
            "Epoch 689/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1230 - mae: 0.3831 - mse: 0.2539\n",
            "Epoch 690/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1212 - mae: 0.3816 - mse: 0.2499 - val_loss: 0.2405 - val_mae: 0.5639 - val_mse: 0.5555\n",
            "Epoch 691/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1221 - mae: 0.3829 - mse: 0.2516\n",
            "Epoch 692/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1205 - mae: 0.3812 - mse: 0.2483\n",
            "Epoch 693/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1205 - mae: 0.3796 - mse: 0.2482\n",
            "Epoch 694/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1214 - mae: 0.3811 - mse: 0.2504\n",
            "Epoch 695/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1202 - mae: 0.3810 - mse: 0.2472\n",
            "Epoch 696/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1207 - mae: 0.3787 - mse: 0.2488\n",
            "Epoch 697/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1205 - mae: 0.3811 - mse: 0.2480\n",
            "Epoch 698/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1209 - mae: 0.3822 - mse: 0.2488\n",
            "Epoch 699/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1207 - mae: 0.3801 - mse: 0.2488\n",
            "Epoch 700/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1205 - mae: 0.3803 - mse: 0.2481 - val_loss: 0.2431 - val_mae: 0.5668 - val_mse: 0.5608\n",
            "Epoch 701/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1211 - mae: 0.3828 - mse: 0.2494\n",
            "Epoch 702/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1211 - mae: 0.3814 - mse: 0.2496\n",
            "Epoch 703/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1200 - mae: 0.3806 - mse: 0.2472\n",
            "Epoch 704/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1206 - mae: 0.3813 - mse: 0.2481\n",
            "Epoch 705/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1199 - mae: 0.3815 - mse: 0.2468\n",
            "Epoch 706/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1206 - mae: 0.3813 - mse: 0.2480\n",
            "Epoch 707/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1206 - mae: 0.3810 - mse: 0.2480\n",
            "Epoch 708/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1196 - mae: 0.3793 - mse: 0.2461\n",
            "Epoch 709/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1215 - mae: 0.3822 - mse: 0.2499\n",
            "Epoch 710/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1197 - mae: 0.3810 - mse: 0.2461 - val_loss: 0.2464 - val_mae: 0.5712 - val_mse: 0.5683\n",
            "Epoch 711/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1198 - mae: 0.3796 - mse: 0.2465\n",
            "Epoch 712/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1201 - mae: 0.3806 - mse: 0.2472\n",
            "Epoch 713/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1203 - mae: 0.3800 - mse: 0.2483\n",
            "Epoch 714/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1195 - mae: 0.3783 - mse: 0.2459\n",
            "Epoch 715/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1195 - mae: 0.3795 - mse: 0.2454\n",
            "Epoch 716/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1195 - mae: 0.3798 - mse: 0.2462\n",
            "Epoch 717/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1217 - mae: 0.3829 - mse: 0.2505\n",
            "Epoch 718/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1210 - mae: 0.3796 - mse: 0.2485\n",
            "Epoch 719/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1207 - mae: 0.3831 - mse: 0.2484\n",
            "Epoch 720/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1190 - mae: 0.3787 - mse: 0.2448 - val_loss: 0.2453 - val_mae: 0.5700 - val_mse: 0.5670\n",
            "Epoch 721/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1195 - mae: 0.3793 - mse: 0.2459\n",
            "Epoch 722/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1194 - mae: 0.3807 - mse: 0.2454\n",
            "Epoch 723/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1213 - mae: 0.3831 - mse: 0.2499\n",
            "Epoch 724/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1192 - mae: 0.3790 - mse: 0.2451\n",
            "Epoch 725/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1197 - mae: 0.3803 - mse: 0.2460\n",
            "Epoch 726/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1194 - mae: 0.3784 - mse: 0.2456\n",
            "Epoch 727/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1202 - mae: 0.3812 - mse: 0.2476\n",
            "Epoch 728/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1192 - mae: 0.3780 - mse: 0.2452\n",
            "Epoch 729/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1191 - mae: 0.3780 - mse: 0.2445\n",
            "Epoch 730/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1190 - mae: 0.3785 - mse: 0.2444 - val_loss: 0.2459 - val_mae: 0.5692 - val_mse: 0.5679\n",
            "Epoch 731/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1178 - mae: 0.3754 - mse: 0.2421\n",
            "Epoch 732/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1186 - mae: 0.3796 - mse: 0.2437\n",
            "Epoch 733/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1193 - mae: 0.3785 - mse: 0.2449\n",
            "Epoch 734/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1205 - mae: 0.3820 - mse: 0.2478\n",
            "Epoch 735/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1199 - mae: 0.3793 - mse: 0.2470\n",
            "Epoch 736/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1198 - mae: 0.3805 - mse: 0.2457\n",
            "Epoch 737/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1177 - mae: 0.3756 - mse: 0.2420\n",
            "Epoch 738/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1183 - mae: 0.3766 - mse: 0.2430\n",
            "Epoch 739/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1191 - mae: 0.3799 - mse: 0.2444\n",
            "Epoch 740/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1173 - mae: 0.3746 - mse: 0.2410 - val_loss: 0.2518 - val_mae: 0.5780 - val_mse: 0.5807\n",
            "Epoch 741/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1189 - mae: 0.3779 - mse: 0.2446\n",
            "Epoch 742/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1214 - mae: 0.3819 - mse: 0.2499\n",
            "Epoch 743/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1191 - mae: 0.3779 - mse: 0.2450\n",
            "Epoch 744/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1231 - mae: 0.3834 - mse: 0.2537\n",
            "Epoch 745/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1196 - mae: 0.3807 - mse: 0.2466\n",
            "Epoch 746/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1210 - mae: 0.3808 - mse: 0.2490\n",
            "Epoch 747/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1180 - mae: 0.3757 - mse: 0.2425\n",
            "Epoch 748/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1175 - mae: 0.3752 - mse: 0.2412\n",
            "Epoch 749/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1163 - mae: 0.3725 - mse: 0.2388\n",
            "Epoch 750/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1170 - mae: 0.3748 - mse: 0.2405 - val_loss: 0.2585 - val_mae: 0.5861 - val_mse: 0.5948\n",
            "Epoch 751/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1184 - mae: 0.3762 - mse: 0.2433\n",
            "Epoch 752/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1168 - mae: 0.3743 - mse: 0.2400\n",
            "Epoch 753/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1175 - mae: 0.3754 - mse: 0.2412\n",
            "Epoch 754/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1171 - mae: 0.3757 - mse: 0.2405\n",
            "Epoch 755/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1164 - mae: 0.3715 - mse: 0.2386\n",
            "Epoch 756/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1169 - mae: 0.3750 - mse: 0.2398\n",
            "Epoch 757/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1189 - mae: 0.3774 - mse: 0.2450\n",
            "Epoch 758/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1202 - mae: 0.3828 - mse: 0.2473\n",
            "Epoch 759/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1177 - mae: 0.3774 - mse: 0.2415\n",
            "Epoch 760/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1182 - mae: 0.3757 - mse: 0.2425 - val_loss: 0.2541 - val_mae: 0.5820 - val_mse: 0.5864\n",
            "Epoch 761/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1165 - mae: 0.3740 - mse: 0.2391\n",
            "Epoch 762/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1171 - mae: 0.3754 - mse: 0.2403\n",
            "Epoch 763/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1170 - mae: 0.3742 - mse: 0.2401\n",
            "Epoch 764/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1170 - mae: 0.3733 - mse: 0.2405\n",
            "Epoch 765/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1165 - mae: 0.3746 - mse: 0.2388\n",
            "Epoch 766/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1164 - mae: 0.3738 - mse: 0.2388\n",
            "Epoch 767/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1180 - mae: 0.3787 - mse: 0.2424\n",
            "Epoch 768/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1158 - mae: 0.3708 - mse: 0.2372\n",
            "Epoch 769/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1167 - mae: 0.3750 - mse: 0.2392\n",
            "Epoch 770/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1169 - mae: 0.3757 - mse: 0.2398 - val_loss: 0.2511 - val_mae: 0.5777 - val_mse: 0.5788\n",
            "Epoch 771/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1166 - mae: 0.3734 - mse: 0.2391\n",
            "Epoch 772/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1160 - mae: 0.3736 - mse: 0.2380\n",
            "Epoch 773/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1181 - mae: 0.3767 - mse: 0.2432\n",
            "Epoch 774/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1159 - mae: 0.3733 - mse: 0.2380\n",
            "Epoch 775/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1170 - mae: 0.3746 - mse: 0.2400\n",
            "Epoch 776/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1165 - mae: 0.3742 - mse: 0.2393\n",
            "Epoch 777/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1179 - mae: 0.3785 - mse: 0.2417\n",
            "Epoch 778/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1197 - mae: 0.3782 - mse: 0.2465\n",
            "Epoch 779/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1175 - mae: 0.3756 - mse: 0.2406\n",
            "Epoch 780/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1201 - mae: 0.3784 - mse: 0.2474 - val_loss: 0.2526 - val_mae: 0.5782 - val_mse: 0.5814\n",
            "Epoch 781/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1186 - mae: 0.3755 - mse: 0.2436\n",
            "Epoch 782/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1163 - mae: 0.3734 - mse: 0.2382\n",
            "Epoch 783/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1172 - mae: 0.3736 - mse: 0.2404\n",
            "Epoch 784/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1157 - mae: 0.3721 - mse: 0.2369\n",
            "Epoch 785/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1172 - mae: 0.3762 - mse: 0.2401\n",
            "Epoch 786/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1199 - mae: 0.3799 - mse: 0.2465\n",
            "Epoch 787/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1165 - mae: 0.3720 - mse: 0.2393\n",
            "Epoch 788/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1154 - mae: 0.3734 - mse: 0.2366\n",
            "Epoch 789/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1156 - mae: 0.3701 - mse: 0.2372\n",
            "Epoch 790/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1151 - mae: 0.3711 - mse: 0.2357 - val_loss: 0.2667 - val_mae: 0.5993 - val_mse: 0.6155\n",
            "Epoch 791/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1174 - mae: 0.3735 - mse: 0.2413\n",
            "Epoch 792/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1187 - mae: 0.3772 - mse: 0.2435\n",
            "Epoch 793/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1150 - mae: 0.3711 - mse: 0.2357\n",
            "Epoch 794/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1167 - mae: 0.3759 - mse: 0.2389\n",
            "Epoch 795/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1161 - mae: 0.3738 - mse: 0.2380\n",
            "Epoch 796/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1147 - mae: 0.3694 - mse: 0.2352\n",
            "Epoch 797/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1141 - mae: 0.3679 - mse: 0.2337\n",
            "Epoch 798/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1145 - mae: 0.3694 - mse: 0.2347\n",
            "Epoch 799/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1146 - mae: 0.3711 - mse: 0.2351\n",
            "Epoch 800/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1150 - mae: 0.3716 - mse: 0.2354 - val_loss: 0.2508 - val_mae: 0.5768 - val_mse: 0.5782\n",
            "Epoch 801/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1143 - mae: 0.3685 - mse: 0.2343\n",
            "Epoch 802/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1160 - mae: 0.3753 - mse: 0.2380\n",
            "Epoch 803/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1182 - mae: 0.3755 - mse: 0.2425\n",
            "Epoch 804/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1151 - mae: 0.3722 - mse: 0.2359\n",
            "Epoch 805/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1147 - mae: 0.3714 - mse: 0.2354\n",
            "Epoch 806/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1150 - mae: 0.3702 - mse: 0.2357\n",
            "Epoch 807/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1146 - mae: 0.3680 - mse: 0.2345\n",
            "Epoch 808/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1145 - mae: 0.3723 - mse: 0.2348\n",
            "Epoch 809/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1151 - mae: 0.3707 - mse: 0.2357\n",
            "Epoch 810/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1139 - mae: 0.3680 - mse: 0.2334 - val_loss: 0.2546 - val_mae: 0.5815 - val_mse: 0.5865\n",
            "Epoch 811/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1148 - mae: 0.3711 - mse: 0.2350\n",
            "Epoch 812/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1143 - mae: 0.3714 - mse: 0.2343\n",
            "Epoch 813/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1157 - mae: 0.3728 - mse: 0.2373\n",
            "Epoch 814/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1164 - mae: 0.3739 - mse: 0.2385\n",
            "Epoch 815/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1143 - mae: 0.3722 - mse: 0.2341\n",
            "Epoch 816/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1152 - mae: 0.3714 - mse: 0.2363\n",
            "Epoch 817/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1142 - mae: 0.3703 - mse: 0.2338\n",
            "Epoch 818/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1134 - mae: 0.3685 - mse: 0.2320\n",
            "Epoch 819/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1140 - mae: 0.3694 - mse: 0.2336\n",
            "Epoch 820/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1135 - mae: 0.3681 - mse: 0.2322 - val_loss: 0.2507 - val_mae: 0.5764 - val_mse: 0.5783\n",
            "Epoch 821/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1149 - mae: 0.3723 - mse: 0.2351\n",
            "Epoch 822/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1139 - mae: 0.3675 - mse: 0.2332\n",
            "Epoch 823/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1144 - mae: 0.3696 - mse: 0.2340\n",
            "Epoch 824/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1141 - mae: 0.3691 - mse: 0.2337\n",
            "Epoch 825/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1143 - mae: 0.3715 - mse: 0.2340\n",
            "Epoch 826/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1138 - mae: 0.3692 - mse: 0.2328\n",
            "Epoch 827/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1131 - mae: 0.3668 - mse: 0.2318\n",
            "Epoch 828/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1135 - mae: 0.3686 - mse: 0.2326\n",
            "Epoch 829/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1133 - mae: 0.3684 - mse: 0.2320\n",
            "Epoch 830/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1128 - mae: 0.3658 - mse: 0.2308 - val_loss: 0.2712 - val_mae: 0.6024 - val_mse: 0.6253\n",
            "Epoch 831/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1145 - mae: 0.3687 - mse: 0.2348\n",
            "Epoch 832/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1138 - mae: 0.3673 - mse: 0.2334\n",
            "Epoch 833/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1134 - mae: 0.3679 - mse: 0.2321\n",
            "Epoch 834/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1137 - mae: 0.3687 - mse: 0.2329\n",
            "Epoch 835/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1140 - mae: 0.3695 - mse: 0.2338\n",
            "Epoch 836/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1141 - mae: 0.3673 - mse: 0.2336\n",
            "Epoch 837/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1132 - mae: 0.3696 - mse: 0.2312\n",
            "Epoch 838/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1131 - mae: 0.3663 - mse: 0.2312\n",
            "Epoch 839/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1136 - mae: 0.3682 - mse: 0.2325\n",
            "Epoch 840/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1141 - mae: 0.3738 - mse: 0.2329 - val_loss: 0.2527 - val_mae: 0.5778 - val_mse: 0.5827\n",
            "Epoch 841/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1132 - mae: 0.3661 - mse: 0.2316\n",
            "Epoch 842/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1123 - mae: 0.3659 - mse: 0.2298\n",
            "Epoch 843/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1136 - mae: 0.3680 - mse: 0.2326\n",
            "Epoch 844/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1120 - mae: 0.3638 - mse: 0.2292\n",
            "Epoch 845/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1117 - mae: 0.3660 - mse: 0.2286\n",
            "Epoch 846/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1134 - mae: 0.3675 - mse: 0.2322\n",
            "Epoch 847/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1128 - mae: 0.3663 - mse: 0.2306\n",
            "Epoch 848/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1126 - mae: 0.3676 - mse: 0.2305\n",
            "Epoch 849/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1124 - mae: 0.3663 - mse: 0.2300\n",
            "Epoch 850/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1123 - mae: 0.3658 - mse: 0.2296 - val_loss: 0.2594 - val_mae: 0.5869 - val_mse: 0.5975\n",
            "Epoch 851/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1119 - mae: 0.3650 - mse: 0.2291\n",
            "Epoch 852/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1122 - mae: 0.3688 - mse: 0.2293\n",
            "Epoch 853/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1126 - mae: 0.3659 - mse: 0.2307\n",
            "Epoch 854/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1131 - mae: 0.3696 - mse: 0.2316\n",
            "Epoch 855/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1120 - mae: 0.3640 - mse: 0.2293\n",
            "Epoch 856/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1131 - mae: 0.3640 - mse: 0.2316\n",
            "Epoch 857/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1128 - mae: 0.3665 - mse: 0.2311\n",
            "Epoch 858/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1155 - mae: 0.3725 - mse: 0.2375\n",
            "Epoch 859/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1118 - mae: 0.3673 - mse: 0.2287\n",
            "Epoch 860/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1121 - mae: 0.3650 - mse: 0.2292 - val_loss: 0.2595 - val_mae: 0.5899 - val_mse: 0.5993\n",
            "Epoch 861/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1115 - mae: 0.3625 - mse: 0.2282\n",
            "Epoch 862/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1111 - mae: 0.3649 - mse: 0.2269\n",
            "Epoch 863/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1126 - mae: 0.3650 - mse: 0.2304\n",
            "Epoch 864/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1108 - mae: 0.3640 - mse: 0.2266\n",
            "Epoch 865/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1151 - mae: 0.3700 - mse: 0.2357\n",
            "Epoch 866/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1109 - mae: 0.3646 - mse: 0.2269\n",
            "Epoch 867/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1114 - mae: 0.3640 - mse: 0.2276\n",
            "Epoch 868/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1120 - mae: 0.3633 - mse: 0.2286\n",
            "Epoch 869/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1112 - mae: 0.3661 - mse: 0.2273\n",
            "Epoch 870/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1108 - mae: 0.3629 - mse: 0.2264 - val_loss: 0.2539 - val_mae: 0.5789 - val_mse: 0.5865\n",
            "Epoch 871/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1108 - mae: 0.3614 - mse: 0.2265\n",
            "Epoch 872/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1126 - mae: 0.3688 - mse: 0.2305\n",
            "Epoch 873/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1112 - mae: 0.3640 - mse: 0.2273\n",
            "Epoch 874/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1137 - mae: 0.3683 - mse: 0.2333\n",
            "Epoch 875/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1114 - mae: 0.3661 - mse: 0.2274\n",
            "Epoch 876/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1112 - mae: 0.3646 - mse: 0.2272\n",
            "Epoch 877/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1099 - mae: 0.3608 - mse: 0.2244\n",
            "Epoch 878/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1155 - mae: 0.3711 - mse: 0.2367\n",
            "Epoch 879/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1112 - mae: 0.3662 - mse: 0.2271\n",
            "Epoch 880/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1105 - mae: 0.3605 - mse: 0.2255 - val_loss: 0.2616 - val_mae: 0.5914 - val_mse: 0.6045\n",
            "Epoch 881/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1107 - mae: 0.3630 - mse: 0.2262\n",
            "Epoch 882/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1104 - mae: 0.3616 - mse: 0.2254\n",
            "Epoch 883/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1120 - mae: 0.3641 - mse: 0.2293\n",
            "Epoch 884/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1111 - mae: 0.3636 - mse: 0.2270\n",
            "Epoch 885/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1106 - mae: 0.3622 - mse: 0.2263\n",
            "Epoch 886/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1112 - mae: 0.3646 - mse: 0.2273\n",
            "Epoch 887/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1123 - mae: 0.3644 - mse: 0.2297\n",
            "Epoch 888/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1100 - mae: 0.3599 - mse: 0.2251\n",
            "Epoch 889/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1112 - mae: 0.3657 - mse: 0.2271\n",
            "Epoch 890/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1102 - mae: 0.3630 - mse: 0.2253 - val_loss: 0.2548 - val_mae: 0.5814 - val_mse: 0.5884\n",
            "Epoch 891/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1130 - mae: 0.3662 - mse: 0.2306\n",
            "Epoch 892/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1130 - mae: 0.3683 - mse: 0.2307\n",
            "Epoch 893/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1098 - mae: 0.3608 - mse: 0.2242\n",
            "Epoch 894/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1109 - mae: 0.3657 - mse: 0.2265\n",
            "Epoch 895/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1103 - mae: 0.3630 - mse: 0.2255\n",
            "Epoch 896/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1105 - mae: 0.3618 - mse: 0.2261\n",
            "Epoch 897/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1103 - mae: 0.3627 - mse: 0.2258\n",
            "Epoch 898/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1103 - mae: 0.3618 - mse: 0.2253\n",
            "Epoch 899/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1095 - mae: 0.3606 - mse: 0.2235\n",
            "Epoch 900/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1104 - mae: 0.3629 - mse: 0.2254 - val_loss: 0.2519 - val_mae: 0.5730 - val_mse: 0.5823\n",
            "Epoch 901/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1128 - mae: 0.3651 - mse: 0.2305\n",
            "Epoch 902/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1097 - mae: 0.3619 - mse: 0.2243\n",
            "Epoch 903/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1090 - mae: 0.3590 - mse: 0.2226\n",
            "Epoch 904/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1103 - mae: 0.3606 - mse: 0.2249\n",
            "Epoch 905/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1088 - mae: 0.3593 - mse: 0.2221\n",
            "Epoch 906/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1106 - mae: 0.3629 - mse: 0.2257\n",
            "Epoch 907/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1121 - mae: 0.3643 - mse: 0.2294\n",
            "Epoch 908/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1105 - mae: 0.3643 - mse: 0.2259\n",
            "Epoch 909/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1087 - mae: 0.3581 - mse: 0.2222\n",
            "Epoch 910/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1095 - mae: 0.3598 - mse: 0.2238 - val_loss: 0.2596 - val_mae: 0.5874 - val_mse: 0.6009\n",
            "Epoch 911/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1090 - mae: 0.3602 - mse: 0.2227\n",
            "Epoch 912/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1092 - mae: 0.3625 - mse: 0.2232\n",
            "Epoch 913/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1121 - mae: 0.3676 - mse: 0.2287\n",
            "Epoch 914/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1081 - mae: 0.3575 - mse: 0.2207\n",
            "Epoch 915/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1106 - mae: 0.3641 - mse: 0.2258\n",
            "Epoch 916/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1100 - mae: 0.3624 - mse: 0.2244\n",
            "Epoch 917/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1084 - mae: 0.3588 - mse: 0.2214\n",
            "Epoch 918/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1098 - mae: 0.3604 - mse: 0.2243\n",
            "Epoch 919/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1093 - mae: 0.3603 - mse: 0.2231\n",
            "Epoch 920/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1081 - mae: 0.3591 - mse: 0.2206 - val_loss: 0.2583 - val_mae: 0.5853 - val_mse: 0.5966\n",
            "Epoch 921/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1077 - mae: 0.3574 - mse: 0.2197\n",
            "Epoch 922/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1093 - mae: 0.3597 - mse: 0.2230\n",
            "Epoch 923/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1116 - mae: 0.3646 - mse: 0.2278\n",
            "Epoch 924/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1085 - mae: 0.3582 - mse: 0.2211\n",
            "Epoch 925/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1087 - mae: 0.3593 - mse: 0.2220\n",
            "Epoch 926/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1115 - mae: 0.3643 - mse: 0.2277\n",
            "Epoch 927/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1084 - mae: 0.3582 - mse: 0.2212\n",
            "Epoch 928/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1093 - mae: 0.3589 - mse: 0.2228\n",
            "Epoch 929/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1085 - mae: 0.3587 - mse: 0.2218\n",
            "Epoch 930/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1087 - mae: 0.3603 - mse: 0.2215 - val_loss: 0.2634 - val_mae: 0.5929 - val_mse: 0.6085\n",
            "Epoch 931/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1103 - mae: 0.3633 - mse: 0.2257\n",
            "Epoch 932/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1094 - mae: 0.3612 - mse: 0.2228\n",
            "Epoch 933/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1078 - mae: 0.3592 - mse: 0.2202\n",
            "Epoch 934/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1104 - mae: 0.3605 - mse: 0.2255\n",
            "Epoch 935/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1075 - mae: 0.3569 - mse: 0.2190\n",
            "Epoch 936/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1096 - mae: 0.3616 - mse: 0.2239\n",
            "Epoch 937/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1099 - mae: 0.3610 - mse: 0.2245\n",
            "Epoch 938/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1117 - mae: 0.3643 - mse: 0.2282\n",
            "Epoch 939/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1091 - mae: 0.3599 - mse: 0.2229\n",
            "Epoch 940/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1076 - mae: 0.3580 - mse: 0.2194 - val_loss: 0.2558 - val_mae: 0.5796 - val_mse: 0.5919\n",
            "Epoch 941/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1074 - mae: 0.3569 - mse: 0.2189\n",
            "Epoch 942/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1078 - mae: 0.3583 - mse: 0.2196\n",
            "Epoch 943/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1078 - mae: 0.3570 - mse: 0.2199\n",
            "Epoch 944/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1083 - mae: 0.3587 - mse: 0.2211\n",
            "Epoch 945/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1084 - mae: 0.3580 - mse: 0.2213\n",
            "Epoch 946/1000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1080 - mae: 0.3572 - mse: 0.2205\n",
            "Epoch 947/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1100 - mae: 0.3627 - mse: 0.2245\n",
            "Epoch 948/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1100 - mae: 0.3612 - mse: 0.2250\n",
            "Epoch 949/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1071 - mae: 0.3561 - mse: 0.2184\n",
            "Epoch 950/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1072 - mae: 0.3564 - mse: 0.2185 - val_loss: 0.2604 - val_mae: 0.5871 - val_mse: 0.6028\n",
            "Epoch 951/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1076 - mae: 0.3574 - mse: 0.2195\n",
            "Epoch 952/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1089 - mae: 0.3627 - mse: 0.2224\n",
            "Epoch 953/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1078 - mae: 0.3575 - mse: 0.2200\n",
            "Epoch 954/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1066 - mae: 0.3553 - mse: 0.2171\n",
            "Epoch 955/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1073 - mae: 0.3567 - mse: 0.2186\n",
            "Epoch 956/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1088 - mae: 0.3604 - mse: 0.2221\n",
            "Epoch 957/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1085 - mae: 0.3590 - mse: 0.2210\n",
            "Epoch 958/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1075 - mae: 0.3581 - mse: 0.2193\n",
            "Epoch 959/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1083 - mae: 0.3586 - mse: 0.2209\n",
            "Epoch 960/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1061 - mae: 0.3524 - mse: 0.2162 - val_loss: 0.2655 - val_mae: 0.5949 - val_mse: 0.6149\n",
            "Epoch 961/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1090 - mae: 0.3621 - mse: 0.2224\n",
            "Epoch 962/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1074 - mae: 0.3568 - mse: 0.2192\n",
            "Epoch 963/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1069 - mae: 0.3568 - mse: 0.2180\n",
            "Epoch 964/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1085 - mae: 0.3577 - mse: 0.2219\n",
            "Epoch 965/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1065 - mae: 0.3554 - mse: 0.2169\n",
            "Epoch 966/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1067 - mae: 0.3569 - mse: 0.2176\n",
            "Epoch 967/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1069 - mae: 0.3559 - mse: 0.2182\n",
            "Epoch 968/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1059 - mae: 0.3518 - mse: 0.2158\n",
            "Epoch 969/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1067 - mae: 0.3561 - mse: 0.2174\n",
            "Epoch 970/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1072 - mae: 0.3571 - mse: 0.2182 - val_loss: 0.2620 - val_mae: 0.5912 - val_mse: 0.6077\n",
            "Epoch 971/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1061 - mae: 0.3549 - mse: 0.2162\n",
            "Epoch 972/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1062 - mae: 0.3537 - mse: 0.2166\n",
            "Epoch 973/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1060 - mae: 0.3550 - mse: 0.2159\n",
            "Epoch 974/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1070 - mae: 0.3552 - mse: 0.2180\n",
            "Epoch 975/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1065 - mae: 0.3572 - mse: 0.2171\n",
            "Epoch 976/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1052 - mae: 0.3540 - mse: 0.2143\n",
            "Epoch 977/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1057 - mae: 0.3536 - mse: 0.2156\n",
            "Epoch 978/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1079 - mae: 0.3571 - mse: 0.2203\n",
            "Epoch 979/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1098 - mae: 0.3596 - mse: 0.2238\n",
            "Epoch 980/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1058 - mae: 0.3540 - mse: 0.2155 - val_loss: 0.2586 - val_mae: 0.5827 - val_mse: 0.5985\n",
            "Epoch 981/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1062 - mae: 0.3550 - mse: 0.2161\n",
            "Epoch 982/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1065 - mae: 0.3533 - mse: 0.2169\n",
            "Epoch 983/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1086 - mae: 0.3608 - mse: 0.2206\n",
            "Epoch 984/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1078 - mae: 0.3585 - mse: 0.2200\n",
            "Epoch 985/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1060 - mae: 0.3562 - mse: 0.2155\n",
            "Epoch 986/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1057 - mae: 0.3550 - mse: 0.2154\n",
            "Epoch 987/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1077 - mae: 0.3572 - mse: 0.2196\n",
            "Epoch 988/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1056 - mae: 0.3545 - mse: 0.2151\n",
            "Epoch 989/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1083 - mae: 0.3612 - mse: 0.2208\n",
            "Epoch 990/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1069 - mae: 0.3578 - mse: 0.2185 - val_loss: 0.2802 - val_mae: 0.6161 - val_mse: 0.6506\n",
            "Epoch 991/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1064 - mae: 0.3562 - mse: 0.2165\n",
            "Epoch 992/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1048 - mae: 0.3521 - mse: 0.2134\n",
            "Epoch 993/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1062 - mae: 0.3550 - mse: 0.2161\n",
            "Epoch 994/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1052 - mae: 0.3526 - mse: 0.2144\n",
            "Epoch 995/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1047 - mae: 0.3523 - mse: 0.2135\n",
            "Epoch 996/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1072 - mae: 0.3568 - mse: 0.2178\n",
            "Epoch 997/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1059 - mae: 0.3551 - mse: 0.2159\n",
            "Epoch 998/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1060 - mae: 0.3534 - mse: 0.2160\n",
            "Epoch 999/1000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1050 - mae: 0.3523 - mse: 0.2139\n",
            "Epoch 1000/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1054 - mae: 0.3537 - mse: 0.2145 - val_loss: 0.2604 - val_mae: 0.5857 - val_mse: 0.6037\n",
            "Fin del entrenamiento\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gráficas de errores absoluto y cuadrático promedios"
      ],
      "metadata": {
        "id": "LL942W-14TP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================ Gráficas de MAE y MSE ================\n",
        "#Luego del entrenamiento, se obtienen los datos de pérdida para el entrenamiento\n",
        "#y la validación\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "mse = history.history['mse']\n",
        "val_mse = history.history['val_mse']\n",
        "#Se crean arrays para definir los ejes horizontales de las pérdidas anteriores\n",
        "#en la gráfica\n",
        "x_mae = []\n",
        "x_mse = []\n",
        "x_valmae = []\n",
        "x_valmse = []\n",
        "#Se agregan los valores a cada eje x del entrenamiento, que corresponden a cada\n",
        "#iteración\n",
        "for i in range(EPOCHS):\n",
        "  x_mae.append(i + 1)\n",
        "  x_mse.append(i + 1)\n",
        "#Se agregan los valores a cada eje x de validación, de acuerdo con la frecuencia \n",
        "#de validación definida anteriormente\n",
        "for i in range(CantVal):\n",
        "  x_valmae.append((i + 1) * freqVal)\n",
        "  x_valmse.append((i + 1) * freqVal)\n",
        "#Para graficar de mejor forma los resultados, se usa un subplot con 2 espacios\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n",
        "#Se configuran los nombres de cada eje en las gráficas\n",
        "axs[0].set_xlabel(\"Iteración\")\n",
        "axs[0].set_ylabel(\"MAE\")\n",
        "axs[1].set_xlabel(\"Iteración\")\n",
        "axs[1].set_ylabel(\"MSE\")\n",
        "#Se grafican los datos de error absoluto para el entrenamiento y la validación\n",
        "axs[0].plot(x_mae, mae, label=\"Error de entrenamiento\")\n",
        "axs[0].plot(x_valmae, val_mae, label=\"Error de validación\")\n",
        "#Se grafican los datos de error cuadrático para el entrenamiento y la validación\n",
        "axs[1].plot(x_mse, mse, label=\"Error de entrenamiento\")\n",
        "axs[1].plot(x_valmse, val_mse, label=\"Error de validación\")\n",
        "#Limita los ejes de las gráficas a valores entre 0 y 1, para observar cada error\n",
        "axs[0].set_ylim([0,1])\n",
        "axs[1].set_ylim([0,1])\n",
        "#Muestra las leyendas para identificar las curvas\n",
        "axs[0].legend()\n",
        "axs[1].legend()\n",
        "#Despliega las gráficas resultantes\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "f1hZvvRU4yK0",
        "outputId": "cdbc6f52-7446-4844-be25-7a255dfbea0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluación de pruebas"
      ],
      "metadata": {
        "id": "jaDblDea7xeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Para evaluar completamente el funcionamiento del modelo, se realiza una serie\n",
        "#de predicciones usando el subconjunto de prueba que se definió anteriormente\n",
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "#Para observar cuánto distan los valores predichos de los valores reales, se\n",
        "#realiza una gráfica de dispersión entre dichos datos\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "#Se colocan los nombres de los ejes\n",
        "plt.xlabel('Valores reales')\n",
        "plt.ylabel('Valores predichos')\n",
        "#Se definen las dimensiones de la gráfica\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "#Se establecen límites para cada uno de los ejes, de modo que se aproveche el\n",
        "#espacio lo más que se pueda\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "#Se dibuja la recta ideal en la cual se encontrarían los datos, si el error de\n",
        "#la red fuera cero\n",
        "_ = plt.plot([-100, 100], [-100, 100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "YDScy9Kv6KDg",
        "outputId": "2916e10b-35a5-4a61-a3ed-b376640b9d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#En adición a lo anterior, se realiza un histograma en donde se indica la\n",
        "#cantidad de veces que sucedió cada posible error en la predicción\n",
        "#Para ello, se calcula el error de predicción, al sustraer los valores reales\n",
        "#de los valores predichos\n",
        "error = test_predictions - test_labels\n",
        "#Se grafica el histograma correctamente\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Error de predicción\")\n",
        "_ = plt.ylabel(\"Cantidad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "kjjz_X8i6hMS",
        "outputId": "ce382e41-2f2e-46e7-e98d-76787d3cf211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Carga de combinaciones adicionales de entrada"
      ],
      "metadata": {
        "id": "BV6BuU-9yFVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================ Carga de datos externos ================\n",
        "#Primero se cargan los datos a partir de un nuevo archivo .csv\n",
        "data_redwine = pd.read_csv('winequality-red1.csv', header=0)\n",
        "print(data_redwine)\n",
        "#Como estos datos solo incluyen los parámetros de entrada, se procede a su\n",
        "#normalización\n",
        "normed_data_redwine = scaler.fit_transform(data_redwine)\n",
        "#Luego, se calculan las calidades de vino\n",
        "qual_preds = model.predict(normed_data_redwine).flatten()\n",
        "print(\"\\nQualities:\",qual_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HLvyHDSyLBU",
        "outputId": "a87fb7f2-3a05-4d78-a3af-45c80c0a6851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
            "0            6.3              0.56         0.18             5.3        177   \n",
            "1            9.9              0.26         0.02             6.9         24   \n",
            "2            5.9              0.77         0.12             7.2        112   \n",
            "\n",
            "   free sulfur dioxide  total sulfur dioxide  density   pH  sulphates  alcohol  \n",
            "0                   17                    23   0.8933  8.2       0.91     11.7  \n",
            "1                   17                    51   0.8733  2.3       0.67      9.2  \n",
            "2                    9                    67   0.8841  6.5       1.17     14.5  \n",
            "\n",
            "Qualities: [6.126431 5.441194 5.702664]\n"
          ]
        }
      ]
    }
  ]
}